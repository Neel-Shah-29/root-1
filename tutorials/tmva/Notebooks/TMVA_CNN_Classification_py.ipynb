{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d72673",
   "metadata": {},
   "source": [
    "## TMVA Classification Example Using a Convolutional Neural Network\n",
    "This is an example of using a CNN in TMVA. We do classification using a toy image data set that is generated when running the example macro.\n",
    "\n",
    "Helper function to create input images data we create a signal and background 2D histograms from 2d gaussians with a location (means in X and Y)  different for each event The difference between signal and background is in the gaussian width. The width for the background gaussian is slightly larger than the signal width by few % values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb14961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA \n",
    "import os\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c09d0",
   "metadata": {},
   "source": [
    "### Setting up TMVA\n",
    "\n",
    "TMVA requires initialization the PyMVA to utilize PyTorch. PyMVA is the interface for third-party MVA tools based on Python. It is created to make powerful external libraries easily accessible with a direct integration into the TMVA workflow. All PyMVA methods provide the same plug-and-play mechanisms as the TMVA methods. Because the base method of PyMVA is inherited from the TMVA base method, all options of internal TMVA methods apply for PyMVA methods as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb5a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.TMVA.Tools.Instance()\n",
    "\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42c962",
   "metadata": {},
   "source": [
    "### Create an Output File and Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods whose performance you'd like to investigate.\n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    "- The first argument is the base of the name of all the output weightfiles in the directory weight/ that will be created with the method parameters\n",
    "\n",
    "- The second argument is the output file for the training results\n",
    "\n",
    "- The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6b96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputFile = ROOT.TFile.Open(\"CNN_ClassificationOutput.root\", \"RECREATE\")\n",
    "\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee020d",
   "metadata": {},
   "source": [
    "### Define the Options and number of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc992dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=[1,1,1,1,1]\n",
    "useTMVACNN = opt[0] if (len(opt) > 0) else False\n",
    "useKerasCNN = opt[0] if (len(opt) > 1) else False\n",
    "useTMVADNN = opt[0] if (len(opt) > 2) else False\n",
    "useTMVABDT = opt[0] if (len(opt) > 3) else False\n",
    "usePyTorchCNN = opt[0] if (len(opt) > 4) else False\n",
    "# useTMVACNN = False\n",
    "\n",
    "writeOutputFile = True\n",
    "\n",
    "num_threads = 0  # use default threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd37cd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with nthreads  = 4\n"
     ]
    }
   ],
   "source": [
    "# do enable MT running\n",
    "if (num_threads >= 0):\n",
    "  ROOT.EnableImplicitMT(num_threads)\n",
    "  if (num_threads > 0):\n",
    "     ROOT.gSystem.Setenv(\"OMP_NUM_THREADS\", ROOT.TString.Format(\"%d\",num_threads))\n",
    "\n",
    "else:\n",
    "  ROOT.gSystem.Setenv(\"OMP_NUM_THREADS\", \"1\")\n",
    "\n",
    "print(\"Running with nthreads  = \" + str(ROOT.GetThreadPoolSize()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3667de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __debug__:\n",
    "    ROOT.gSystem.Setenv(\"KERAS_BACKEND\", \"tensorflow\")\n",
    "    # for using Keras\n",
    "#     TMVA.PyMethodBase.PyInitialize()\n",
    "else:\n",
    "    useKerasCNN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae55798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (writeOutputFile):\n",
    "#     outputFile = ROOT.TFile.Open(\"TMVA_CNN_ClassificationOutput.root\", \"RECREATE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c429a2",
   "metadata": {},
   "source": [
    "### Declare Factory\n",
    "- Note that we disable any pre-transformation of the input variables and we avoid computing correlations between input variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8a976b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "factory =  ROOT.TMVA.Factory (\n",
    "  \"TMVA_CNN_Classification\", outputFile,\n",
    "  \"!V:ROC:!Silent:Color:AnalysisType=Classification:Transformations=None:!Correlations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46ab7e",
   "metadata": {},
   "source": [
    "### Declare DataLoader(s)\n",
    "\n",
    "  The next step is to declare the DataLoader class that deals with input variables\n",
    "\n",
    "  Define the input variables that shall be used for the MVA training\n",
    "  note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "  In this case the input data consists of an image of 16x16 pixels. Each single pixel is a branch in a ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f942ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = ROOT.TMVA.DataLoader(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930417f1",
   "metadata": {},
   "source": [
    "### Setup Dataset(s)\n",
    "Define input data file and setup the signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f6db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : signal_tree                                            *\n",
      "*Entries :     5000 : Total =         5207924 bytes  File  Size =    4659345 *\n",
      "*        :          : Tree compression factor =   1.12                       *\n",
      "******************************************************************************\n",
      "*Br    0 :vars      : vector<float>                                          *\n",
      "*Entries :     5000 : Total  Size=    5207506 bytes  File Size  =    4657486 *\n",
      "*Baskets :      167 : Basket Size=      32000 bytes  Compression=   1.12     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "imgSize = 16 * 16\n",
    "inputFileName = \"images_data_16x16.root\"\n",
    "inputFile = ROOT.TFile.Open(inputFileName)\n",
    "if (inputFile == None):\n",
    "    Error(\"TMVA_CNN_Classification\", \"Error opening input file %s - exit\", inputFileName.Data())\n",
    "signalTree     = inputFile.Get(\"sig_tree\")\n",
    "backgroundTree = inputFile.Get(\"bkg_tree\")\n",
    "\n",
    "signalTree.Print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e189e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 5000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 5000 events\n"
     ]
    }
   ],
   "source": [
    "nEventsSig = signalTree.GetEntries()\n",
    "nEventsBkg = backgroundTree.GetEntries()\n",
    "# global event weights per tree (see below for setting event-wise weights)\n",
    "signalWeight = 1.0\n",
    "backgroundWeight = 1.0\n",
    "\n",
    "# You can add an arbitrary number of signal or background trees\n",
    "loader.AddSignalTree(signalTree, signalWeight)\n",
    "loader.AddBackgroundTree(backgroundTree, backgroundWeight)\n",
    "\n",
    "## add event variables (image)\n",
    "## use new method (from ROOT 6.20 to add a variable array for all image data)\n",
    " \n",
    "loader.AddVariablesArray(\"vars\",imgSize,'F')\n",
    "\n",
    "# Set individual event weights (the variables must exist in the original TTree)\n",
    "#    for signal    : factory.SetSignalWeightExpression    (\"weight1*weight2\")\n",
    "#    for background: factory.SetBackgroundWeightExpression(\"weight1*weight2\")\n",
    "# loader.SetBackgroundWeightExpression( \"weight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c784d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\") # for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "mycutb = ROOT.TCut(\"\") # for example: TCut mycutb = \"abs(var1)<0.5\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e2cd3f",
   "metadata": {},
   "source": [
    "###  Tell the factory how to use the training and testing events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77065ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If no numbers of events are given, half of the events in the tree are used\n",
    "#  for training, and the other half for testing:\n",
    "#     loader.PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "#  It is possible also to specify the number of training and testing events,\n",
    "#  note we disable the computation of the correlation matrix of the input variables\n",
    "\n",
    "nTrainSig = 0.8 * nEventsSig\n",
    "nTrainBkg = 0.8 * nEventsBkg\n",
    "\n",
    "#  build the string options for DataLoader::PrepareTrainingAndTestTree\n",
    "prepareOptions = \"nTrain_Signal=\"+str(nTrainSig)+\":nTrain_Background=\"+str(nTrainBkg)+\":SplitMode=Random:SplitSeed=100:NormMode=NumEvents:!V:!CalcCorrelations\"\n",
    "  \n",
    "loader.PrepareTrainingAndTestTree(mycuts, mycutb, prepareOptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d357a24",
   "metadata": {},
   "source": [
    "### Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Boosted Decision Tree method (BDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e01b5f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "                         : Rebuilding Dataset dataset\n",
      "                         : Building event vectors for type 2 Signal\n",
      "                         : Dataset[dataset] :  create input formulas for tree sig_tree\n",
      "                         : Using variable vars[0] from array expression vars of size 256\n",
      "                         : Building event vectors for type 2 Background\n",
      "                         : Dataset[dataset] :  create input formulas for tree bkg_tree\n",
      "                         : Using variable vars[0] from array expression vars of size 256\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 4000\n",
      "                         : Signal     -- testing events             : 1000\n",
      "                         : Signal     -- training and testing events: 5000\n",
      "                         : Background -- training events            : 4000\n",
      "                         : Background -- testing events             : 1000\n",
      "                         : Background -- training and testing events: 5000\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Boosted Decision Trees\n",
    "if (useTMVABDT):\n",
    "  factory.BookMethod(loader, ROOT.TMVA.Types.kBDT, \"BDT\",\"!V:NTrees=400:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:\"+\"UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd109b34",
   "metadata": {},
   "source": [
    "   ### Booking Deep Neural Network\n",
    "\n",
    "   Here we define the option string for building the Deep Neural network model.\n",
    "\n",
    "   #### 1. Define DNN layout\n",
    "\n",
    "   The DNN configuration is defined using a string. Note that whitespaces between characters are not allowed.\n",
    "\n",
    "   We define first the DNN layout:\n",
    "\n",
    "   - **input layout** :   this defines the input data format for the DNN as  ``input depth | height | width``.\n",
    "      In case of a dense layer as first layer the input layout should be  ``1 | 1 | number of input variables`` (features)\n",
    "   - **batch layout**  : this defines how are the input batch. It is related to input layout but not the same.\n",
    "      If the first layer is dense it should be ``1 | batch size ! number of variables`` (features)\n",
    "\n",
    "      *(note the use of the character `|` as  separator of  input parameters for DNN layout)*\n",
    "\n",
    "   note that in case of only dense layer the input layout could be omitted but it is required when defining more\n",
    "   complex architectures\n",
    "\n",
    "   - **layer layout** string defining the layer architecture. The syntax is\n",
    "      - layer type (e.g. DENSE, CONV, RNN)\n",
    "      - layer parameters (e.g. number of units)\n",
    "      - activation function (e.g  TANH, RELU,...)\n",
    "\n",
    "      *the different layers are separated by the ``\",\"`` *\n",
    "\n",
    "   #### 2. Define Training Strategy\n",
    "\n",
    "   We define here the training strategy parameters for the DNN. The parameters are separated by the ``\",\"`` separator.\n",
    "   One can then concatenate different training strategy with different parameters. The training strategy are separated by\n",
    "   the ``\"|\"`` separator.\n",
    "\n",
    "   - Optimizer\n",
    "   - Learning rate\n",
    "   - Momentum (valid for SGD and RMSPROP)\n",
    "   - Regularization and Weight Decay\n",
    "   - Dropout\n",
    "   - Max number of epochs\n",
    "   - Convergence steps. if the test error will not decrease after that value the training will stop\n",
    "   - Batch size (This value must be the same specified in the input layout)\n",
    "   - Test Repetitions (the interval when the test error will be computed)\n",
    "\n",
    "\n",
    "   #### 3. Define general DNN options\n",
    "\n",
    "   We define the general DNN options concatenating in the final string the previously defined layout and training strategy.\n",
    "   Note we use the ``\":\"`` separator to separate the different higher level options, as in the other TMVA methods.\n",
    "   In addition to input layout, batch layout and training strategy we add now:\n",
    "\n",
    "   - Type of Loss function (e.g. CROSSENTROPY)\n",
    "   - Weight Initizalization (e.g XAVIER, XAVIERUNIFORM, NORMAL )\n",
    "   - Variable Transformation\n",
    "   - Type of Architecture (e.g. CPU, GPU, Standard)\n",
    "\n",
    "   We can then book the DL method using the built option string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eeba66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.MethodDL object at 0x93c9520>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mTMVA_DNN_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIER:Layout=DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIER:Layout=DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     Layout: \"DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIER\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     InputLayout: \"0|0|0\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n"
     ]
    }
   ],
   "source": [
    "# Define the DNN layout\n",
    "if (useTMVADNN):\n",
    "  layoutString = \"Layout=DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,BNORM,DENSE|100|RELU,DENSE|1|LINEAR\"\n",
    "\n",
    "  #  Training strategies\n",
    "  #  one can catenate several training strings with different parameters (e.g. learning rates or regularizations\n",
    "  #  parameters) The training string must be concatenates with the `|` delimiter\n",
    "  trainingString1 = \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"+ \"ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,\"+\"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"+\"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\"\n",
    "                          \n",
    "\n",
    "  trainingStrategyString = \"TrainingStrategy=\"\n",
    "  trainingStrategyString += trainingString1 # + \"|\" + trainingString2 + ....\n",
    "\n",
    "  # Build now the full DNN Option string\n",
    "\n",
    "  dnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"+\"WeightInitialization=XAVIER\"\n",
    "  dnnOptions+= \":\"\n",
    "  dnnOptions+= layoutString\n",
    "  dnnOptions+= \":\"\n",
    "  dnnOptions+= trainingStrategyString\n",
    "\n",
    "  dnnMethodName = \"TMVA_DNN_CPU\"\n",
    "\n",
    "  dnnOptions += \":Architecture=CPU\"\n",
    "\n",
    "\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kDL, dnnMethodName, dnnOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f54f2e",
   "metadata": {},
   "source": [
    "\n",
    "### Book Convolutional Neural Network in TMVA\n",
    "\n",
    "For building a CNN one needs to define\n",
    "\n",
    "-  Input Layout :  number of channels (in this case = 1)  | image height | image width\n",
    "-  Batch Layout :  batch size | number of channels | image size = (height*width)\n",
    "\n",
    "Then one add Convolutional layers and MaxPool layers.\n",
    "\n",
    "-  For Convolutional layer the option string has to be:\n",
    "   - CONV | number of units | filter height | filter width | stride height | stride width | padding height | paddig\n",
    "width | activation function\n",
    "\n",
    "   - note in this case we are using a filer 3x3 and padding=1 and stride=1 so we get the output dimension of the\n",
    "conv layer equal to the input\n",
    "\n",
    "  - note we use after the first convolutional layer a batch normalization layer. This seems to help significantly the\n",
    "convergence\n",
    "\n",
    " - For the MaxPool layer:\n",
    "    - MAXPOOL  | pool height | pool width | stride height | stride width\n",
    "\n",
    "The RESHAPE layer is needed to flatten the output before the Dense layer\n",
    "\n",
    "\n",
    "Note that to run the CNN is required to have CPU  or GPU support\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc50dc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.MethodDL object at 0x958f740>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mTMVA_CNN_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIER::Architecture=CPU:InputLayout=1|16|16:Layout=CONV|10|3|3|1|1|1|1|RELU,BNORM,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|100|RELU,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIER::Architecture=CPU:InputLayout=1|16|16:Layout=CONV|10|3|3|1|1|1|1|RELU,BNORM,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|100|RELU,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "<WARNING>                : Value for option architecture was previously set to CPU\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|16|16\" [The Layout of the input]\n",
      "                         :     Layout: \"CONV|10|3|3|1|1|1|1|RELU,BNORM,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|100|RELU,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIER\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n"
     ]
    }
   ],
   "source": [
    "inputLayoutString =\"InputLayout=1|16|16\"\n",
    "\n",
    "#  Batch Layout\n",
    "layoutString = \"Layout=CONV|10|3|3|1|1|1|1|RELU,BNORM,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,\"+\"RESHAPE|FLAT,DENSE|100|RELU,DENSE|1|LINEAR\"\n",
    "\n",
    "#  Training strategies.\n",
    "trainingString1 = \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"+\"ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,\"+\"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"+\"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\"\n",
    "\n",
    "trainingStrategyString = \"TrainingStrategy=\"\n",
    "trainingStrategyString += trainingString1 # + \"|\" + trainingString2 + \"|\" + trainingString3; for concatenating more training strings\n",
    "\n",
    "# Build full CNN Options.\n",
    "\n",
    "\n",
    "cnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\" +\"WeightInitialization=XAVIER::Architecture=CPU\"\n",
    "\n",
    "cnnOptions +=  \":\" + inputLayoutString\n",
    "cnnOptions +=  \":\" + layoutString\n",
    "cnnOptions +=  \":\" + trainingStrategyString\n",
    "  ## New DL (CNN)\n",
    "cnnMethodName = \"TMVA_CNN_CPU\"\n",
    "# use GPU if available\n",
    "\n",
    "\n",
    "cnnOptions += \":Architecture=CPU\"\n",
    "cnnMethodName = \"TMVA_CNN_CPU\"\n",
    "\n",
    "\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kDL, cnnMethodName, cnnOptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7156e46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 16, 16, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 10)        100       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 10)        910       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 10)       40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 10)        910       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 10)       40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2250)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               576256    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 578,770\n",
      "Trainable params: 578,730\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.MethodPyKeras object at 0xce22380>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mPyKeras\u001b[0m\n",
      "                         : \n",
      "                         : Setting up keras with tensorflow backend\n",
      "                         : Using Keras version 2.8\n",
      "                         : Using TensorFlow version 2\n",
      "<WARNING>                : The Keras version is not compatible with TensorFlow 2. Use instead tf.keras\n",
      "                         : Use Keras version from TensorFlow : tf.keras\n",
      "                         :  Loading Keras Model \n",
      "                         : Loaded model from file: model_cnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TMVA_CNN_Classification>: Building convolutional keras model\n",
      "2022-04-08 18:57:04.587935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/neel/Root/install/lib:/opt/ros/noetic/lib\n",
      "2022-04-08 18:57:04.587961: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-08 18:57:26.059026: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/neel/Root/install/lib:/opt/ros/noetic/lib\n",
      "2022-04-08 18:57:26.059050: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-08 18:57:26.059072: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (neel-HP-Pavilion-15-Notebook-PC): /proc/driver/nvidia/version does not exist\n",
      "2022-04-08 18:57:26.059307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Info in <TMVA_CNN_Classification>: Booking tf.Keras CNN model\n"
     ]
    }
   ],
   "source": [
    "ROOT.Info(\"TMVA_CNN_Classification\", \"Building convolutional keras model\")\n",
    "#  create python script which can be executed\n",
    "#  create 2 conv2d layer + maxpool + dense\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((16, 16, 1), input_shape = (256, )))\n",
    "model.add(Conv2D(10, kernel_size=(3,3), kernel_initializer='TruncatedNormal', activation='relu', padding='same' ) )\n",
    "model.add(Conv2D(10, kernel_size=(3,3), kernel_initializer='glorot_normal', activation ='relu', padding = 'same') )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(10, kernel_size = (3,3), kernel_initializer = 'glorot_normal',activation ='relu', padding = 'same') )\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (1,1))) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu')) \n",
    "model.add(Dense(2, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model.save('model_cnn.h5')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "if (ROOT.gSystem.AccessPathName(\"model_cnn.h5\")):\n",
    " Warning(\"TMVA_CNN_Classification\", \"Error creating Keras model file - skip using Keras\")\n",
    "else:\n",
    " #  book PyKeras method only if Keras model could be created\n",
    " ROOT.Info(\"TMVA_CNN_Classification\", \"Booking tf.Keras CNN model\")\n",
    "\n",
    "\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyKeras, \"PyKeras\",\"H:!V:VarTransform=None:FilenameModel=model_cnn.h5:\"+\"FilenameTrainedModel=trained_model_cnn.h5:NumEpochs=20:BatchSize=128\")\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1c1e9",
   "metadata": {},
   "source": [
    "### Training All Methods\n",
    "\n",
    "Here we train all the previously booked methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8508c0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 16, 16, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 10)        100       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 10)        910       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 10)       40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 10)        910       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 10)       40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2250)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               576256    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 578,770\n",
      "Trainable params: 578,730\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.8329 - accuracy: 0.5577\n",
      "Epoch 1: val_loss improved from inf to 0.68131, saving model to trained_model_cnn.h5\n",
      "50/50 [==============================] - 7s 81ms/step - loss: 0.8329 - accuracy: 0.5577 - val_loss: 0.6813 - val_accuracy: 0.5906\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6856\n",
      "Epoch 2: val_loss did not improve from 0.68131\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 0.6203 - accuracy: 0.6856 - val_loss: 0.7122 - val_accuracy: 0.5156\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7577\n",
      "Epoch 3: val_loss did not improve from 0.68131\n",
      "50/50 [==============================] - 3s 68ms/step - loss: 0.5185 - accuracy: 0.7577 - val_loss: 1.3789 - val_accuracy: 0.5044\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4581 - accuracy: 0.7809\n",
      "Epoch 4: val_loss did not improve from 0.68131\n",
      "50/50 [==============================] - 4s 74ms/step - loss: 0.4581 - accuracy: 0.7809 - val_loss: 0.7194 - val_accuracy: 0.6544\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8180\n",
      "Epoch 5: val_loss did not improve from 0.68131\n",
      "50/50 [==============================] - 4s 71ms/step - loss: 0.3995 - accuracy: 0.8180 - val_loss: 1.6846 - val_accuracy: 0.5231\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.8378\n",
      "Epoch 6: val_loss did not improve from 0.68131\n",
      "50/50 [==============================] - 4s 71ms/step - loss: 0.3683 - accuracy: 0.8378 - val_loss: 1.0507 - val_accuracy: 0.5944\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8391\n",
      "Epoch 7: val_loss improved from 0.68131 to 0.47955, saving model to trained_model_cnn.h5\n",
      "50/50 [==============================] - 5s 102ms/step - loss: 0.3593 - accuracy: 0.8391 - val_loss: 0.4796 - val_accuracy: 0.7681\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.8480\n",
      "Epoch 8: val_loss did not improve from 0.47955\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3414 - accuracy: 0.8480 - val_loss: 1.4155 - val_accuracy: 0.5681\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.8380\n",
      "Epoch 9: val_loss did not improve from 0.47955\n",
      "50/50 [==============================] - 4s 78ms/step - loss: 0.3638 - accuracy: 0.8380 - val_loss: 0.7336 - val_accuracy: 0.6875\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8597\n",
      "Epoch 10: val_loss improved from 0.47955 to 0.43003, saving model to trained_model_cnn.h5\n",
      "50/50 [==============================] - 4s 76ms/step - loss: 0.3151 - accuracy: 0.8597 - val_loss: 0.4300 - val_accuracy: 0.8094\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8547\n",
      "Epoch 11: val_loss did not improve from 0.43003\n",
      "50/50 [==============================] - 3s 64ms/step - loss: 0.3309 - accuracy: 0.8547 - val_loss: 1.0142 - val_accuracy: 0.6288\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8580\n",
      "Epoch 12: val_loss did not improve from 0.43003\n",
      "50/50 [==============================] - 3s 65ms/step - loss: 0.3198 - accuracy: 0.8580 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8711\n",
      "Epoch 13: val_loss did not improve from 0.43003\n",
      "50/50 [==============================] - 3s 70ms/step - loss: 0.2974 - accuracy: 0.8711 - val_loss: 0.7635 - val_accuracy: 0.6963\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.8831\n",
      "Epoch 14: val_loss improved from 0.43003 to 0.38999, saving model to trained_model_cnn.h5\n",
      "50/50 [==============================] - 4s 72ms/step - loss: 0.2703 - accuracy: 0.8831 - val_loss: 0.3900 - val_accuracy: 0.8275\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.8872\n",
      "Epoch 15: val_loss did not improve from 0.38999\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 0.2635 - accuracy: 0.8872 - val_loss: 2.3276 - val_accuracy: 0.5269\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.8772\n",
      "Epoch 16: val_loss did not improve from 0.38999\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.2859 - accuracy: 0.8772 - val_loss: 0.7286 - val_accuracy: 0.7169\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8777\n",
      "Epoch 17: val_loss did not improve from 0.38999\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 0.2798 - accuracy: 0.8777 - val_loss: 1.0994 - val_accuracy: 0.6231\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.8856\n",
      "Epoch 18: val_loss did not improve from 0.38999\n",
      "50/50 [==============================] - 3s 68ms/step - loss: 0.2581 - accuracy: 0.8856 - val_loss: 2.0596 - val_accuracy: 0.5337\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.8908\n",
      "Epoch 19: val_loss did not improve from 0.38999\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 0.2573 - accuracy: 0.8908 - val_loss: 0.6794 - val_accuracy: 0.7356\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9041\n",
      "Epoch 20: val_loss did not improve from 0.38999\n",
      "50/50 [==============================] - 4s 75ms/step - loss: 0.2341 - accuracy: 0.9041 - val_loss: 0.4613 - val_accuracy: 0.8062\n",
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 4000 bkg: 4000\n",
      "                         : #events: (unweighted) sig: 4000 bkg: 4000\n",
      "                         : Training 400 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 8000 events: 38.6 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (8000 events)\n",
      "                         : Elapsed time for evaluation of 8000 events: 0.184 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.class.C\u001b[0m\n",
      "                         : CNN_ClassificationOutput.root:/dataset/Method_BDT/BDT\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: TMVA_DNN_CPU for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 8  Input = ( 1, 1, 256 )  Batch size = 100  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =   256 , Width =   100 ) \tOutput = (  1 ,   100 ,   100 ) \t Activation Function = Relu\n",
      "\tLayer 1\t BATCH NORM Layer: \t Input/Output = ( 100 , 100 , 1 ) \t Norm dim =   100\t axis = -1\n",
      "\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =   100 , Width =   100 ) \tOutput = (  1 ,   100 ,   100 ) \t Activation Function = Relu\n",
      "\tLayer 3\t BATCH NORM Layer: \t Input/Output = ( 100 , 100 , 1 ) \t Norm dim =   100\t axis = -1\n",
      "\n",
      "\tLayer 4\t DENSE Layer: \t ( Input =   100 , Width =   100 ) \tOutput = (  1 ,   100 ,   100 ) \t Activation Function = Relu\n",
      "\tLayer 5\t BATCH NORM Layer: \t Input/Output = ( 100 , 100 , 1 ) \t Norm dim =   100\t axis = -1\n",
      "\n",
      "\tLayer 6\t DENSE Layer: \t ( Input =   100 , Width =   100 ) \tOutput = (  1 ,   100 ,   100 ) \t Activation Function = Relu\n",
      "\tLayer 7\t DENSE Layer: \t ( Input =   100 , Width =     1 ) \tOutput = (  1 ,   100 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 6400 events for training and 1600 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = inf\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.762376    0.710329    0.110278  0.00792724     62530.1           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.576386    0.646887    0.109426  0.00814817     63192.3           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.474607    0.515689    0.108718  0.00773804     63378.8           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.401628    0.482584    0.109925  0.00776043       62644           0\n",
      "                         :          5 |     0.373448    0.665741    0.108361  0.00718455     63256.1           1\n",
      "                         :          6 |     0.341886    0.503835    0.108254   0.0071802     63320.3           2\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.332368    0.477023    0.108968  0.00777844     63247.6           0\n",
      "                         :          8 |     0.310903    0.486312    0.121473  0.00725451       56033           1\n",
      "                         :          9 |     0.286745    0.537939     0.11006  0.00729522       62278           2\n",
      "                         :         10 |     0.268336    0.551437    0.134807    0.012189     52194.8           3\n",
      "                         :         11 |     0.257688    0.843186    0.147587  0.00883718     46126.2           4\n",
      "                         :         12 |     0.258812    0.536013    0.129464  0.00748011     52466.1           5\n",
      "                         :         13 |     0.248315    0.735833    0.151241  0.00744406     44507.3           6\n",
      "                         : \n",
      "                         : Elapsed time for training with 8000 events: 1.67 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 100\n",
      "                         : \n",
      "TMVA_DNN_CPU             : [dataset] : Evaluation of TMVA_DNN_CPU on training sample (8000 events)\n",
      "                         : Elapsed time for evaluation of 8000 events: 0.036 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_TMVA_DNN_CPU.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_TMVA_DNN_CPU.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: TMVA_CNN_CPU for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 7  Input = ( 1, 16, 16 )  Batch size = 100  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 16 ,  H = 16 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 100 , 10 , 10 , 256 ) \t Activation Function = Relu\n",
      "\tLayer 1\t BATCH NORM Layer: \t Input/Output = ( 10 , 256 , 100 ) \t Norm dim =    10\t axis = 1\n",
      "\n",
      "\tLayer 2\t CONV LAYER: \t( W = 16 ,  H = 16 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 100 , 10 , 10 , 256 ) \t Activation Function = Relu\n",
      "\tLayer 3\t POOL Layer: \t( W = 15 ,  H = 15 ,  D = 10 ) \t Filter ( W = 2 ,  H = 2 ) \tOutput = ( 100 , 10 , 10 , 225 ) \n",
      "\tLayer 4\t RESHAPE Layer \t Input = ( 10 , 15 , 15 ) \tOutput = ( 1 , 100 , 2250 ) \n",
      "\tLayer 5\t DENSE Layer: \t ( Input =  2250 , Width =   100 ) \tOutput = (  1 ,   100 ,   100 ) \t Activation Function = Relu\n",
      "\tLayer 6\t DENSE Layer: \t ( Input =   100 , Width =     1 ) \tOutput = (  1 ,   100 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 6400 events for training and 1600 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = inf\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |          inf    0.683806     3.37058    0.331433     2105.86           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |      0.65702    0.633252     3.36268    0.359108      2130.8           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.626393    0.591214     3.39649    0.328801     2086.26           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |      0.58023    0.564719     3.24142    0.335217     2202.19           0\n",
      "                         :          5 |     0.535329     0.66134     3.31306    0.326815     2143.16           1\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.499821    0.466968     3.20758    0.327787     2222.38           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.437513    0.431699     3.21899    0.334568     2218.81           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.452327    0.418405     3.23471    0.329677     2203.07           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.425982    0.417664     3.35681    0.329626     2114.18           0\n",
      "                         :         10 |     0.416009    0.443992     3.23672    0.330186     2201.94           1\n",
      "                         :         11 |     0.389055    0.433964     3.34883    0.328133     2118.72           2\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.407204    0.399531     4.20538    0.330403     1651.62           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.372033     0.39884     4.69159    0.329631     1467.23           0\n",
      "                         :         14 |     0.382838    0.406279     4.56354    0.325847     1510.26           1\n",
      "                         :         15 |     0.362229    0.489942     4.28627    0.329609     1617.52           2\n",
      "                         :         16 |     0.356345    0.404693     4.28697    0.327209     1616.26           3\n",
      "                         :         17 Minimum Test error found - save the configuration \n",
      "                         :         17 |     0.349092    0.396691     4.30075    0.332798     1612.92           0\n",
      "                         :         18 |     0.352824    0.425804     4.59922    0.328377     1498.53           1\n",
      "                         :         19 Minimum Test error found - save the configuration \n",
      "                         :         19 |     0.349202    0.389224     4.38256    0.328734     1578.75           0\n",
      "                         :         20 |      0.32613    0.418388     4.27834    0.329569     1620.76           1\n",
      "                         : \n",
      "                         : Elapsed time for training with 8000 events: 76.3 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 100\n",
      "                         : \n",
      "TMVA_CNN_CPU             : [dataset] : Evaluation of TMVA_CNN_CPU on training sample (8000 events)\n",
      "                         : Elapsed time for evaluation of 8000 events: 1.76 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_TMVA_CNN_CPU.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_TMVA_CNN_CPU.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: PyKeras for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :\u001b[0m\n",
      "                         : \n",
      "                         : Keras is a high-level API for the Theano and Tensorflow packages.\n",
      "                         : This method wraps the training and predictions steps of the Keras\n",
      "                         : Python package for TMVA, so that dataloading, preprocessing and\n",
      "                         : evaluation can be done within the TMVA system. To use this Keras\n",
      "                         : interface, you have to generate a model with Keras first. Then,\n",
      "                         : this model can be loaded and trained in TMVA.\n",
      "                         : \n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Split TMVA training data in 6400 training events and 1600 validation events\n",
      "                         : Training Model Summary\n",
      "                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored\n",
      "                         : Getting training history for item:0 name = 'loss'\n",
      "                         : Getting training history for item:1 name = 'accuracy'\n",
      "                         : Getting training history for item:2 name = 'val_loss'\n",
      "                         : Getting training history for item:3 name = 'val_accuracy'\n",
      "                         : Elapsed time for training with 8000 events: 77.3 sec         \n",
      "PyKeras                  : [dataset] : Evaluation of PyKeras on training sample (8000 events)\n",
      "                         : Elapsed time for evaluation of 8000 events: 2.2 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_PyKeras.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_PyKeras.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : --------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : --------------------------------------\n",
      "                         :    1 : vars      : 1.079e-02\n",
      "                         :    2 : vars      : 1.077e-02\n",
      "                         :    3 : vars      : 1.077e-02\n",
      "                         :    4 : vars      : 1.031e-02\n",
      "                         :    5 : vars      : 1.010e-02\n",
      "                         :    6 : vars      : 9.967e-03\n",
      "                         :    7 : vars      : 9.801e-03\n",
      "                         :    8 : vars      : 9.606e-03\n",
      "                         :    9 : vars      : 9.556e-03\n",
      "                         :   10 : vars      : 9.483e-03\n",
      "                         :   11 : vars      : 9.400e-03\n",
      "                         :   12 : vars      : 9.259e-03\n",
      "                         :   13 : vars      : 9.120e-03\n",
      "                         :   14 : vars      : 8.942e-03\n",
      "                         :   15 : vars      : 8.721e-03\n",
      "                         :   16 : vars      : 8.582e-03\n",
      "                         :   17 : vars      : 8.564e-03\n",
      "                         :   18 : vars      : 8.561e-03\n",
      "                         :   19 : vars      : 8.274e-03\n",
      "                         :   20 : vars      : 8.127e-03\n",
      "                         :   21 : vars      : 8.117e-03\n",
      "                         :   22 : vars      : 8.018e-03\n",
      "                         :   23 : vars      : 7.925e-03\n",
      "                         :   24 : vars      : 7.826e-03\n",
      "                         :   25 : vars      : 7.824e-03\n",
      "                         :   26 : vars      : 7.820e-03\n",
      "                         :   27 : vars      : 7.802e-03\n",
      "                         :   28 : vars      : 7.574e-03\n",
      "                         :   29 : vars      : 7.556e-03\n",
      "                         :   30 : vars      : 7.445e-03\n",
      "                         :   31 : vars      : 7.441e-03\n",
      "                         :   32 : vars      : 7.410e-03\n",
      "                         :   33 : vars      : 7.405e-03\n",
      "                         :   34 : vars      : 7.317e-03\n",
      "                         :   35 : vars      : 7.241e-03\n",
      "                         :   36 : vars      : 7.152e-03\n",
      "                         :   37 : vars      : 7.134e-03\n",
      "                         :   38 : vars      : 7.086e-03\n",
      "                         :   39 : vars      : 7.069e-03\n",
      "                         :   40 : vars      : 7.066e-03\n",
      "                         :   41 : vars      : 7.065e-03\n",
      "                         :   42 : vars      : 7.044e-03\n",
      "                         :   43 : vars      : 6.965e-03\n",
      "                         :   44 : vars      : 6.954e-03\n",
      "                         :   45 : vars      : 6.879e-03\n",
      "                         :   46 : vars      : 6.874e-03\n",
      "                         :   47 : vars      : 6.861e-03\n",
      "                         :   48 : vars      : 6.773e-03\n",
      "                         :   49 : vars      : 6.693e-03\n",
      "                         :   50 : vars      : 6.628e-03\n",
      "                         :   51 : vars      : 6.549e-03\n",
      "                         :   52 : vars      : 6.483e-03\n",
      "                         :   53 : vars      : 6.441e-03\n",
      "                         :   54 : vars      : 6.426e-03\n",
      "                         :   55 : vars      : 6.390e-03\n",
      "                         :   56 : vars      : 6.386e-03\n",
      "                         :   57 : vars      : 6.384e-03\n",
      "                         :   58 : vars      : 6.300e-03\n",
      "                         :   59 : vars      : 6.289e-03\n",
      "                         :   60 : vars      : 6.260e-03\n",
      "                         :   61 : vars      : 6.257e-03\n",
      "                         :   62 : vars      : 6.202e-03\n",
      "                         :   63 : vars      : 6.169e-03\n",
      "                         :   64 : vars      : 6.147e-03\n",
      "                         :   65 : vars      : 6.131e-03\n",
      "                         :   66 : vars      : 6.004e-03\n",
      "                         :   67 : vars      : 5.977e-03\n",
      "                         :   68 : vars      : 5.937e-03\n",
      "                         :   69 : vars      : 5.893e-03\n",
      "                         :   70 : vars      : 5.879e-03\n",
      "                         :   71 : vars      : 5.876e-03\n",
      "                         :   72 : vars      : 5.869e-03\n",
      "                         :   73 : vars      : 5.846e-03\n",
      "                         :   74 : vars      : 5.831e-03\n",
      "                         :   75 : vars      : 5.768e-03\n",
      "                         :   76 : vars      : 5.688e-03\n",
      "                         :   77 : vars      : 5.674e-03\n",
      "                         :   78 : vars      : 5.650e-03\n",
      "                         :   79 : vars      : 5.637e-03\n",
      "                         :   80 : vars      : 5.623e-03\n",
      "                         :   81 : vars      : 5.520e-03\n",
      "                         :   82 : vars      : 5.405e-03\n",
      "                         :   83 : vars      : 5.387e-03\n",
      "                         :   84 : vars      : 5.349e-03\n",
      "                         :   85 : vars      : 5.211e-03\n",
      "                         :   86 : vars      : 5.149e-03\n",
      "                         :   87 : vars      : 5.041e-03\n",
      "                         :   88 : vars      : 5.008e-03\n",
      "                         :   89 : vars      : 4.950e-03\n",
      "                         :   90 : vars      : 4.939e-03\n",
      "                         :   91 : vars      : 4.923e-03\n",
      "                         :   92 : vars      : 4.825e-03\n",
      "                         :   93 : vars      : 4.812e-03\n",
      "                         :   94 : vars      : 4.753e-03\n",
      "                         :   95 : vars      : 4.737e-03\n",
      "                         :   96 : vars      : 4.712e-03\n",
      "                         :   97 : vars      : 4.642e-03\n",
      "                         :   98 : vars      : 4.637e-03\n",
      "                         :   99 : vars      : 4.583e-03\n",
      "                         :  100 : vars      : 4.551e-03\n",
      "                         :  101 : vars      : 4.458e-03\n",
      "                         :  102 : vars      : 4.433e-03\n",
      "                         :  103 : vars      : 4.397e-03\n",
      "                         :  104 : vars      : 4.329e-03\n",
      "                         :  105 : vars      : 4.308e-03\n",
      "                         :  106 : vars      : 4.295e-03\n",
      "                         :  107 : vars      : 4.277e-03\n",
      "                         :  108 : vars      : 4.270e-03\n",
      "                         :  109 : vars      : 4.199e-03\n",
      "                         :  110 : vars      : 4.192e-03\n",
      "                         :  111 : vars      : 4.167e-03\n",
      "                         :  112 : vars      : 4.148e-03\n",
      "                         :  113 : vars      : 4.140e-03\n",
      "                         :  114 : vars      : 4.131e-03\n",
      "                         :  115 : vars      : 4.130e-03\n",
      "                         :  116 : vars      : 4.102e-03\n",
      "                         :  117 : vars      : 4.101e-03\n",
      "                         :  118 : vars      : 3.989e-03\n",
      "                         :  119 : vars      : 3.973e-03\n",
      "                         :  120 : vars      : 3.939e-03\n",
      "                         :  121 : vars      : 3.855e-03\n",
      "                         :  122 : vars      : 3.816e-03\n",
      "                         :  123 : vars      : 3.803e-03\n",
      "                         :  124 : vars      : 3.778e-03\n",
      "                         :  125 : vars      : 3.744e-03\n",
      "                         :  126 : vars      : 3.687e-03\n",
      "                         :  127 : vars      : 3.677e-03\n",
      "                         :  128 : vars      : 3.674e-03\n",
      "                         :  129 : vars      : 3.654e-03\n",
      "                         :  130 : vars      : 3.583e-03\n",
      "                         :  131 : vars      : 3.573e-03\n",
      "                         :  132 : vars      : 3.560e-03\n",
      "                         :  133 : vars      : 3.553e-03\n",
      "                         :  134 : vars      : 3.544e-03\n",
      "                         :  135 : vars      : 3.465e-03\n",
      "                         :  136 : vars      : 3.465e-03\n",
      "                         :  137 : vars      : 3.436e-03\n",
      "                         :  138 : vars      : 3.432e-03\n",
      "                         :  139 : vars      : 3.364e-03\n",
      "                         :  140 : vars      : 3.331e-03\n",
      "                         :  141 : vars      : 3.321e-03\n",
      "                         :  142 : vars      : 3.277e-03\n",
      "                         :  143 : vars      : 3.250e-03\n",
      "                         :  144 : vars      : 3.248e-03\n",
      "                         :  145 : vars      : 3.205e-03\n",
      "                         :  146 : vars      : 3.172e-03\n",
      "                         :  147 : vars      : 3.153e-03\n",
      "                         :  148 : vars      : 3.135e-03\n",
      "                         :  149 : vars      : 3.095e-03\n",
      "                         :  150 : vars      : 3.092e-03\n",
      "                         :  151 : vars      : 3.086e-03\n",
      "                         :  152 : vars      : 3.044e-03\n",
      "                         :  153 : vars      : 3.020e-03\n",
      "                         :  154 : vars      : 2.984e-03\n",
      "                         :  155 : vars      : 2.967e-03\n",
      "                         :  156 : vars      : 2.928e-03\n",
      "                         :  157 : vars      : 2.881e-03\n",
      "                         :  158 : vars      : 2.876e-03\n",
      "                         :  159 : vars      : 2.819e-03\n",
      "                         :  160 : vars      : 2.811e-03\n",
      "                         :  161 : vars      : 2.782e-03\n",
      "                         :  162 : vars      : 2.757e-03\n",
      "                         :  163 : vars      : 2.696e-03\n",
      "                         :  164 : vars      : 2.690e-03\n",
      "                         :  165 : vars      : 2.606e-03\n",
      "                         :  166 : vars      : 2.598e-03\n",
      "                         :  167 : vars      : 2.554e-03\n",
      "                         :  168 : vars      : 2.548e-03\n",
      "                         :  169 : vars      : 2.543e-03\n",
      "                         :  170 : vars      : 2.500e-03\n",
      "                         :  171 : vars      : 2.491e-03\n",
      "                         :  172 : vars      : 2.484e-03\n",
      "                         :  173 : vars      : 2.456e-03\n",
      "                         :  174 : vars      : 2.424e-03\n",
      "                         :  175 : vars      : 2.383e-03\n",
      "                         :  176 : vars      : 2.349e-03\n",
      "                         :  177 : vars      : 2.266e-03\n",
      "                         :  178 : vars      : 2.229e-03\n",
      "                         :  179 : vars      : 2.203e-03\n",
      "                         :  180 : vars      : 2.161e-03\n",
      "                         :  181 : vars      : 2.131e-03\n",
      "                         :  182 : vars      : 2.120e-03\n",
      "                         :  183 : vars      : 2.095e-03\n",
      "                         :  184 : vars      : 2.074e-03\n",
      "                         :  185 : vars      : 2.032e-03\n",
      "                         :  186 : vars      : 2.030e-03\n",
      "                         :  187 : vars      : 1.943e-03\n",
      "                         :  188 : vars      : 1.882e-03\n",
      "                         :  189 : vars      : 1.860e-03\n",
      "                         :  190 : vars      : 1.856e-03\n",
      "                         :  191 : vars      : 1.778e-03\n",
      "                         :  192 : vars      : 1.702e-03\n",
      "                         :  193 : vars      : 1.638e-03\n",
      "                         :  194 : vars      : 1.601e-03\n",
      "                         :  195 : vars      : 1.596e-03\n",
      "                         :  196 : vars      : 1.527e-03\n",
      "                         :  197 : vars      : 1.481e-03\n",
      "                         :  198 : vars      : 1.389e-03\n",
      "                         :  199 : vars      : 1.350e-03\n",
      "                         :  200 : vars      : 1.324e-03\n",
      "                         :  201 : vars      : 1.274e-03\n",
      "                         :  202 : vars      : 1.264e-03\n",
      "                         :  203 : vars      : 1.190e-03\n",
      "                         :  204 : vars      : 1.178e-03\n",
      "                         :  205 : vars      : 1.084e-03\n",
      "                         :  206 : vars      : 1.035e-03\n",
      "                         :  207 : vars      : 9.057e-04\n",
      "                         :  208 : vars      : 8.352e-04\n",
      "                         :  209 : vars      : 0.000e+00\n",
      "                         :  210 : vars      : 0.000e+00\n",
      "                         :  211 : vars      : 0.000e+00\n",
      "                         :  212 : vars      : 0.000e+00\n",
      "                         :  213 : vars      : 0.000e+00\n",
      "                         :  214 : vars      : 0.000e+00\n",
      "                         :  215 : vars      : 0.000e+00\n",
      "                         :  216 : vars      : 0.000e+00\n",
      "                         :  217 : vars      : 0.000e+00\n",
      "                         :  218 : vars      : 0.000e+00\n",
      "                         :  219 : vars      : 0.000e+00\n",
      "                         :  220 : vars      : 0.000e+00\n",
      "                         :  221 : vars      : 0.000e+00\n",
      "                         :  222 : vars      : 0.000e+00\n",
      "                         :  223 : vars      : 0.000e+00\n",
      "                         :  224 : vars      : 0.000e+00\n",
      "                         :  225 : vars      : 0.000e+00\n",
      "                         :  226 : vars      : 0.000e+00\n",
      "                         :  227 : vars      : 0.000e+00\n",
      "                         :  228 : vars      : 0.000e+00\n",
      "                         :  229 : vars      : 0.000e+00\n",
      "                         :  230 : vars      : 0.000e+00\n",
      "                         :  231 : vars      : 0.000e+00\n",
      "                         :  232 : vars      : 0.000e+00\n",
      "                         :  233 : vars      : 0.000e+00\n",
      "                         :  234 : vars      : 0.000e+00\n",
      "                         :  235 : vars      : 0.000e+00\n",
      "                         :  236 : vars      : 0.000e+00\n",
      "                         :  237 : vars      : 0.000e+00\n",
      "                         :  238 : vars      : 0.000e+00\n",
      "                         :  239 : vars      : 0.000e+00\n",
      "                         :  240 : vars      : 0.000e+00\n",
      "                         :  241 : vars      : 0.000e+00\n",
      "                         :  242 : vars      : 0.000e+00\n",
      "                         :  243 : vars      : 0.000e+00\n",
      "                         :  244 : vars      : 0.000e+00\n",
      "                         :  245 : vars      : 0.000e+00\n",
      "                         :  246 : vars      : 0.000e+00\n",
      "                         :  247 : vars      : 0.000e+00\n",
      "                         :  248 : vars      : 0.000e+00\n",
      "                         :  249 : vars      : 0.000e+00\n",
      "                         :  250 : vars      : 0.000e+00\n",
      "                         :  251 : vars      : 0.000e+00\n",
      "                         :  252 : vars      : 0.000e+00\n",
      "                         :  253 : vars      : 0.000e+00\n",
      "                         :  254 : vars      : 0.000e+00\n",
      "                         :  255 : vars      : 0.000e+00\n",
      "                         :  256 : vars      : 0.000e+00\n",
      "                         : --------------------------------------\n",
      "                         : No variable ranking supplied by classifier: TMVA_DNN_CPU\n",
      "                         : No variable ranking supplied by classifier: TMVA_CNN_CPU\n",
      "                         : No variable ranking supplied by classifier: PyKeras\n",
      "TH1.Print Name  = TrainingHistory_TMVA_DNN_CPU_trainingError, Entries= 0, Total sum= 4.8935\n",
      "TH1.Print Name  = TrainingHistory_TMVA_DNN_CPU_valError, Entries= 0, Total sum= 7.69281\n",
      "TH1.Print Name  = TrainingHistory_TMVA_CNN_CPU_trainingError, Entries= 0, Total sum= inf\n",
      "TH1.Print Name  = TrainingHistory_TMVA_CNN_CPU_valError, Entries= 0, Total sum= 9.47641\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'accuracy', Entries= 0, Total sum= 16.6117\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'loss', Entries= 0, Total sum= 7.37423\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'val_accuracy', Entries= 0, Total sum= 13.0625\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_'val_loss', Entries= 0, Total sum= 19.37\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_TMVA_DNN_CPU.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_TMVA_CNN_CPU.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_PyKeras.weights.xml\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%, time left: unknown\n",
      "6%, time left: 33 sec\n",
      "12%, time left: 31 sec\n",
      "19%, time left: 29 sec\n",
      "25%, time left: 26 sec\n",
      "31%, time left: 24 sec\n",
      "37%, time left: 22 sec\n",
      "44%, time left: 20 sec\n",
      "50%, time left: 18 sec\n",
      "56%, time left: 15 sec\n",
      "62%, time left: 13 sec\n",
      "69%, time left: 11 sec\n",
      "75%, time left: 9 sec\n",
      "81%, time left: 6 sec\n",
      "87%, time left: 4 sec\n",
      "94%, time left: 2 sec\n",
      "0%, time left: unknown\n",
      "7%, time left: 0 sec\n",
      "13%, time left: 0 sec\n",
      "19%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "32%, time left: 0 sec\n",
      "38%, time left: 0 sec\n",
      "44%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "57%, time left: 0 sec\n",
      "63%, time left: 0 sec\n",
      "69%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "82%, time left: 0 sec\n",
      "88%, time left: 0 sec\n",
      "94%, time left: 0 sec\n"
     ]
    }
   ],
   "source": [
    "#  ## Train Methods\n",
    "\n",
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa3301",
   "metadata": {},
   "source": [
    "### Test all methods\n",
    "\n",
    "Now we test  all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb38e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.0437 sec       \n",
      "Factory                  : Test method: TMVA_DNN_CPU for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TMVA_DNN_CPU             : [dataset] : Evaluation of TMVA_DNN_CPU on testing sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.0133 sec       \n",
      "Factory                  : Test method: TMVA_CNN_CPU for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TMVA_CNN_CPU             : [dataset] : Evaluation of TMVA_CNN_CPU on testing sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.619 sec       \n",
      "Factory                  : Test method: PyKeras for Classification performance\n",
      "                         : \n",
      "                         : Setting up tf.keras\n",
      "                         : Using TensorFlow version 2\n",
      "                         : Use Keras version from TensorFlow : tf.keras\n",
      "                         :  Loading Keras Model \n",
      "                         : Loaded model from file: trained_model_cnn.h5\n",
      "PyKeras                  : [dataset] : Evaluation of PyKeras on testing sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.618 sec       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%, time left: unknown\n",
      "7%, time left: 0 sec\n",
      "13%, time left: 0 sec\n",
      "19%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "32%, time left: 0 sec\n",
      "38%, time left: 0 sec\n",
      "44%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "57%, time left: 0 sec\n",
      "63%, time left: 0 sec\n",
      "69%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "82%, time left: 0 sec\n",
      "88%, time left: 0 sec\n",
      "94%, time left: 0 sec\n"
     ]
    }
   ],
   "source": [
    "## Test and Evaluate Methods\n",
    "\n",
    "factory.TestAllMethods()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884eff1a",
   "metadata": {},
   "source": [
    "### Evaluate all methods\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both training and tetsing data sets. Several histograms are produced which can be examined with the TMVAGui or directly using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd04e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 256 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: TMVA_DNN_CPU\n",
      "                         : \n",
      "TMVA_DNN_CPU             : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 256 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: TMVA_CNN_CPU\n",
      "                         : \n",
      "TMVA_CNN_CPU             : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 256 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: PyKeras\n",
      "                         : \n",
      "PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 256 , it is larger than 200\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       TMVA_CNN_CPU   : 0.915\n",
      "                         : dataset       PyKeras        : 0.915\n",
      "                         : dataset       TMVA_DNN_CPU   : 0.895\n",
      "                         : dataset       BDT            : 0.844\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              TMVA_CNN_CPU   : 0.265 (0.455)       0.747 (0.790)      0.922 (0.924)\n",
      "                         : dataset              PyKeras        : 0.355 (0.475)       0.752 (0.805)      0.919 (0.928)\n",
      "                         : dataset              TMVA_DNN_CPU   : 0.252 (0.360)       0.687 (0.749)      0.899 (0.924)\n",
      "                         : dataset              BDT            : 0.155 (0.297)       0.544 (0.647)      0.817 (0.861)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 2000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 8000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb15fd",
   "metadata": {},
   "source": [
    "### Plot ROC Curve\n",
    "Here we plot the ROC curve and display the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a1cedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot ROC Curve\n",
    "\n",
    "c1 = factory.GetROCCurve(loader)\n",
    "c1.Draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05eccb7",
   "metadata": {},
   "source": [
    "### Close the Output File\n",
    "Close outputfile to save all output information (evaluation result of methods) and it can be used by TMVAGUI to display additional plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a2b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close outputfile to save output file\n",
    "outputFile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b861cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
