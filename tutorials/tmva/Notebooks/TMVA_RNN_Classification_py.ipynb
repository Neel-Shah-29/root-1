{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b750ba9",
   "metadata": {},
   "source": [
    "#   TMVA Classification Example Using a Recurrent Neural Network\n",
    " \n",
    "This is an example of using a RNN in TMVA. We do classification using a toy time dependent data set\n",
    "that is generated when running this example macro.\n",
    "\n",
    "This is an example of using a RNN in TMVA. We do the classification using a toy data set containing a time series of data sample ntimes and with dimension ndim that is generated when running the provided function `MakeTimeData (nevents, ntime, ndim)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4093cd4",
   "metadata": {},
   "source": [
    "### Import the necessary modules\n",
    "\n",
    "We start with importing the necessary modules required for the tutorial. Here we imported ROOT and TMVA(Toolkit for Multivariate Data Analysis). If you want to know more about TMVA, you can refer the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af11d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8276e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ninput = 30\n",
    "# ninput=10\n",
    "ntime = 10\n",
    "# batchSize = 100\n",
    "batchSize = 100\n",
    "maxepochs = 20\n",
    "\n",
    "use_type = 1\n",
    "\n",
    "nTotEvts = 10000 # total events to be generated for signal or background\n",
    "\n",
    "useKeras = True\n",
    "\n",
    "\n",
    "useTMVA_RNN = True\n",
    "useTMVA_DNN = True\n",
    "useTMVA_BDT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc7e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn_types = [\"RNN\", \"LSTM\", \"GRU\"]\n",
    "use_rnn_type = [1, 1, 1]\n",
    "if (use_type >=0 & use_type < 3) :\n",
    "      use_rnn_type = [0,0,0]\n",
    "      use_rnn_type[use_type] = 1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936061e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "archString = \"CPU\"\n",
    "writeOutputFile = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1d1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_type = \"RNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae7a37",
   "metadata": {},
   "source": [
    "### Setting up TMVA\n",
    "\n",
    "TMVA requires initialization the PyMVA to utilize PyTorch. PyMVA is the interface for third-party MVA tools based on Python. It is created to make powerful external libraries easily accessible with a direct integration into the TMVA workflow. All PyMVA methods provide the same plug-and-play mechanisms as the TMVA methods. Because the base method of PyMVA is inherited from the TMVA base method, all options of internal TMVA methods apply for PyMVA methods as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06612027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.TMVA.Tools.Instance()\n",
    "ROOT.TMVA.PyMethodBase.PyInitialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b40031",
   "metadata": {},
   "source": [
    "### Define the input files and the number of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f588b1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with nthreads  = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_threads = 0   # use by default all threads\n",
    "#    do enable MT running\n",
    "if (num_threads >= 0):\n",
    "    ROOT.EnableImplicitMT(num_threads)\n",
    "    if (num_threads > 0):\n",
    "        ROOT.gSystem.Setenv(\"OMP_NUM_THREADS\", num_threads)\n",
    "    else:\n",
    "      ROOT.gSystem.Setenv(\"OMP_NUM_THREADS\", \"1\")\n",
    "\n",
    "\n",
    "print(\"Running with nthreads  = \" + str(ROOT.GetThreadPoolSize()) + \"\\n\" )\n",
    "\n",
    "inputFileName = \"time_data_t10_d30.root\"\n",
    "\n",
    "fileExist = ROOT.gSystem.AccessPathName(inputFileName)\n",
    "\n",
    "#if file does not exists create it\n",
    "if (fileExist==None):\n",
    "    MakeTimeData(nTotEvts,ntime, ninput)\n",
    "\n",
    "inputFile = ROOT.TFile.Open(inputFileName)\n",
    "if (inputFile==None):\n",
    "    Error(\"TMVA_RNN_Classification\", \"Error opening input file %s - exit\", inputFileName.Data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204016f",
   "metadata": {},
   "source": [
    "### Create an Output File and Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods whose performance you'd like to investigate.\n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    "- The first argument is the base of the name of all the output weightfiles in the directory weight/ that will be created with the method parameters\n",
    "\n",
    "- The second argument is the output file for the training results\n",
    "\n",
    "- The third argument is a string option defining some general configuration for the TMVA session. \n",
    "\n",
    "For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49cde7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RNNClassification  : Using input file: time_data_t10_d30.root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- RNNClassification  : Using input file: \" + inputFile.GetName()+\"\\n\")\n",
    "\n",
    "#   Create a ROOT output file where TMVA will store ntuples, histograms, etc.\n",
    "outfileName = \"data_RNN_\"+ archString +\".root\"\n",
    "\n",
    "if (writeOutputFile):\n",
    "    outputFile = ROOT.TFile.Open(outfileName, \"RECREATE\")\n",
    "\n",
    "#  Creating the factory object\n",
    "factory = ROOT.TMVA.Factory(\"TMVAClassification\", outputFile,\"!V:!Silent:Color:DrawProgressBar:Transformations=None:!Correlations:\"+\"AnalysisType=Classification:ModelPersistence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07fc9b",
   "metadata": {},
   "source": [
    "### Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables\n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11738b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of variables is 300\n",
      "\n",
      "vars_time0[0]\n",
      "\n",
      "vars_time0[1]\n",
      "\n",
      "vars_time0[2]\n",
      "\n",
      "vars_time0[3]\n",
      "\n",
      "vars_time0[4]\n",
      "\n",
      "vars_time0[5]\n",
      "\n",
      "vars_time0[6]\n",
      "\n",
      "vars_time0[7]\n",
      "\n",
      "vars_time0[8]\n",
      "\n",
      "vars_time0[9]\n",
      "\n",
      "vars_time0[10]\n",
      "\n",
      "vars_time0[11]\n",
      "\n",
      "vars_time0[12]\n",
      "\n",
      "vars_time0[13]\n",
      "\n",
      "vars_time0[14]\n",
      "\n",
      "vars_time0[15]\n",
      "\n",
      "vars_time0[16]\n",
      "\n",
      "vars_time0[17]\n",
      "\n",
      "vars_time0[18]\n",
      "\n",
      "vars_time0[19]\n",
      "\n",
      "vars_time0[20]\n",
      "\n",
      "vars_time0[21]\n",
      "\n",
      "vars_time0[22]\n",
      "\n",
      "vars_time0[23]\n",
      "\n",
      "vars_time0[24]\n",
      "\n",
      "vars_time0[25]\n",
      "\n",
      "vars_time0[26]\n",
      "\n",
      "vars_time0[27]\n",
      "\n",
      "vars_time0[28]\n",
      "\n",
      "vars_time0[29]\n",
      "\n",
      "vars_time1[0]\n",
      "\n",
      "vars_time1[1]\n",
      "\n",
      "vars_time1[2]\n",
      "\n",
      "vars_time1[3]\n",
      "\n",
      "vars_time1[4]\n",
      "\n",
      "vars_time1[5]\n",
      "\n",
      "vars_time1[6]\n",
      "\n",
      "vars_time1[7]\n",
      "\n",
      "vars_time1[8]\n",
      "\n",
      "vars_time1[9]\n",
      "\n",
      "vars_time1[10]\n",
      "\n",
      "vars_time1[11]\n",
      "\n",
      "vars_time1[12]\n",
      "\n",
      "vars_time1[13]\n",
      "\n",
      "vars_time1[14]\n",
      "\n",
      "vars_time1[15]\n",
      "\n",
      "vars_time1[16]\n",
      "\n",
      "vars_time1[17]\n",
      "\n",
      "vars_time1[18]\n",
      "\n",
      "vars_time1[19]\n",
      "\n",
      "vars_time1[20]\n",
      "\n",
      "vars_time1[21]\n",
      "\n",
      "vars_time1[22]\n",
      "\n",
      "vars_time1[23]\n",
      "\n",
      "vars_time1[24]\n",
      "\n",
      "vars_time1[25]\n",
      "\n",
      "vars_time1[26]\n",
      "\n",
      "vars_time1[27]\n",
      "\n",
      "vars_time1[28]\n",
      "\n",
      "vars_time1[29]\n",
      "\n",
      "vars_time2[0]\n",
      "\n",
      "vars_time2[1]\n",
      "\n",
      "vars_time2[2]\n",
      "\n",
      "vars_time2[3]\n",
      "\n",
      "vars_time2[4]\n",
      "\n",
      "vars_time2[5]\n",
      "\n",
      "vars_time2[6]\n",
      "\n",
      "vars_time2[7]\n",
      "\n",
      "vars_time2[8]\n",
      "\n",
      "vars_time2[9]\n",
      "\n",
      "vars_time2[10]\n",
      "\n",
      "vars_time2[11]\n",
      "\n",
      "vars_time2[12]\n",
      "\n",
      "vars_time2[13]\n",
      "\n",
      "vars_time2[14]\n",
      "\n",
      "vars_time2[15]\n",
      "\n",
      "vars_time2[16]\n",
      "\n",
      "vars_time2[17]\n",
      "\n",
      "vars_time2[18]\n",
      "\n",
      "vars_time2[19]\n",
      "\n",
      "vars_time2[20]\n",
      "\n",
      "vars_time2[21]\n",
      "\n",
      "vars_time2[22]\n",
      "\n",
      "vars_time2[23]\n",
      "\n",
      "vars_time2[24]\n",
      "\n",
      "vars_time2[25]\n",
      "\n",
      "vars_time2[26]\n",
      "\n",
      "vars_time2[27]\n",
      "\n",
      "vars_time2[28]\n",
      "\n",
      "vars_time2[29]\n",
      "\n",
      "vars_time3[0]\n",
      "\n",
      "vars_time3[1]\n",
      "\n",
      "vars_time3[2]\n",
      "\n",
      "vars_time3[3]\n",
      "\n",
      "vars_time3[4]\n",
      "\n",
      "vars_time3[5]\n",
      "\n",
      "vars_time3[6]\n",
      "\n",
      "vars_time3[7]\n",
      "\n",
      "vars_time3[8]\n",
      "\n",
      "vars_time3[9]\n",
      "\n",
      "vars_time3[10]\n",
      "\n",
      "vars_time3[11]\n",
      "\n",
      "vars_time3[12]\n",
      "\n",
      "vars_time3[13]\n",
      "\n",
      "vars_time3[14]\n",
      "\n",
      "vars_time3[15]\n",
      "\n",
      "vars_time3[16]\n",
      "\n",
      "vars_time3[17]\n",
      "\n",
      "vars_time3[18]\n",
      "\n",
      "vars_time3[19]\n",
      "\n",
      "vars_time3[20]\n",
      "\n",
      "vars_time3[21]\n",
      "\n",
      "vars_time3[22]\n",
      "\n",
      "vars_time3[23]\n",
      "\n",
      "vars_time3[24]\n",
      "\n",
      "vars_time3[25]\n",
      "\n",
      "vars_time3[26]\n",
      "\n",
      "vars_time3[27]\n",
      "\n",
      "vars_time3[28]\n",
      "\n",
      "vars_time3[29]\n",
      "\n",
      "vars_time4[0]\n",
      "\n",
      "vars_time4[1]\n",
      "\n",
      "vars_time4[2]\n",
      "\n",
      "vars_time4[3]\n",
      "\n",
      "vars_time4[4]\n",
      "\n",
      "vars_time4[5]\n",
      "\n",
      "vars_time4[6]\n",
      "\n",
      "vars_time4[7]\n",
      "\n",
      "vars_time4[8]\n",
      "\n",
      "vars_time4[9]\n",
      "\n",
      "vars_time4[10]\n",
      "\n",
      "vars_time4[11]\n",
      "\n",
      "vars_time4[12]\n",
      "\n",
      "vars_time4[13]\n",
      "\n",
      "vars_time4[14]\n",
      "\n",
      "vars_time4[15]\n",
      "\n",
      "vars_time4[16]\n",
      "\n",
      "vars_time4[17]\n",
      "\n",
      "vars_time4[18]\n",
      "\n",
      "vars_time4[19]\n",
      "\n",
      "vars_time4[20]\n",
      "\n",
      "vars_time4[21]\n",
      "\n",
      "vars_time4[22]\n",
      "\n",
      "vars_time4[23]\n",
      "\n",
      "vars_time4[24]\n",
      "\n",
      "vars_time4[25]\n",
      "\n",
      "vars_time4[26]\n",
      "\n",
      "vars_time4[27]\n",
      "\n",
      "vars_time4[28]\n",
      "\n",
      "vars_time4[29]\n",
      "\n",
      "vars_time5[0]\n",
      "\n",
      "vars_time5[1]\n",
      "\n",
      "vars_time5[2]\n",
      "\n",
      "vars_time5[3]\n",
      "\n",
      "vars_time5[4]\n",
      "\n",
      "vars_time5[5]\n",
      "\n",
      "vars_time5[6]\n",
      "\n",
      "vars_time5[7]\n",
      "\n",
      "vars_time5[8]\n",
      "\n",
      "vars_time5[9]\n",
      "\n",
      "vars_time5[10]\n",
      "\n",
      "vars_time5[11]\n",
      "\n",
      "vars_time5[12]\n",
      "\n",
      "vars_time5[13]\n",
      "\n",
      "vars_time5[14]\n",
      "\n",
      "vars_time5[15]\n",
      "\n",
      "vars_time5[16]\n",
      "\n",
      "vars_time5[17]\n",
      "\n",
      "vars_time5[18]\n",
      "\n",
      "vars_time5[19]\n",
      "\n",
      "vars_time5[20]\n",
      "\n",
      "vars_time5[21]\n",
      "\n",
      "vars_time5[22]\n",
      "\n",
      "vars_time5[23]\n",
      "\n",
      "vars_time5[24]\n",
      "\n",
      "vars_time5[25]\n",
      "\n",
      "vars_time5[26]\n",
      "\n",
      "vars_time5[27]\n",
      "\n",
      "vars_time5[28]\n",
      "\n",
      "vars_time5[29]\n",
      "\n",
      "vars_time6[0]\n",
      "\n",
      "vars_time6[1]\n",
      "\n",
      "vars_time6[2]\n",
      "\n",
      "vars_time6[3]\n",
      "\n",
      "vars_time6[4]\n",
      "\n",
      "vars_time6[5]\n",
      "\n",
      "vars_time6[6]\n",
      "\n",
      "vars_time6[7]\n",
      "\n",
      "vars_time6[8]\n",
      "\n",
      "vars_time6[9]\n",
      "\n",
      "vars_time6[10]\n",
      "\n",
      "vars_time6[11]\n",
      "\n",
      "vars_time6[12]\n",
      "\n",
      "vars_time6[13]\n",
      "\n",
      "vars_time6[14]\n",
      "\n",
      "vars_time6[15]\n",
      "\n",
      "vars_time6[16]\n",
      "\n",
      "vars_time6[17]\n",
      "\n",
      "vars_time6[18]\n",
      "\n",
      "vars_time6[19]\n",
      "\n",
      "vars_time6[20]\n",
      "\n",
      "vars_time6[21]\n",
      "\n",
      "vars_time6[22]\n",
      "\n",
      "vars_time6[23]\n",
      "\n",
      "vars_time6[24]\n",
      "\n",
      "vars_time6[25]\n",
      "\n",
      "vars_time6[26]\n",
      "\n",
      "vars_time6[27]\n",
      "\n",
      "vars_time6[28]\n",
      "\n",
      "vars_time6[29]\n",
      "\n",
      "vars_time7[0]\n",
      "\n",
      "vars_time7[1]\n",
      "\n",
      "vars_time7[2]\n",
      "\n",
      "vars_time7[3]\n",
      "\n",
      "vars_time7[4]\n",
      "\n",
      "vars_time7[5]\n",
      "\n",
      "vars_time7[6]\n",
      "\n",
      "vars_time7[7]\n",
      "\n",
      "vars_time7[8]\n",
      "\n",
      "vars_time7[9]\n",
      "\n",
      "vars_time7[10]\n",
      "\n",
      "vars_time7[11]\n",
      "\n",
      "vars_time7[12]\n",
      "\n",
      "vars_time7[13]\n",
      "\n",
      "vars_time7[14]\n",
      "\n",
      "vars_time7[15]\n",
      "\n",
      "vars_time7[16]\n",
      "\n",
      "vars_time7[17]\n",
      "\n",
      "vars_time7[18]\n",
      "\n",
      "vars_time7[19]\n",
      "\n",
      "vars_time7[20]\n",
      "\n",
      "vars_time7[21]\n",
      "\n",
      "vars_time7[22]\n",
      "\n",
      "vars_time7[23]\n",
      "\n",
      "vars_time7[24]\n",
      "\n",
      "vars_time7[25]\n",
      "\n",
      "vars_time7[26]\n",
      "\n",
      "vars_time7[27]\n",
      "\n",
      "vars_time7[28]\n",
      "\n",
      "vars_time7[29]\n",
      "\n",
      "vars_time8[0]\n",
      "\n",
      "vars_time8[1]\n",
      "\n",
      "vars_time8[2]\n",
      "\n",
      "vars_time8[3]\n",
      "\n",
      "vars_time8[4]\n",
      "\n",
      "vars_time8[5]\n",
      "\n",
      "vars_time8[6]\n",
      "\n",
      "vars_time8[7]\n",
      "\n",
      "vars_time8[8]\n",
      "\n",
      "vars_time8[9]\n",
      "\n",
      "vars_time8[10]\n",
      "\n",
      "vars_time8[11]\n",
      "\n",
      "vars_time8[12]\n",
      "\n",
      "vars_time8[13]\n",
      "\n",
      "vars_time8[14]\n",
      "\n",
      "vars_time8[15]\n",
      "\n",
      "vars_time8[16]\n",
      "\n",
      "vars_time8[17]\n",
      "\n",
      "vars_time8[18]\n",
      "\n",
      "vars_time8[19]\n",
      "\n",
      "vars_time8[20]\n",
      "\n",
      "vars_time8[21]\n",
      "\n",
      "vars_time8[22]\n",
      "\n",
      "vars_time8[23]\n",
      "\n",
      "vars_time8[24]\n",
      "\n",
      "vars_time8[25]\n",
      "\n",
      "vars_time8[26]\n",
      "\n",
      "vars_time8[27]\n",
      "\n",
      "vars_time8[28]\n",
      "\n",
      "vars_time8[29]\n",
      "\n",
      "vars_time9[0]\n",
      "\n",
      "vars_time9[1]\n",
      "\n",
      "vars_time9[2]\n",
      "\n",
      "vars_time9[3]\n",
      "\n",
      "vars_time9[4]\n",
      "\n",
      "vars_time9[5]\n",
      "\n",
      "vars_time9[6]\n",
      "\n",
      "vars_time9[7]\n",
      "\n",
      "vars_time9[8]\n",
      "\n",
      "vars_time9[9]\n",
      "\n",
      "vars_time9[10]\n",
      "\n",
      "vars_time9[11]\n",
      "\n",
      "vars_time9[12]\n",
      "\n",
      "vars_time9[13]\n",
      "\n",
      "vars_time9[14]\n",
      "\n",
      "vars_time9[15]\n",
      "\n",
      "vars_time9[16]\n",
      "\n",
      "vars_time9[17]\n",
      "\n",
      "vars_time9[18]\n",
      "\n",
      "vars_time9[19]\n",
      "\n",
      "vars_time9[20]\n",
      "\n",
      "vars_time9[21]\n",
      "\n",
      "vars_time9[22]\n",
      "\n",
      "vars_time9[23]\n",
      "\n",
      "vars_time9[24]\n",
      "\n",
      "vars_time9[25]\n",
      "\n",
      "vars_time9[26]\n",
      "\n",
      "vars_time9[27]\n",
      "\n",
      "vars_time9[28]\n",
      "\n",
      "vars_time9[29]\n",
      "\n",
      "******************************************************************************\n",
      "*Tree    :sgn       : sgn                                                    *\n",
      "*Entries :    10000 : Total =        13449901 bytes  File  Size =   11258248 *\n",
      "*        :          : Tree compression factor =   1.19                       *\n",
      "******************************************************************************\n",
      "*Br    0 :vars_time0 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1124563 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    1 :vars_time1 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1124654 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    2 :vars_time2 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1124757 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    3 :vars_time3 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1124807 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    4 :vars_time4 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1125129 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    5 :vars_time5 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1125625 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    6 :vars_time6 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1125720 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    7 :vars_time7 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1126131 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    8 :vars_time8 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1126511 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "*Br    9 :vars_time9 : vector<float>                                         *\n",
      "*Entries :    10000 : Total  Size=    1344905 bytes  File Size  =    1126524 *\n",
      "*Baskets :       44 : Basket Size=      32000 bytes  Compression=   1.19     *\n",
      "*............................................................................*\n",
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sgn of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloader =TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "signalTree = inputFile.Get(\"sgn\")\n",
    "background = inputFile.Get(\"bkg\")\n",
    "\n",
    "signalTree.Print()\n",
    "nvar = ninput * ntime\n",
    "\n",
    "# add variables - use new AddVariablesArray function\n",
    "for i in range(ntime):\n",
    "    varName = \"vars_time\"+str(i)\n",
    "    dataloader.AddVariablesArray(varName,ninput,'F')\n",
    "\n",
    "dataloader.AddSignalTree(signalTree, 1.0)\n",
    "dataloader.AddBackgroundTree(background, 1.0)\n",
    "\n",
    "# check given input\n",
    "datainfo = dataloader.GetDataSetInfo()\n",
    "vars = datainfo.GetListOfVariables()\n",
    "print(\"number of variables is \" + str(vars.size())+ \"\\n\")\n",
    "for v in vars:\n",
    "    print(str(v)+\"\\n\")\n",
    "\n",
    "nTrainSig = 0.8 * nTotEvts\n",
    "nTrainBkg = 0.8 *  nTotEvts\n",
    "\n",
    "#build the string options for DataLoader::PrepareTrainingAndTestTree\n",
    "prepareOptions = \"nTrain_Signal=\"+str(nTrainSig)+\":nTrain_Background=\"+str(nTrainBkg)+\":SplitMode=Random:SplitSeed=100:NormMode=NumEvents:!V:!CalcCorrelations\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b9dde",
   "metadata": {},
   "source": [
    "###  Tell the factory how to use the training and testing events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae30b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared DATA LOADER \n"
     ]
    }
   ],
   "source": [
    "# Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\")   ## for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "mycutb = ROOT.TCut(\"\")   ## for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "dataloader.PrepareTrainingAndTestTree(mycuts, mycutb, prepareOptions)\n",
    "\n",
    "print(\"prepared DATA LOADER \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23491509",
   "metadata": {},
   "source": [
    "### Book TMVA  recurrent models\n",
    "\n",
    "Book the different types of recurrent models in TMVA  (SimpleRNN, LSTM or GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd60f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mTMVA_RNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234:InputLayout=10|30:Layout=RNN|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234:InputLayout=10|30:Layout=RNN|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"10|30\" [The Layout of the input]\n",
      "                         :     Layout: \"RNN|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     RandomSeed: \"1234\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"0.2\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n",
      "Factory                  : Booking method: \u001b[1mTMVA_LSTM\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234:InputLayout=10|30:Layout=LSTM|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234:InputLayout=10|30:Layout=LSTM|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"10|30\" [The Layout of the input]\n",
      "                         :     Layout: \"LSTM|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     RandomSeed: \"1234\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"0.2\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n",
      "Factory                  : Booking method: \u001b[1mTMVA_GRU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234:InputLayout=10|30:Layout=GRU|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234:InputLayout=10|30:Layout=GRU|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"10|30\" [The Layout of the input]\n",
      "                         :     Layout: \"GRU|10|30|10|0|1,RESHAPE|FLAT,DENSE|64|TANH,LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     RandomSeed: \"1234\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"0.2\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=5,BatchSize=100,TestRepetitions=1,WeightDecay=1e-2,Regularization=None,MaxEpochs=20,Optimizer=ADAM,DropConfig=0.0+0.+0.+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if (useTMVA_RNN):\n",
    "    for i in range(3):\n",
    "        if (use_rnn_type[i]==None):\n",
    "            continue\n",
    "        rnn_type = str(rnn_types[i])\n",
    "\n",
    "#          define the inputlayout string for RNN\n",
    "#          the input data should be organize as   following:\n",
    "#          input layout for RNN:    time x ndim\n",
    "\n",
    "        inputLayoutString = \"InputLayout=\"+str(ntime)+\"|\"+str(ninput)\n",
    "\n",
    "        # Define RNN layer layout\n",
    "        # it should be   LayerType (RNN or LSTM or GRU) |  number of units | number of inputs | time steps | remember output (typically no=0 | return full sequence\n",
    "        rnnLayout = str(rnn_type) + \"|10|\"+ str(ninput) + \"|\" + str(ntime) + \"|0|1\"\n",
    "\n",
    "        #        add after RNN a reshape layer (needed top flatten the output) and a dense layer with 64 units and a last one\n",
    "        #        Note the last layer is linear because  when using Crossentropy a Sigmoid is applied already\n",
    "        layoutString =\"Layout=\" + rnnLayout + \",RESHAPE|FLAT,DENSE|64|TANH,LINEAR\"\n",
    "\n",
    "        #Defining Training strategies. Different training strings can be concatenate. Use however only one\n",
    "        trainingString1 = \"LearningRate=1e-3,Momentum=0.0,Repetitions=1,\"+\"ConvergenceSteps=5,BatchSize=\"+str(batchSize)+\",TestRepetitions=1,\"+\"WeightDecay=1e-2,Regularization=None,MaxEpochs=\"+str(maxepochs\n",
    "        )+\",\"+\"Optimizer=ADAM,DropConfig=0.0+0.+0.+0.\"\n",
    "\n",
    "        trainingStrategyString=\"TrainingStrategy=\"\n",
    "        trainingStrategyString += trainingString1; # + \"|\" + trainingString2\n",
    "\n",
    "        # Define the full RNN Noption string adding the final options for all network\n",
    "        rnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"+\"WeightInitialization=XAVIERUNIFORM:ValidationSize=0.2:RandomSeed=1234\"\n",
    "        rnnOptions +=  \":\" + inputLayoutString\n",
    "        rnnOptions +=  \":\" + layoutString\n",
    "        rnnOptions +=  \":\" + trainingStrategyString\n",
    "        rnnOptions +=  \":\" + \"Architecture=\" + str(archString)\n",
    "\n",
    "        rnnName = \"TMVA_\" + rnn_type\n",
    "        factory.BookMethod(dataloader, TMVA.Types.kDL, rnnName, rnnOptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff56bbe",
   "metadata": {},
   "source": [
    "### Book TMVA  fully connected dense layer  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1188f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mTMVA_DNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIER:RandomSeed=0:InputLayout=1|1|300:Layout=DENSE|64|TANH,DENSE|TANH|64,DENSE|TANH|64,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=10,BatchSize=256,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,MaxEpochs=20DropConfig=0.0+0.+0.+0.,Optimizer=ADAM:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIER:RandomSeed=0:InputLayout=1|1|300:Layout=DENSE|64|TANH,DENSE|TANH|64,DENSE|TANH|64,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=10,BatchSize=256,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,MaxEpochs=20DropConfig=0.0+0.+0.+0.,Optimizer=ADAM:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|300\" [The Layout of the input]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|TANH|64,DENSE|TANH|64,LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIER\" [Weight initialization strategy]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=10,BatchSize=256,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,MaxEpochs=20DropConfig=0.0+0.+0.+0.,Optimizer=ADAM\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if (useTMVA_DNN):\n",
    "#    Method DL with Dense Layer\n",
    "    inputLayoutString = \"InputLayout=1|1|\" + str(ntime * ninput)\n",
    "\n",
    "    layoutString = \"Layout=DENSE|64|TANH,DENSE|TANH|64,DENSE|TANH|64,LINEAR\"\n",
    "#   Training strategies.\n",
    "    trainingString1 = \"LearningRate=1e-3,Momentum=0.0,Repetitions=1,\"+\"ConvergenceSteps=10,BatchSize=256,TestRepetitions=1,\"+\"WeightDecay=1e-4,Regularization=None,MaxEpochs=20\"+\"DropConfig=0.0+0.+0.+0.,Optimizer=ADAM\"\n",
    "    trainingStrategyString = \"TrainingStrategy=\"\n",
    "    trainingStrategyString += trainingString1 # + \"|\" + trainingString2\n",
    "\n",
    "      # General Options.\n",
    "    dnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"+\"WeightInitialization=XAVIER:RandomSeed=0\" \n",
    "\n",
    "    dnnOptions +=  \":\" + inputLayoutString\n",
    "    dnnOptions +=  \":\" + layoutString\n",
    "    dnnOptions +=  \":\" + trainingStrategyString\n",
    "    dnnOptions +=  \":\" + \"Architecture=\" + str(archString)\n",
    "\n",
    "\n",
    "    dnnName = \"TMVA_DNN\"\n",
    "    factory.BookMethod(dataloader, TMVA.Types.kDL, dnnName, dnnOptions)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f3f41",
   "metadata": {},
   "source": [
    "### Book Keras recurrent models\n",
    "\n",
    "Book the different types of recurrent models in Keras  (SimpleRNN, LSTM or GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da87118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 10, 30)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 10)            1640      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 10)           40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,274\n",
      "Trainable params: 8,254\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "Factory                  : Booking method: \u001b[1mPyKeras_LSTM\u001b[0m\n",
      "                         : \n",
      "                         : Setting up tf.keras\n",
      "                         : Using TensorFlow version 2\n",
      "                         : Use Keras version from TensorFlow : tf.keras\n",
      "                         : Applying GPU option:  gpu_options.allow_growth=True\n",
      "                         :  Loading Keras Model \n",
      "                         : Loaded model from file: model_LSTM.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 19:08:22.035384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/neel/Root/install/lib:/opt/ros/noetic/lib\n",
      "2022-04-08 19:08:22.035411: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Info in <TMVA_RNN_Classification>: Building recurrent keras model using aLSTM layer\n",
      "2022-04-08 19:08:23.852191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/neel/Root/install/lib:/opt/ros/noetic/lib\n",
      "2022-04-08 19:08:23.852221: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-08 19:08:23.852240: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (neel-HP-Pavilion-15-Notebook-PC): /proc/driver/nvidia/version does not exist\n",
      "2022-04-08 19:08:23.852458: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "python: can't open file 'make_rnn_model.py': [Errno 2] No such file or directory\n",
      "Info in <TMVA_RNN_Classification>: Booking KerasLSTMmodel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "\n",
    "\n",
    "if (useKeras):\n",
    "    for i in range(3):\n",
    "        if (use_rnn_type[i]):\n",
    "            modelName = \"model_\" + str(rnn_types[i]) + \".h5\"\n",
    "            trainedModelName = \"trained_model_\"+ str(rnn_types[i]) + \".h5\"\n",
    "\n",
    "            ROOT.Info(\"TMVA_RNN_Classification\", \"Building recurrent keras model using a\"+str(rnn_types[i])+\" layer\")\n",
    "            # create python script which can be executed\n",
    "            # create 2 conv2d layer + maxpool + dense\n",
    "        \n",
    "            \n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Reshape((10, 30), input_shape = (10*30, )))\n",
    "            # add recurrent neural network depending on type / Use option to return the full output\n",
    "            if (rnn_types[i] == \"LSTM\"):\n",
    "               model.add(LSTM(units=10, return_sequences=True) )\n",
    "            elif (rnn_types[i] == \"GRU\"):\n",
    "               model.add(GRU(units=10, return_sequences=True) )\n",
    "            else:\n",
    "               model.add(SimpleRNN(units=10, return_sequences=True) )\n",
    "\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Flatten())# needed if returning the full time output sequen\n",
    "            model.add(Dense(64, activation = 'tanh')) \n",
    "            model.add(Dense(2, activation = 'sigmoid')) \n",
    "            model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "            \n",
    "            model.save(modelName)\n",
    "            model.summary()\n",
    "\n",
    "#             m.SaveSource(\"make_rnn_model.py\");\n",
    "#              execute\n",
    "            ROOT.gSystem.Exec(\"python make_rnn_model.py\")\n",
    "\n",
    "            if (ROOT.gSystem.AccessPathName(modelName)):\n",
    "               Warning(\"TMVA_RNN_Classification\", \"Error creating Keras recurrent model file - Skip using Keras\")\n",
    "               useKeras = False\n",
    "            else:\n",
    "               # book PyKeras method only if Keras model could be created\n",
    "               ROOT.Info(\"TMVA_RNN_Classification\", \"Booking Keras\" + str(rnn_types[i]) +  \"model\")\n",
    "               factory.BookMethod(dataloader, TMVA.Types.kPyKeras,\"PyKeras_\"+ str(rnn_types[i]),\"!H:!V:VarTransform=None:FilenameModel=\"+str(modelName)+\":tf.keras:\"+\"FilenameTrainedModel=\"+str(trainedModelName)+\":GpuOptions=allow_growth=True:\"+\"NumEpochs=\"+str(maxepochs)+\":BatchSize=\"+str(batchSize))\n",
    "                                                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e529e",
   "metadata": {},
   "source": [
    "### Training All Methods\n",
    "\n",
    "Here we train all the previously booked methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da594215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 10, 30)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 10)            1640      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 10)           40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,274\n",
      "Trainable params: 8,254\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.6418 - accuracy: 0.6298\n",
      "Epoch 1: val_loss improved from inf to 0.63289, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 5s 18ms/step - loss: 0.6385 - accuracy: 0.6338 - val_loss: 0.6329 - val_accuracy: 0.6347\n",
      "Epoch 2/20\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.5405 - accuracy: 0.7284\n",
      "Epoch 2: val_loss improved from 0.63289 to 0.55375, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.5364 - accuracy: 0.7308 - val_loss: 0.5538 - val_accuracy: 0.7181\n",
      "Epoch 3/20\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7820\n",
      "Epoch 3: val_loss improved from 0.55375 to 0.47000, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.7817 - val_loss: 0.4700 - val_accuracy: 0.7778\n",
      "Epoch 4/20\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.4352 - accuracy: 0.7981\n",
      "Epoch 4: val_loss improved from 0.47000 to 0.42911, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4351 - accuracy: 0.7981 - val_loss: 0.4291 - val_accuracy: 0.8022\n",
      "Epoch 5/20\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.4158 - accuracy: 0.8097\n",
      "Epoch 5: val_loss did not improve from 0.42911\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4156 - accuracy: 0.8097 - val_loss: 0.4381 - val_accuracy: 0.8009\n",
      "Epoch 6/20\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.4044 - accuracy: 0.8145\n",
      "Epoch 6: val_loss did not improve from 0.42911\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4029 - accuracy: 0.8153 - val_loss: 0.4544 - val_accuracy: 0.7919\n",
      "Epoch 7/20\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.3924 - accuracy: 0.8202\n",
      "Epoch 7: val_loss did not improve from 0.42911\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3929 - accuracy: 0.8200 - val_loss: 0.4675 - val_accuracy: 0.7825\n",
      "Epoch 8/20\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8249\n",
      "Epoch 8: val_loss improved from 0.42911 to 0.39958, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3916 - accuracy: 0.8239 - val_loss: 0.3996 - val_accuracy: 0.8172\n",
      "Epoch 9/20\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8284\n",
      "Epoch 9: val_loss did not improve from 0.39958\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3860 - accuracy: 0.8280 - val_loss: 0.4008 - val_accuracy: 0.8097\n",
      "Epoch 10/20\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8264\n",
      "Epoch 10: val_loss improved from 0.39958 to 0.39814, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3860 - accuracy: 0.8264 - val_loss: 0.3981 - val_accuracy: 0.8203\n",
      "Epoch 11/20\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8297\n",
      "Epoch 11: val_loss did not improve from 0.39814\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3814 - accuracy: 0.8295 - val_loss: 0.4003 - val_accuracy: 0.8200\n",
      "Epoch 12/20\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8287\n",
      "Epoch 12: val_loss improved from 0.39814 to 0.39293, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3798 - accuracy: 0.8286 - val_loss: 0.3929 - val_accuracy: 0.8144\n",
      "Epoch 13/20\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.8347\n",
      "Epoch 13: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3758 - accuracy: 0.8341 - val_loss: 0.4117 - val_accuracy: 0.8037\n",
      "Epoch 14/20\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.3740 - accuracy: 0.8337\n",
      "Epoch 14: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.3734 - accuracy: 0.8339 - val_loss: 0.3971 - val_accuracy: 0.8125\n",
      "Epoch 15/20\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8339\n",
      "Epoch 15: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3728 - accuracy: 0.8339 - val_loss: 0.3957 - val_accuracy: 0.8197\n",
      "Epoch 16/20\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.3731 - accuracy: 0.8365\n",
      "Epoch 16: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3718 - accuracy: 0.8373 - val_loss: 0.4378 - val_accuracy: 0.8016\n",
      "Epoch 17/20\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.3749 - accuracy: 0.8299\n",
      "Epoch 17: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3740 - accuracy: 0.8307 - val_loss: 0.3952 - val_accuracy: 0.8197\n",
      "Epoch 18/20\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.3698 - accuracy: 0.8354\n",
      "Epoch 18: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3699 - accuracy: 0.8352 - val_loss: 0.3988 - val_accuracy: 0.8213\n",
      "Epoch 19/20\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.3691 - accuracy: 0.8349\n",
      "Epoch 19: val_loss did not improve from 0.39293\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3688 - accuracy: 0.8352 - val_loss: 0.3973 - val_accuracy: 0.8159\n",
      "Epoch 20/20\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8330\n",
      "Epoch 20: val_loss improved from 0.39293 to 0.39218, saving model to trained_model_LSTM.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3673 - accuracy: 0.8330 - val_loss: 0.3922 - val_accuracy: 0.8159\n",
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "                         : Rebuilding Dataset dataset\n",
      "                         : Building event vectors for type 2 Signal\n",
      "                         : Dataset[dataset] :  create input formulas for tree sgn\n",
      "                         : Using variable vars_time0[0] from array expression vars_time0 of size 30\n",
      "                         : Using variable vars_time1[0] from array expression vars_time1 of size 30\n",
      "                         : Using variable vars_time2[0] from array expression vars_time2 of size 30\n",
      "                         : Using variable vars_time3[0] from array expression vars_time3 of size 30\n",
      "                         : Using variable vars_time4[0] from array expression vars_time4 of size 30\n",
      "                         : Using variable vars_time5[0] from array expression vars_time5 of size 30\n",
      "                         : Using variable vars_time6[0] from array expression vars_time6 of size 30\n",
      "                         : Using variable vars_time7[0] from array expression vars_time7 of size 30\n",
      "                         : Using variable vars_time8[0] from array expression vars_time8 of size 30\n",
      "                         : Using variable vars_time9[0] from array expression vars_time9 of size 30\n",
      "                         : Building event vectors for type 2 Background\n",
      "                         : Dataset[dataset] :  create input formulas for tree bkg\n",
      "                         : Using variable vars_time0[0] from array expression vars_time0 of size 30\n",
      "                         : Using variable vars_time1[0] from array expression vars_time1 of size 30\n",
      "                         : Using variable vars_time2[0] from array expression vars_time2 of size 30\n",
      "                         : Using variable vars_time3[0] from array expression vars_time3 of size 30\n",
      "                         : Using variable vars_time4[0] from array expression vars_time4 of size 30\n",
      "                         : Using variable vars_time5[0] from array expression vars_time5 of size 30\n",
      "                         : Using variable vars_time6[0] from array expression vars_time6 of size 30\n",
      "                         : Using variable vars_time7[0] from array expression vars_time7 of size 30\n",
      "                         : Using variable vars_time8[0] from array expression vars_time8 of size 30\n",
      "                         : Using variable vars_time9[0] from array expression vars_time9 of size 30\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 8000\n",
      "                         : Signal     -- testing events             : 2000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 8000\n",
      "                         : Background -- testing events             : 2000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n",
      "Factory                  : Train method: TMVA_RNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 4\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 4  Input = ( 10, 1, 30 )  Batch size = 100  Loss function = C\n",
      "\tLayer 0\t RECURRENT Layer: \t  (NInput = 30, NState = 10, NTime  = 10 )\tOutput = ( 100 , 10 , 10 )\n",
      "\tLayer 1\t RESHAPE Layer \t Input = ( 1 , 10 , 10 ) \tOutput = ( 1 , 100 , 100 ) \n",
      "\tLayer 2\t DENSE Layer: \t ( Input =   100 , Width =    64 ) \tOutput = (  1 ,   100 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   100 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 12800 events for training and 3200 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = 0.929443\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.681476    0.658081    0.498833   0.0529958     28710.1           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.630023    0.617435    0.489734   0.0533291     29330.5           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.592102    0.574997    0.492154   0.0534674       29178           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.550848    0.549153    0.495994   0.0540376     28962.1           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.520528    0.518078    0.497515   0.0543211     28881.2           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |      0.49195     0.49751    0.502481   0.0548717     28596.3           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.470456    0.491288    0.509505   0.0548101     28150.8           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.457386    0.469806    0.502561   0.0545417     28570.2           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.445034     0.45544     0.50325   0.0550077       28556           0\n",
      "                         :         10 |     0.435398    0.456206    0.502175   0.0553658     28647.6           1\n",
      "                         :         11 Minimum Test error found - save the configuration \n",
      "                         :         11 |     0.429634    0.450135    0.500478   0.0546439     28710.2           0\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.426046    0.435608    0.503164   0.0543407       28519           0\n",
      "                         :         13 |     0.421704    0.448529    0.505658   0.0549243     28398.1           1\n",
      "                         :         14 |     0.416236    0.438522    0.503581    0.054619     28510.2           2\n",
      "                         :         15 Minimum Test error found - save the configuration \n",
      "                         :         15 |     0.414906    0.431005    0.505438   0.0554916     28447.9           0\n",
      "                         :         16 Minimum Test error found - save the configuration \n",
      "                         :         16 |     0.408304     0.43009    0.507737   0.0548566     28263.5           0\n",
      "                         :         17 Minimum Test error found - save the configuration \n",
      "                         :         17 |     0.410414    0.428649    0.519328   0.0550519     27569.8           0\n",
      "                         :         18 |     0.403984    0.429797    0.504835   0.0550573     28458.5           1\n",
      "                         :         19 |      0.40319    0.438378    0.506486   0.0548338     28340.4           2\n",
      "                         :         20 Minimum Test error found - save the configuration \n",
      "                         :         20 |     0.400041    0.424189    0.506325   0.0559357     28419.9           0\n",
      "                         : \n",
      "                         : Elapsed time for training with 16000 events: 10.2 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 100\n",
      "                         : \n",
      "TMVA_RNN                 : [dataset] : Evaluation of TMVA_RNN on training sample (16000 events)\n",
      "                         : Elapsed time for evaluation of 16000 events: 0.274 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_RNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_RNN.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: TMVA_LSTM for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 4\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 4  Input = ( 10, 1, 30 )  Batch size = 100  Loss function = C\n",
      "\tLayer 0\t LSTM Layer: \t  (NInput = 30, NState = 10, NTime  = 10 )\tOutput = ( 100 , 10 , 10 )\n",
      "\tLayer 1\t RESHAPE Layer \t Input = ( 1 , 10 , 10 ) \tOutput = ( 1 , 100 , 100 ) \n",
      "\tLayer 2\t DENSE Layer: \t ( Input =   100 , Width =    64 ) \tOutput = (  1 ,   100 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   100 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 12800 events for training and 3200 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = 0.709671\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.686673    0.668444     2.09086    0.148471     6589.83           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.630225    0.593114     2.43827    0.158905     5615.59           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.560831    0.539399      2.2682     0.14461     6027.52           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.505407     0.49572     1.97217    0.146776      7012.2           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.466613    0.468333     2.05543    0.146806     6706.41           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.440583    0.449364     2.03733    0.148617     6777.08           0\n",
      "                         :          7 |     0.430692    0.465379      2.0434    0.147173     6750.25           1\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.420473    0.435105     2.15782    0.149624     6373.89           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.410565    0.425871     2.09966    0.146213     6552.52           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n",
      "                         :         10 |     0.406882    0.419272     2.05375    0.155675     6743.68           0\n",
      "                         :         11 |     0.403718    0.422049     2.04544     0.14841     6747.37           1\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.403093     0.41696     2.13143    0.162512     6501.04           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.398086    0.412449     2.16081    0.145516     6351.43           0\n",
      "                         :         14 Minimum Test error found - save the configuration \n",
      "                         :         14 |     0.394568    0.407053     2.17817    0.162222     6349.36           0\n",
      "                         :         15 |     0.393418    0.407509     2.20696    0.159075     6250.35           1\n",
      "                         :         16 |     0.389071    0.418958     2.15862    0.146053     6360.02           2\n",
      "                         :         17 Minimum Test error found - save the configuration \n",
      "                         :         17 |     0.392416     0.40564     2.04056    0.140268     6735.81           0\n",
      "                         :         18 Minimum Test error found - save the configuration \n",
      "                         :         18 |     0.390365    0.403835     1.99215    0.139337     6908.42           0\n",
      "                         :         19 |      0.39019    0.408447     2.07405    0.139395     6616.17           1\n",
      "                         :         20 Minimum Test error found - save the configuration \n",
      "                         :         20 |     0.387259    0.401651      2.0575    0.151117     6714.29           0\n",
      "                         : \n",
      "                         : Elapsed time for training with 16000 events: 42.4 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 100\n",
      "                         : \n",
      "TMVA_LSTM                : [dataset] : Evaluation of TMVA_LSTM on training sample (16000 events)\n",
      "                         : Elapsed time for evaluation of 16000 events: 0.73 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_LSTM.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_LSTM.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: TMVA_GRU for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 4\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 4  Input = ( 10, 1, 30 )  Batch size = 100  Loss function = C\n",
      "\tLayer 0\t GRU Layer: \t  (NInput = 30, NState = 10, NTime  = 10 )\tOutput = ( 100 , 10 , 10 )\n",
      "\tLayer 1\t RESHAPE Layer \t Input = ( 1 , 10 , 10 ) \tOutput = ( 1 , 100 , 100 ) \n",
      "\tLayer 2\t DENSE Layer: \t ( Input =   100 , Width =    64 ) \tOutput = (  1 ,   100 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   100 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 12800 events for training and 3200 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = 0.709404\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.683836    0.675681     0.96759   0.0965331     14694.8           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.661734    0.660563    0.950231   0.0819706     14742.1           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.633841    0.619115    0.953576   0.0821244     14688.1           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |       0.6107    0.589355      0.9588    0.100445     14912.2           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.590247    0.577662    0.945961   0.0800293     14781.8           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.563742    0.550545    0.935518   0.0849171     15048.2           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.545018    0.544448    0.945893   0.0818006     14813.2           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.529968    0.521708     1.02026   0.0812449     13631.2           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.515032    0.514816     1.02749   0.0931148       13699           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n",
      "                         :         10 |      0.49921    0.500196    0.996914    0.080032     13960.4           0\n",
      "                         :         11 Minimum Test error found - save the configuration \n",
      "                         :         11 |     0.491648    0.492723     1.05236   0.0922811     13332.3           0\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.480009    0.486195     1.06012    0.080722     13069.3           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.472961    0.483426     1.01532   0.0799739     13684.7           0\n",
      "                         :         14 Minimum Test error found - save the configuration \n",
      "                         :         14 |     0.470983    0.473198     1.01893    0.080449       13639           0\n",
      "                         :         15 |      0.46673    0.478858     1.01759   0.0803522     13657.2           1\n",
      "                         :         16 Minimum Test error found - save the configuration \n",
      "                         :         16 |     0.458625    0.469393     1.01985   0.0796754     13614.5           0\n",
      "                         :         17 Minimum Test error found - save the configuration \n",
      "                         :         17 |     0.450367    0.458926      1.0351   0.0800863       13403           0\n",
      "                         :         18 |     0.447508    0.462523     1.04334   0.0794615     13279.7           1\n",
      "                         :         19 Minimum Test error found - save the configuration \n",
      "                         :         19 |     0.445449    0.453093     1.08135   0.0818907       12807           0\n",
      "                         :         20 Minimum Test error found - save the configuration \n",
      "                         :         20 |      0.43637    0.448977     1.11163   0.0937775     12575.4           0\n",
      "                         : \n",
      "                         : Elapsed time for training with 16000 events: 20.2 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 100\n",
      "                         : \n",
      "TMVA_GRU                 : [dataset] : Evaluation of TMVA_GRU on training sample (16000 events)\n",
      "                         : Elapsed time for evaluation of 16000 events: 0.41 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_GRU.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_GRU.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: TMVA_DNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 4\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 4  Input = ( 1, 1, 300 )  Batch size = 256  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =   300 , Width =    64 ) \tOutput = (  1 ,   256 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   256 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   256 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   256 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 12800 events for training and 3200 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = 0.760023\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.698069    0.686133    0.219993   0.0267639     66242.8           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.682189     0.68052    0.205533   0.0261417     71352.4           0\n",
      "                         :          3 |     0.675086    0.681852    0.254631   0.0287951     56678.4           1\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.666375    0.659886    0.238912   0.0299424     61253.1           0\n",
      "                         :          5 |     0.662582    0.682167    0.276723   0.0379831     53614.9           1\n",
      "                         :          6 |     0.660958    0.667784    0.262134    0.028819     54861.5           2\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.629346    0.616477    0.252529   0.0285135       57139           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.611059    0.609959    0.277015   0.0287908     51566.2           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.607358    0.591331    0.241959   0.0272912     59627.1           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n",
      "                         :         10 |     0.587157    0.589627    0.225707   0.0289346     65049.8           0\n",
      "                         :         11 |     0.585933    0.590901    0.231988    0.028142     62792.6           1\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.567691    0.542551    0.231727   0.0293431     63246.1           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.532349    0.539131    0.237829   0.0299537     61575.4           0\n",
      "                         :         14 |     0.528906    0.549497    0.236988    0.027069     60975.9           1\n",
      "                         :         15 |     0.520112    0.547512    0.258007   0.0277895     55599.5           2\n",
      "                         :         16 |     0.521651     0.59448    0.281492   0.0284618     50586.9           3\n",
      "                         :         17 Minimum Test error found - save the configuration \n",
      "                         :         17 |     0.517778    0.525537    0.294256   0.0272681     47942.3           0\n",
      "                         :         18 |     0.512454    0.529644    0.280153   0.0268356     50529.5           1\n",
      "                         :         19 |      0.51173    0.536247    0.288117   0.0280858     49224.8           2\n",
      "                         :         20 Minimum Test error found - save the configuration \n",
      "                         :         20 |     0.483485    0.498172    0.285665    0.029157       49901           0\n",
      "                         : \n",
      "                         : Elapsed time for training with 16000 events: 5.11 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 256\n",
      "                         : \n",
      "TMVA_DNN                 : [dataset] : Evaluation of TMVA_DNN on training sample (16000 events)\n",
      "                         : Elapsed time for evaluation of 16000 events: 0.139 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_DNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_DNN.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: PyKeras_LSTM for Classification\n",
      "                         : \n",
      "                         : Split TMVA training data in 12800 training events and 3200 validation events\n",
      "                         : Training Model Summary\n",
      "                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored\n",
      "                         : Getting training history for item:0 name = 'loss'\n",
      "                         : Getting training history for item:1 name = 'accuracy'\n",
      "                         : Getting training history for item:2 name = 'val_loss'\n",
      "                         : Getting training history for item:3 name = 'val_accuracy'\n",
      "                         : Elapsed time for training with 16000 events: 27.2 sec         \n",
      "PyKeras_LSTM             : [dataset] : Evaluation of PyKeras_LSTM on training sample (16000 events)\n",
      "                         : Elapsed time for evaluation of 16000 events: 1.61 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_PyKeras_LSTM.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_PyKeras_LSTM.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "                         : No variable ranking supplied by classifier: TMVA_RNN\n",
      "                         : No variable ranking supplied by classifier: TMVA_LSTM\n",
      "                         : No variable ranking supplied by classifier: TMVA_GRU\n",
      "                         : No variable ranking supplied by classifier: TMVA_DNN\n",
      "                         : No variable ranking supplied by classifier: PyKeras_LSTM\n",
      "TH1.Print Name  = TrainingHistory_TMVA_RNN_trainingError, Entries= 0, Total sum= 9.40966\n",
      "TH1.Print Name  = TrainingHistory_TMVA_RNN_valError, Entries= 0, Total sum= 9.6429\n",
      "TH1.Print Name  = TrainingHistory_TMVA_LSTM_trainingError, Entries= 0, Total sum= 8.90113\n",
      "TH1.Print Name  = TrainingHistory_TMVA_LSTM_valError, Entries= 0, Total sum= 9.06455\n",
      "TH1.Print Name  = TrainingHistory_TMVA_GRU_trainingError, Entries= 0, Total sum= 10.454\n",
      "TH1.Print Name  = TrainingHistory_TMVA_GRU_valError, Entries= 0, Total sum= 10.4614\n",
      "TH1.Print Name  = TrainingHistory_TMVA_DNN_trainingError, Entries= 0, Total sum= 11.7623\n",
      "TH1.Print Name  = TrainingHistory_TMVA_DNN_valError, Entries= 0, Total sum= 11.9194\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_LSTM_'accuracy', Entries= 0, Total sum= 16.1991\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_LSTM_'loss', Entries= 0, Total sum= 8.18906\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_LSTM_'val_accuracy', Entries= 0, Total sum= 15.9\n",
      "TH1.Print Name  = TrainingHistory_PyKeras_LSTM_'val_loss', Entries= 0, Total sum= 8.66332\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_RNN.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_LSTM.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_GRU.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_TMVA_DNN.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_PyKeras_LSTM.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train all methods\n",
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7594723",
   "metadata": {},
   "source": [
    "### Test all methods\n",
    "\n",
    "Now we test  all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a088af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nthreads  = 4\n",
      "\n",
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: TMVA_RNN for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TMVA_RNN                 : [dataset] : Evaluation of TMVA_RNN on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.0693 sec       \n",
      "Factory                  : Test method: TMVA_LSTM for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TMVA_LSTM                : [dataset] : Evaluation of TMVA_LSTM on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.175 sec       \n",
      "Factory                  : Test method: TMVA_GRU for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TMVA_GRU                 : [dataset] : Evaluation of TMVA_GRU on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.0933 sec       \n",
      "Factory                  : Test method: TMVA_DNN for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TMVA_DNN                 : [dataset] : Evaluation of TMVA_DNN on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.0253 sec       \n",
      "Factory                  : Test method: PyKeras_LSTM for Classification performance\n",
      "                         : \n",
      "                         : Setting up tf.keras\n",
      "                         : Using TensorFlow version 2\n",
      "                         : Use Keras version from TensorFlow : tf.keras\n",
      "                         : Applying GPU option:  gpu_options.allow_growth=True\n",
      "                         :  Loading Keras Model \n",
      "                         : Loaded model from file: trained_model_LSTM.h5\n",
      "PyKeras_LSTM             : [dataset] : Evaluation of PyKeras_LSTM on testing sample (4000 events)\n",
      "                         : Elapsed time for evaluation of 4000 events: 0.791 sec       \n"
     ]
    }
   ],
   "source": [
    "print(\"nthreads  = \"+ str(ROOT.GetThreadPoolSize()) + \"\\n\")\n",
    "\n",
    "# Evaluate all MVAs using the set of test events\n",
    "factory.TestAllMethods()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef639a",
   "metadata": {},
   "source": [
    "### Evaluate all methods\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both training and tetsing data sets. Several histograms are produced which can be examined with the TMVAGui or directly using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aba5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: TMVA_RNN\n",
      "                         : \n",
      "TMVA_RNN                 : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 300 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: TMVA_LSTM\n",
      "                         : \n",
      "TMVA_LSTM                : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 300 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: TMVA_GRU\n",
      "                         : \n",
      "TMVA_GRU                 : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 300 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: TMVA_DNN\n",
      "                         : \n",
      "TMVA_DNN                 : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 300 , it is larger than 200\n",
      "Factory                  : Evaluate classifier: PyKeras_LSTM\n",
      "                         : \n",
      "PyKeras_LSTM             : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Dataset[dataset] :  variable plots are not produces ! The number of variables is 300 , it is larger than 200\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       PyKeras_LSTM   : 0.913\n",
      "                         : dataset       TMVA_LSTM      : 0.910\n",
      "                         : dataset       TMVA_RNN       : 0.898\n",
      "                         : dataset       TMVA_GRU       : 0.878\n",
      "                         : dataset       TMVA_DNN       : 0.857\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              PyKeras_LSTM   : 0.320 (0.352)       0.738 (0.759)      0.921 (0.925)\n",
      "                         : dataset              TMVA_LSTM      : 0.295 (0.322)       0.742 (0.732)      0.921 (0.919)\n",
      "                         : dataset              TMVA_RNN       : 0.325 (0.284)       0.686 (0.711)      0.908 (0.902)\n",
      "                         : dataset              TMVA_GRU       : 0.208 (0.223)       0.655 (0.667)      0.870 (0.876)\n",
      "                         : dataset              TMVA_DNN       : 0.199 (0.189)       0.582 (0.603)      0.848 (0.856)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 4000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 16000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and compare performance of all configured MVAs\n",
    "factory.EvaluateAllMethods()\n",
    "#  check method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191510e",
   "metadata": {},
   "source": [
    "### Plot ROC Curve\n",
    "Here we plot the ROC curve and display the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe9d486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElEQVR4nO2dXbakuLG2hZdHdG6qfAV4EN+yR1EegQFP4FSPwu2eQxvy6nRPqvkutLdKKSShACU/yudZtbpJNgjx8qMgFApV8zwrAAAAAB9/OrsCAAAAcF0wFAAAACAIhgIAAAAEwVAAAACAIBgKAAAAEARD4Qb0fd80TWXR9/1ys6qqmqY5unIWfd9XVTVNU67S9FmbNdM06TX6EBsO1zTNuRJdHC2pgxYt12UNHfRFhV+NVz+koZdDdvI+7HB1Zrg2kWs3juNyy5OqOc/zXNf1slbb6LpueYuaNV3XmW30ciKnS3Rx9BUMUdf16w6a5ba5Pi+9A8dxfNFlGsfRuUBvddUAj8KlMR8f3qe0bVt747qu7fb11ugvFX3W9hr9EtTfTE3T1HUt+j6r6zreFoJa2F7jOOr76vF4HPO1CtvY8EQkMk1T27b21dfHyn4guCZ/PrsCEOPxeCil5oVfYZom7a3t+948vSW5AfWJ2688fXb2mg3+8JIkOgzTXzMMwzAM2ApX5rA7nNvgrcBQuC7xZ77rumEYUt4L0zTp3v3VT43VLfXhEktLqZh6bvtzYWRJLzyxMilibjh6FuybIfuh+74fhmHPcbPIIrqZl8fKe2lSSttzk4f23VBm4olneSTTRT7rSQExB3VxgBzd45h+jZYbmxIMyzKVUnVde7eMF6UWPurEbstlUXav6rL3ZF44VCIxCkt3aFwi7y6h4I/46Xsrb4rSRwntEoq08NbH7GV0814db4FxQpWcA3ejt6trWdtl9exDLG8bs713pX0gu0r6Z9d1Zr19lMilCVVD45y1+encNsvIgMidvJTXLl8XtbyO8QdnDsQoxMV3Tt9bsnd3r1yJIqeoB5cCQ+HShJ63yMbmp3lB6NgF58m099J/0puN42i2XBaut7FLi7/xlzi1WgYtmh5xXbixCZxKzr4m1n6XRcIhvQo752WfhfOWtCWyN7M1sYtyTtx71UKimbOO7LUqaToRQ2H5p+VxvXeOqY9zH5qinNsmbiVEbmbTTJotHSstUodlNQzeW8io4dyuTmnxCntRz5gyQ1fZvjeWhkJIfOeOsg+3vH+8T99SrnSRvephK1wZDIVL41jo+gkMbex9o4W+yZzNvC8O5yW1+vmSYigs3x3eqi7fp0uzwFnjfGTbVTLbOMV6d1mu9L7fnZIjH9ymqOUGq04j7wbOyqUy3mOlYLcHhlDr4rUqlisj96G9i2P0eJ06XjNFLUyx0Cd1fKXIUIhf6PhZx6+L2carQHzl8pGM7BWp/HLH5T0WMu/sQkIix+8HuCBcm6tjf7/aLC0G+2HzPvyz9aB69zI47wVt+K++Q1cNBa/BMfveFKF3ccRQ8L4TnSOmnHtos3jJoW9xu6jlNpEv+MjRnRP3FjKOY4oXysF7p4VuOW1GOCWkWG/OSZnbJmQlhBqSRJ9NSGRnvchQWKq9vNApT98SrwIhGZ2b0PnptSCXpXmr5GyzaiiIRA7dDzNcFa7NbdCtdcSHGW+TTCHeF5+zWegVY7N8660aCpFiV2uVaChEKuxsE/mOcU7Eu1ncBPES+uCL77U8cWcv43aKX68UzHt8fCbRP2wkjRsx3oN2C4+3IXTbOFcwdEFDIntNvURDIb5ZqKiUT2fvBhEZlwqsntFsRUKEbHeHVUMhdF4pRm1kd7gI5FG4DU3T9H0/TdNstQ3xlHZ5Y4lNYkSNHsEoLUEpNQzDMv3f/ropq39axLIyG04tBX05TOGJddbj0MyIg+Vefd/rn0bYnYkUmwV938/zrHypFOy0oU5iD7vA1YPaQyqcQ4TOxVvstntASvyMloN7U/ZaRfrg6Gq0bevd60U3uYM+ZecKMsbhdjA88rpEhirpt3PovfyKmtjHqutatx/bKnDMqzydI+tT17Vua00CjPTx6NpQ8+6lBw32fa/f/o/Ho23buq7zjqrvnkfk2gMmzS0xTZPd5Itao3me9Z12ZLaGY9rLLGy7UeN7kVkEUsBQuC66GR7H0WsrmJW6/fCWEPnThprsb3iapnk8Hqa1y4jzsZ5O9tY0Tt/3bdvqI4a+O5eYFloL6N3L9iLoJtxYJPmq/4Q2CLqusw/hiKkNo5TStA+8aRq9i3065qwdsly4V5iJ+hSWT9/OCuvPA2k14ns1TRNKj5EFDJEyoOvhuuhX2OqLPmJGLJ/SPc2GU9qGV0CoVuqzY2VLtaJM0xSahidiW6Tk8wkdzlnj+IfNQfXJJrZSpvfB21uxbAn6vtedU3lf07aLy9Q/ftXsjZ31oSmFjBXlZONZbpx4dqHnyCQCj+y7R8DNFV4SktF2MomqYfYKPQWRB0d6LEVfQwGcHCMBYZahYTbL+GHnguqf3pFRy82cwlPiBDcEM4ZqtQxxWh5xNZjRG1DtlOytcDyC3VuZORBh7q2zt0peHSJE9vKuXB7aO0jBexTvZuYER2scYyh8PT48cl4L/VuKmXIzp4+p8a70hkwub3LvzTAH4mRXn754Ocv18QfHOwhiWZpTlPeiOytXgxm9939oeORqxChcDa7NpbGbh87C+8bxvvjUIrFJyosv1AabMHi7KOeNE2/8nFqN0fxOkSp51+i96nDmqNCBzC5OcxiRKDSEYSl4aLCf6M24OijAlnR56FDT5bDq4ViqvTyoWhgoXlmcu8vbpjoN1bIQW5BIAH/o0tinY9vlzp2phIaCrWT86VstZ1VGe+OlAqFq2NuYEzcP+PLBMXZn5GFPERlD4aZwba6O84ox2A+tZvmwOfvWn6maI34Ie8dlq+C87MwLZQwka/Pi2Bl2CavnEjcUvPWMN/nbKjMHmqVlQ+tVQ/9p9fs+fS9vA28fer+hsLzfltLVgdzDy3t42ZiFCl9+s9onaB8oYih4T22ppPfy6ZVmG+fUIuu9pYV2Xy3fq4Bzsl4FVveaE54Ce4MunMJ5VWQMhZtSzb53K1wNHdZufoq6801npA4Q2xwPb+pgd+FLQ/fjpWVhQ8kZK5NSlI5ayP7omauQXdLVg9pHNAp4h2Ys14vQhWy7maeEKc3sBy1L0IwpJFcITuQGiwiSclvGt0m8fK97ruFMzrZU4CXoL6HlN5P3KxyOJOWzEhy4mVOI+1QANoNHoVj0Z+toja6cPtMhcNFPRF+X7nlUIcThZk5hj78QIALDI4tFf2+1bat9gCZxXijoAV6NPVQSK0GEczM3n8m+uJkNRhMc/pCfkz0a8EqcyO1lPBocibkKZ1fklnAzR7CHbJxdFygQuh4AAAAgCF0PAAAAEARDAQAAAIJgKAAAAEAQDAUAAAAIgqEAAAAAQTAUAAAAIAiGAgAAAATBUAAAAIAgGAoAAAAQBEMBAAAAgmAoAAAAQBAMBQAAAAiCoQAAAABBMBQAAAAgCIYCAAAABMFQAAAAgCAYCgAAABAEQwEAAACC/Hl/EdM0TdOklGqapmma/QXuoaqqcysAAABvzjzPZ1chJ9Xm8+n7fhgG75+6ruv7fnuldlBV288IAABgJ+U1Q1u6HqZpqqpqmqZxHOcF4zjqDc6yFQAAACAXGw0FbQ14OxqappmmqQB7il4MKSgmArlEIJcI5JKCYhFK85CU5/MBAIAbUV4ztGvUQ1VVdDEAAAAUzC5DYZ7nruuGYaiqSvc4ZKrVJcATJQXFRCCXCOQSgVxSUCzC3jwKfd/rAEalVNu2JVkMhfmODgDFRCCXCOQSgVxSUCxCtq4UnU3BHjA5juPxaRXK6xwCAIAbUV4ztNejME1T3/dVVbVtO01T13V6kGTXdW3bZqniWeCJkoJiIpBLBHKJQC4pKBZhl+FjlPVmWKqq6ninQnmmHAAA3IjymqFdKZzjdkBhSgEAALwhu7oevAMjiwlmxBMlBcVEIJcI5BKBXFJQLMJGj4I2ER6PhzMR1DRNj8cjR8UENXlRIgc8IlJQTARyiUAuEcglBcUibDQUbJ+B4z/ouu6wuAQ9zuIKs1YCAAAUyS5D4cReBj3a4qXei/ICUl4NiolALhHIJQK5pKBYhF0xCufGIjRN03Xd68rnppGCYiKQSwRyiUAuKSgWYYsNVVWVHg/ZNI33m/5IxZ1BmFmtQmJb4vBcAQC4lOec2NL1YKIQ+r6/4ACHbcGr+rqaC1xVVVkX+hWcZUjNz5eJhbdY0M/16dW4y4LW6vRq3Gghr2KFcfuzql7oUbgclWmbqzPPcZ6v7muJ24oF3yEAcDrlNUN7Uzg3TVN9vpX18gV9DMUwq/nj34+lXf/UXCX9e6aq5j3/VKU2/ksXKn7W8cMwnBoAwGJXZkYdo6CnjlRKTdPUNE3btmUYU+VZhUvmxDiDta0qVaU7OapwcXPcHEhpwfdfsTnxSJ/Y20pumHe4wTKCXCKQSwqKRdjlUdBWgpNwSZ09GiIX3DTpOE6ORM/EkjT/xlypuZoDfgO18d92P4JdjMQ9wg0mArlEIJcUFIuwy6MA4CXoqAisFjkkPvdZsTukT33kNVEFjIh9LxapYcJbDADOYZezRXc92CUs1xxMRvcRnigpxyiWN4QgY30deyJW8MtFKvC+5XkUgVxSaDsi7PIo6KAE5/1oQhbuTmFX+gCOUSx0kG1DQlLNDst/EfKXLE8/5IpYehNyWxXpxtRtbnKeRxHIJQXFImQwfKZpMhmdT59zoTxTDl7Bls4OpVLCLNw9oi1x0JJYKXPb3/IcAQDilNcMFXc+uI/Oo0jFYk25xG5YWgyb5VqaF4JSfhxxg41y5sUt8u56HcglhbYjwpZRD1VVac9BFSBzHU+isCt9AEUq9pl6wUc12/+WYzCetlWV80/NvpVJVXLRB0xKOWEfSpypYmteixwUeXe9DuSSgmIRtsQomCGRxYQjAMRZvkOW9rDPQv54+SRaAMstUxNd2Ad7qpIdWpF0+EDRKVvzngUoky2Ggo5hVJ9zPeet0HUoz330at5KMedEg2GLH+vn5V6OXF5jImJhpNgQzuVI8fYlmQT+7VYL3zec9J3urv0glxQUi7BFmqqq9LxQbdt6nQonhjRyseEirDbKq/dpuh9CCX0PT0dJ6yt8QQQlzymUSXnN0Jbz6ft+GIbIBmXkUQDIyH674UdRW+MDcg3BED9gSTvw2EIhlNcM7TofZ+bGK0Dk6omgWCJrk1sKS9sXV5juisjge0jdwrMdd5cI5JJC2xGhuPMp7gpB8YjGCW27u9ONCVEXhmiIU7Dc7c8rTzpckfKaoS3BjH3f69xKoUjGgiMcAbJjXikpza6zTeLryNv8r4ZPrhoNogkyzO/PoSCV+wfrwGlUoq0BYBsbRz0opZqmueYskeEpfGQvlPKswleDYiKWcq2HNyaNydxoPSzthpAfQjrgwnkk9U//raK3DI7S9GaL2m5oFAwPoxQUi1CaNFxseB/yxjq4ha/1VmwYZ+E14j0PbGKPBjGScEnKa4b2no/uZdD/NckVdtdqO+VdIYB0UlrYPc9HSqzDqgERiWwIPrx5TAfeDHAE5TVDW1I4G5qmscdJ6jmmi0nhXMyJHAaKiXiFXCZ9dPS426fq9mandstfdUWYzNOeugXSwM+z7q5w/y2OHc0xfVr+6ePhYZSCYhHyD488d8xkeaYcQC587W/W8qMN8LYsDoLHOfKif8GIC4AQ5TVDW4IZbS6VRAEAIjijDdSibd35cpvVHLEV4umozYvVG/moUiyG9OhIO3H2828AWLKr60EtRkKaARE7i70CeKKkoJiIs+SKdE+4c1nKK7icQnO1q0I5YzIDHRMbp6j19lN4Rm5umUzzyvAwSkGxCLs8JNM0tW2rlKrrWo+WfDweXdedmEehPJ8PwAEckPTJf9yE3orUjJCiaukyZSfCiwWSKK8ZynA+fd+bkQ46F9POAvdQ3hUCOIWMk1OsHEieNTJpGszN9asqBl7CHsprhoo7H/J1nweKibijXKmjFHeflmgcpmA6qw1eB/WSqTNfzR3vrnOh7YiQIUZBdxn2fX+6OyEvhV3pA0AxEXeUK2X4pVK7ohw+DpQQ5WAOMj8TrZgkxOHH2c5KzYHQhYvGNNzx7joXFIuwa9SDnm+66zrd9WCMBhQHKJv0xEi5BlZEEk677ofZt/3mwRQ/irXDIb0hDiSThjLZ5VEYhmEcR9uRoJ+6a84BIYUgWCkoJqJIueL5kJTa7mlw5ErJ+2T+qYTBFLLa2J6Gj3+BWpzkaSjy7nopKBaBPApB8ItIQTER7yDX8iPc/ikSwCtX+qyYy3IEU1WlVdAUZP/6qJGzzet5h7srLygWgTwKAHAEnnQGu9M2+A+0iGywXQtWfTw+ho0Ohudy1RwJaAC4H7s8CuM4tm1rOhr0XA9d12Wo1wUg2EIKiol4W7mWCSINETdDFrk+uiGev+y9Pga3p0N6aHOSbu5HK1PkK6/+295dm0GxCHsnhRrHUSn1eDwej4dSSocsZKnZ6XDTSEExEW8uVyiaIeRm2CaXd9CE18GgPn0M3nJ2hTLMiyCGjxW5fSlPR37ru2sDKBahNBsKqxDgvsTmdcrxWG+YtsprHOx4yYQr8Ho3AxxDec3Q3hiFaZqapjHm9hXcCVWADeW8onoFg2IikGtJZNBElg/v+NwTG0IZ5O+W8CiJ+aPoLFEb3F1SUCzCLkOh73s910PXdeM4dl03DMPpkYxzgA3lvKJ6BYNiIpBrlZC5sN9oiGdz2twxIWlsfEMrlyMut54td5cUFIuwy0NSVZUzBZSeJupExcvz+QCAWsse/eqJJ4JOiEC1Nr2FAmf4Y3Alb7Z7UF4ztNdQ8CYwGcfxLL8C+bpPBMVEIJcIW66UD+w90krNhY+9wtWSX+hlhku3xJX9ubuE0HZEyJxHQXN670MWCrvSB4BiIpBLhC1XPPmjZlcqhECvhLdLwq5hvr6JQK+EVeLK/txdQlAsQp48CtpcmKZpGIa6ru3MCnsrCAAQZvl6N22oNPmjv/zPgYw/yv9c9joYlmGPi+p5oh9ix9fHXP76SAFJ8wYvZ2/XQ3yD4/sgcB+dCIqJQC4RIrms7AtZ6+BzJ8T7I9wSou/M6AlW3kWz5/JA3F0iaDsiFHc+xV0hANiA3SJnfyW4Qyi3TuIgj4W0t5+zTc0JWSmvGcp2PheZ5aG8KwQA23iRX+HpEFbLvdlc+CgqNWl01FZQmAvnU14ztDGYse/7qqpMLEJVVW3btm1rr7w75N+QgmIikEvEBrnMu/oWSjuxkOHIx6eYRjUvLIOqUtxdclAswhZDoe/7YRi6rtP+A/3fcRznea7rWqdgKoDCTMIDQDERyCXimnKtzlEpLjCcAvLpsHFzobgv2gNAsQhb7icnz9LyJwmXAOAiHNwB8XGsfd0QKjV8wc2uoPc0m+6sA2yjvGZoe9eDXvCGJpTR+4AnSgqKiUAuEfvletlMjZ4pJPZ7F0IZ6J8dDAvXwod34WPTe3S6XAOexwgZJoVSF4hhfAWFmYQHgGIikEvEZrnieZnykjhtxJaSfRNT/Tisrypmu/1Hfwd4HiPs9SjoDEtmfcF2AwDcF9tceJ1rQQUmqHydufDjsN5kjh+Hx1aAXWwxFMwskdqktbsh2ra17YZbgydKCoqJQC4Rr5DLmdI5r/XgNRfylPxjzou1YRF8JCfD8xhh46iHcRz1shn7oKectvM33x08UVJQTARyicgi1+oMEWphPew94iJ2YW+Jz4SHRTwvvtSLUgQ8jxFKC84sL9wUAI5htRnNNSPl/jERH2WuTBvx/NcnQ4KX5Asprxna4lFI9Bmc5VqoAmwo5xXVKxgUE4FcIg6Qy56U0ut42PNZvhwTsaOmn2WGx0RUVeV2PMxELcTgeYywseuhqirvBNOaaZqapjkr89IcYEM5r6hewaCYCOQScYpcqxaDqHHxDqHMUc2IOLPHXPg4PO3iEzyPEbZMMz1Nk55auqqquq7tMQ7TND0eD6VU13XFBCsAwJvznPbw6U/SyaxnNadPWi0o9tmvoKxP5M8/LeaqJjUTpLG3K6Xve20QPB4PbTRoslRuA0wVeiIoJgK5RFxQrp1zN+6ftDpYcjB2YXHEj7xN1xL2FGg7IhR3PsVdIQC4MiEXvug9lGveardY16nwebTF4bEVMlJeM7Q3MyMAwDsTahGk4QtP+74244I3cKHyGBAASikMhQgEwUpBMRHIJeLKcoXGSoiiHfNmXFjKtVizMBc+DntdnV/KlW+w0ynNQ1KezwcAbsey0Ul/LWXPuBDogFgc1vyfV+g+ymuG8CgAAGRmOagy3buQPZNjWqM1//g/39bwDIZCEDxRUlBMBHKJuKNcXnMhacfdtoJXrlQN562ZIu7MHW+ww9hlKEzTlCUH4jUpzHd0ACgmArlE3FeubYELy9RMIoshJFf0/ZwjLPO23PcGO4AtCZcMOveimRcKAAC86GbItLkpaZqc1ExqR3ameZ6NiaAXwtNVVx//VwyDgA92GQpKqXEcS7USygtIeTUoJgK5RJQhl2MurG//aRB4LYaIubCUy7YVvBt4D/9xWL3j/fWPUMYN9iJ2SfMKZfUUEvH0jjodZNM0y/kmuNgAcHFsQ2FPPsdtYyK8vQ+L16Zv5klerWmU1wztilHI607QEQ96Iom2bUOTTlVVNQyDUmoYBr19rgoAABzMnpmlNsQuqM9p8xbVWGZZWPBOsY1gs8vwaZpGTwHlsK1MPcWUbvj7vh+GYVmOs97exawhX/dZoJgI5BJRpFybZ4tYnSciXS7bRPDtUnkWi7sQirYjyq4YhchM0zsL1AaB7l+IbF/Xdd4K2BR2pQ8AxUQgl4gi5ZrnJ1shfSLKUOyCVXKqXE6c42LH+YeBYIcsFHc5irzBcrHLUMjb77AscGkoaAOi7/umafSU1l3X5aoDAMDBbBgN8bT7xzwNu3oENtoKqkzXAniY9zGOo/1Z33Xd5nKcyiil6rpebmlbBssNduqgnjvwnDUsxBdQjIXXLYSe02IWlHr6J9rd3tXWasMjHNbZ+mcd8ArSZVnYpph3wfwshl3BjH3fm1QKmmEYMroZlkVN0zQMwziO8zyP4/h4PJbbbBPC7GsX4qxhIb6AYiy8biH0nBazMC/yMqXv7mRn2vkwqkWuhXmelR3e6Cx6Nr7fwh7FvBqWxK6uh2EYuq6zIxWaptGmw4to29bkd2qaZhzHlx4OAOBI5vmpG8KsXN/Rys60mmUhfPR4Xqb5qQ/i82AfdS20jQS1f64HJ55RN+Ebhix6dzw3lVMxuagPA8VEIJeI95Fr2eAmzrrgWAbbAhecb+L1yal/WAz3vkDvc4NtYK+h4LUJtjXwdV0b94BJu2R+6gPp3g2zS/ZhFzalOpFeB4qJQC4RbyXXbAUE2KyaC3aWBbXDVnC6IdbNhfvzVjeYlF1dD13X2X0BOoBg85BFM8WU/qnDG02x+hDaYrDvWrMZAEB56PbLGUWpov0RubohlPWdHeuJmD+OxFCIUtmbF0KPVzQ/nfRHG/COk0zfjKQZJ4JiIpBLBHJpEtM/V1W1tA2ypHx+vgq+TM/xml0V2o4IxZ1PcVcIAMBm2fsQsxie2/JttoJaSeD4LtkbEymvGdo7e2TGGAUAAFhlnl1bITLmwMnIlGtAxMpoCOICy2KLoWBmWAiFiZZhTJVnFb4aFBOBXCKQy2aZccHBkcuOWlA618LrbAVTrVtdL26wCKVJw8UGgLdCNGl1xlmqA2/ayvl/UrXKorxmaG9mRu9Kpn4GADielPGTPzbel2jBN2zy6UhP1YI7szFGQZsCeryDHZFgD2W8O+VZha8GxUQglwjkChEYPxmUyxk8uTm88fNYkXiF5zST17583GARNkoTMST3j5DcAxcbAN6Wbd0QWYZNqqfOiLceB1FeM7TrfC4oxwWrBABwGN6PuNBLcfMgiM9jhWyFcvIrbKC8ZmhXjIKjRWGhCaT+loJiIpBLBHIl4m2h4uJtC1ZQn8mel9NOujme7zAfBDdYhF2GgpN0ue/7qqqKMRcKMwkPAMVEIJcI5ErHO1XEi2yFzyMubQXl2grXvoDcYBF2GQpt29Z1bfSdpknP/pCjYgAAsJe4rbAzkvH5QN6iFlNNpsyDCRdjb4zCOI7OGAfvysOIuI+kZ1peP9OrQTERyCUCuUQ4csWDHHOleVaxLAvP+RWudymZ6yHC3hTOFyTXFSrsSh8AiolALhHIJcKRazmE8nXH1bZCcNjkIoXjReAGi7Cr66Gu67ZtTVDCNE3akVBGHgUAgPLwdkDof7kPFLAI5ktHNcKSvR6Spmkej4e95ly7DPfRiaCYCOQSgVwivHKtZlnYn+DZroB1rEV+het1QNB2RMhzPtqpcAVHQnlXCAAgF86XfCReIaOhoJa2QtGZFcprhnZ1PWimaSpmSCQAQMGstl+5OiAC+RV+HObioyXBZlcw4zRNzmDItm27rvNOFnU7yrMKXw2KiUAuEcglIiKXHdgYmYFh/zQQajEztXIslflCc0Bwg0XIk0eh6zqlVNM0XdfpmaIKgJtGCoqJQC4RyCViVS7z90hYYaWqnYmYljXR1oL1553FZ4MbLMLergen00H7EuiJAAC4OCFbwXEk7DcXnG6Ij4PYR4Brk9lQKAlSf0tBMRHIJQK5ROyUazlaMrtr4Wq2AjdYhAx5FOw1JeVRwBMlBcVEIJcI5BKRKFe8A8IxF7L0RKjQZBBn2wrcYBHy51E4MX+zIiAFAEDC6oBJlS/HsyfBc1U9F1bC27u8ZijD+ZjhkU3TnO5LIGnGiaCYCOQSgVwiRHKl2AoqU4oFv62gjIVw2iWm7YhQ3PkUd4UAAA5A6lrYZi6sGQqqAKdCec3QlhiFqqq056CKcrp3AQAAEnGaNu900E7IwqajzJ/lEzx4G7YYPmbyp/iQh7Ztj49XwH10IigmArlEIJeIPXKlp3lWufwKF3Aq0HZEeOH59H1/fIrG8q4QAMDxpM8gtcFW8HRA6CI/Dygt8FKU1wxlyKPQNE1VVX3fT9NkWwZlJHIGAHhD7G2L9FYAACAASURBVJYu3g2xoQ8i0AFRVONaErsMhb7vdR6Fuq71mmEYTg9NCMVMbCjnFdUrGBQTgVwikEtEFrlSohY+/rQjC4Kvqidca26wCLsMhWEYuq4zIQtN04zj6KRVOJ45wIZyXlG9gkExEcglArlE5JJrnj3mwo+/7kjH5J9bsvqxSlbR3XCDRdjb9eD0L6QEOQIAwI1wzIWQraCErgVP20xrfUleMtfD6b0PWcATJQXFRCCXCOQS8Qq5IrbC5hRMwdGS89FOBW6wCLsMha7r2rbVYYyaqqpMvMLdwRMlBcVEIJcI5BLxIrlCtoLaF9t4BbjBIuwdxdH3/TAM5mdd1+f2O5Q3LgUA4FIYE8ENX9g6YFJ/zVuv7nsPhSivGSrufEiacR4oJgK5RCCXiFfLlddWuIKhQNsRYVfXQ1VVBcctFnalDwDFRCCXCOQScbpcGzognqafPrz74nTFrswuQ+H0jgYAADieUKu6fzKIBbeMeCiMXR6SaZratq3r2hnmcGJORtxHJ4JiIpBLBHKJOECuSI7nDR0QvqTOh2Z0pu2IsOt8mqbxplc6UaPyrhAAwAWJTwYhtRVisz9UN8uvUF4zVNz5FHeFAAAuy8e8j7sNBeUJaVQ3nSaqvGZob8KlgiH/hhQUE4FcIpBLxOly5U6r8PLTOV2xK4OhEKQwk/AAUEwEcolALhEHyxVvZHfYCuEET7nhBouAoQAAAHuJzEOtJLbC4st+dv4Px4OhEARPlBQUE4FcIpBLxGFy2fNF5bIVToEbLMKWmIvV3AknTgpVXhQJAMDFCSVq/PhrcmCjL57xs4zPI2yr4ZGU1wxtOZ9Vy4vhkQAAb0WKrZDDUFDXtxXKa4a2dD3Mn4zjqJTqus75mbmOQqoAG8p5RfUKBsVEIJcI5BJxolz7j+yrvHfMZE64wSLsMnyqqhrH0eloONeYKs+UAwC4Bau5GhM9Cirolr5HB0R5zdDeYEZvOAITQAAAvBt24+j9Pq9UFQ9pNO2r3w1ceZbgADIbCtpEODGYMSN4oqSgmAjkEoFcIs6Sa/+HtP0tfuRZcINF+POencdxbNu2qiodlzBN0+PxOD1GIReF+Y4OAMVEIJcI5BJxolzz/OFOqKofdoPudEgcITnPs2m2XTd+pX6kfMzaAcENFmFvV8o0TX3f66mh6rru+/5cd0J5nUMAAPciNAJCNAGEJ17hY2IJs8lFX/XlNUPFnQ9ThZ4HiolALhHIJeJ0uby2wt4pJX8U+vS/LNB2RNh7Pn3fL0MXTwxmLO8KAQDcjtAICLv3YcsgiDs4FcprhnbFKOirWNd1GdGLAACQBROpoJ6DFYSFzG6MoV0uHMUuQ0EptcyjUAzlWYWvBsVEIJcI5BJxBbm8bbod1VipKr0P4sfpfCxkNheuoNhl2Ztw6WrKXrBKAABvy0dfQSCqUa11QIRTMF03+VJ5zdCuPApd15XqTgAAgBeR6EhQzymYApvQE/Fy9nY9PB6PqqrqurZXlpGZsTyr8NWgmAjkEoFcIq4m1zJMYVazdOLp55Oa85oIV1PsUuw1FBwTYT993yulmqaJ+CqmaTIpIF/n0uCmkYJiIpBLBHKJuKBcoZDG1UgFT0jj554Zux0uqNh1uJANNU1T27ba8tAZHrXR4ND3/TAMZjMnmhKrEADgUmTMv/ScpbG65jjJ8pqhXecT6mLY9pWvuzB0mdoaWNZNGxPGOGia5vF4OLnBSZpxFigmArlEIJeIq8nlDWlUElvBn1Mhn6FA2xFh76gH7/ptZTqTVnvnsA4ZEHYhhV0hAIC7s2ooaCLmgn/4ww9b4UKv/fKaoV0xCkstvIkaU/BOOzlN03KN9jocEKMAAAAvJT2k0UQqlNcM34A5N9vKHMfR2VEpVdf1snBNXdc6TKHrOu8G23SwF9SnJbT8EwsoxsLBC6HnlIVbPIxKzfpfcJv5c5O187LvhFmpeTb/rqLYj+qVwq48CiFyDY8MeQvmedZOha7rhmFY/nUDZl+7EGcNC/EFFGPhdQuh55SFGz2MBtGfUgrctvvrFCuMXV0PS4PADG7cU2wEZzRm0zRLQwEAAC7FvDZFg+mDSM/r/EHWQZLgZZeh0LbtcmXXdRuK0raFE5SwNDiapjksmxM9YVJQTARyiUAuEW8p1y6T4S0VS+VC0thjHZ3RDX3f67jF5fBI9ezY4GIDAFyQUDaFp21UpZRw7MPTxNOXePmX1wztzcyoPttp7QzY0+kwTVNVVeY+0OGNev0wDMYy6LrO9mQUdj0AAGCV8hrjK7NXa+0GsNfsnHjaO04yfTOSZpwIiolALhHIJeKacoWyKfzYICH/UjTz0iW6Hq4p/h52nY+2EmzLYJkq8WDKu0IAAGWQbiioBFshr6GQkfKaob2ZGZf+A+/KwyjvCgEAlMGqoaC2ORUwFF7M3jwKBSdGDE9/Dn5QTARyiUAuEfeVy9gH0kmoP3bayn0VO4DMhsKr8ygcSWEm4QGgmAjkEoFcIq4s12qLvJpHwT27HCd7ZcVOZ9eoh3Ec27bVsz4qpXRU47Y8CgAAACJ+OPl/5FAgAVN+MnSlmImgmqbRHoUTIXL1RFBMBHKJQC4Rl5XLdifsGf4QDlNQ2wwF2o4Iu86n7/vTLQOH8q4QAEBJpGde+tgsaiv8MBTUVdIuldcM5R/1cC7lXSEAgMLIMvwhbCioc22F8pqhXcGMTpLEwiAIVgqKiUAuEcgl4hZyrU4T9bFZdCxDrjO9hWJnkWH2yKW+ZRhTZZzFkaCYCOQSgVwiCpNrfUpJPT3ljkDGwhTLyy5DwYQxAgAAJLI66/THZp9zTwcKmcNuAMY+5KS0rpSI+0h6puX1M70aFBOBXCKQS8T15Uoc/qCiwQoZxz4w6iHC3rkeQn/SE0NvLnkz5V0hAIAiSRn+8LFlwFbwGArq/JDG8pqhXcGMegooe/ZIs9y27dVGTgIAwHWwJ3XaWkJR7fFl2etRcJIsTdPUtu08z2YhQx0l4D46ERQTgVwikEvEXeSSOhVCvQ9PHgW1JaECbUeEvXkUlrub5AqnZFko7woBABRMoq0Q732YHe/EqZmXymuG9k4KxagHAADYT2JaBTieXcMjdcKlruuM20DnX9JdEurm00iWZxW+GhQTgVwikEvEjeRKHCoZZ//53kix49mbR0EpNQzDMAx6TV3XxscwjuOuqp0NN40UFBOBXCKQS8S95DK2QlUlBSvEvAtPdocgm8K9FDuY0mworEIAgNuRklbBSb70I8fzMkzh1BGS5TVDu2IUlgEK0zQVkzG7mBM5DBQTgVwikEvE7eSyG9ZQ3eNhCk+nLD/72yl2JLsMBSdZQtM0OmRhb6WuQWEm4QGgmAjkEoFcIu4oV0qVZzW/KKrxjoodxq4YhXEczeyROkzharNOAwDAXRAFK1h7MenDa9nblaITKymluq67QipGkmacCIqJQC4RyCXivnKJghWcMAWlHQOb0i7RdkTYm0ehaRo9uqE8R0JhV/oAUEwEcolALhH3lSuxA0Iv+OeW3HTu91XsALYYPqtBHycqXp4pBwDwbnzkVwy/y0NOBd/sUDeeSeAibIlRuHuChETKu9ivBsVEIJcI5BJRvFyzmv3uhK0Ur9geMkgzTZPudzALJ8LFBgC4OykTQDjTROFReB178yhUVWUGPvR9X1XV6SGNVYBzawUAAK+GV/0r2Dt7pJ2zWSnV9/0wDGXEKJRnFb4aFBOBXCKQS0QBcknDFDwDHyT5GWk7Iuw1FJaJE06ZXdo+emFXCADgDblvPGN5zdDe4ZEAAADHszJI8gn6I3axy1DQ00yboAQz0cPpIY1ZoK9LCoqJQC4RyCWiGLk2nMe2cy9GsVew10OigxLMTydk4XjK8/kAALwhKQMf1PPYB1+Ywmy5Ew5qGsprhrKdzxXGRqoSrxAAwHuyGqagIoMkMRTykS1GwVgJTdOc61TIBZ4oKSgmArlEIJeIkuRKOZVomELqXA+pFXo/dhk+ZkYohzKGRwIAwImkp11Sz70PT1NDqaPHPpTXDO3yKLRtW9e1zujcdd04jnVdd12XqW4AAPC+mNY28rU/H5548Q3Jk0dBo4c/nGtMkTTjRFBMBHKJQC4RxcgldSo8xTOa/RMyL9F2RMgTo+DEJZQRo1DYlT4AFBOBXCKQS0QxcmVyKqyrUYxir2CvoaC9CE3TPB6PDNUBAADYCu39K9hlKIzj+Hg8+r7XQx7M3EtXGCe5H4JgpaCYCOQSgVwiSpIrxamwn5IUy07OrpRpmqZpOnf2yPI6hwAA3pzVSIVl2qXnGAWTTeGI1qG8ZihnwiV1AV9CeVcIAADitsIynvHJUFCHjpAsrxna2PXQ931VVSaGsaqqtm3bti3Je1PSuRwDiolALhHIJeJt5TIWQ5WS1tHe8V0VS2GLoaDnd6jrWimljYO6rud51gkVTncq5KIwk/AAUEwEcolALhHlyWVHKizb9KeBD7FTD1oD5SmWkS0eEm0ZaF+CNhpMITpX47l5FEJ/4j4AALg1iR0Q+sdZvQ90PXxgIhYv6D+YA0jLwRMlBcVEIJcI5BJRqlzxF/msZk9OhbSXf6mKZSHbpFDlUZhJeAAoJgK5RCCXiOLlyt6sF6/YHjAUAACgQHAS5OLP23ZzkiVcsANiP+X1M70aFBOBXCKQS0TBcjkTQ4a3C0UuVt4whYIV288WaVYTNpcxKRQAAFyQ1JBGJ54xYWqoLJTXDBV3PsVdIQAAsLE9CjFbwTUUDsrPWF4zRIxCEPq3pKCYCOQSgVwiypYrtRWWNNZlK7YTDIUghZmEB4BiIpBLBHKJKF6uxPMLNP+elcUrtgcMBQAAuCteS8CTTcH8BeRgKATBEyUFxUQglwjkEvEOcuV1AbyDYpvBUAiCJ0oKiolALhHIJQK5pKBYBAwFAAAACHI5Q6Hv+77v9YxTcaZpcvI+5QVPlBQUE4FcIpBLxFvJlXqu0e3eSjEpFzIUpmmqqmqaJj0F5aoR0LZtij2xGTxRUlBMBHKJQC4RyPWBliFBDRSLcCFDoW1bPXv1NE1d1w3DENkY6w8A4M2hcT+GCxkKyppCQi+EHAb6r3Vdv7Qy2CJSUEwEcolALhHIFR4h6QfFIlzFUNA2gTO5lNdQmKZpGIYD3ER4oqSgmAjkEoFcIt5Nrkgrn2gBvJtiIq5iKHjxGgpt247jGNmr2oTZlwUWWGCBhXstGCJ/WnJAfcpg4zTTx7Ccvbppmrqu47Na7zEMzb7zPFdVNc+zvYaF+AKKiRYMF6nPxRcqa6IdFlYX3uphtFvnJxF0qmb3gQtsnFWxwri0obBET2+tDQWz3Pd93HTYRqmX/HWgmAjkEoFcIpBLCopFuIqhoFv6aZrsJn/Z/HddZ5aNofAKKwEAAG5EVSmnrZ/Vp1PBt3nM1QDPXGja7KZpHo+Hrk/f93bEovYZOAaBsS3slVW+icAzFvUmoJgI5BKBXCLeTS7T++CctDEUZmMw/NjgaVPajghX8Sioz4RLJhjERCzqYQ7Huw0Ku9IHgGIikEsEcolArjCzYpppIZczfLzjJNMpz5QDAIBV9Dem61GoKu04mNVsbaENhVe1FOU1Q8WdD+6j80AxEcglArlEvKFcXkNBffY+rBoKtB0RLp1H4VwKu9IHgGIikEsEcolALikoFgFDAQAACqHQjEcng6EQpNQcW68DxUQglwjkEoFcUlAsAoZCEDxRUlBMBHKJQC4RbyjXzjN+Q8XSwVAAAACAIBgKQfBESUExEcglArlEIJdDOEXj5wYoFgZDIQieKCkoJgK5RCCXiHeWa1uL/86KrYKhAAAAJeBt62fmdNgNhkIQPFFSUEwEcolALhHIJQXFImAoBMETJQXFRCCXCOQSgVxSUCzChSaFykXIMOQ+AAB4B5ZTTiulqtmaQxIkFGgokK/7LFBMBHKJQC4RyCUFxSLQ9RCEm0YKiolALhHIJeJt5docz/i2iqWAoQAAAG9BhTGwCQyFIATBSkExEcglArlEIFeQH8pUz6tRLAiGQhA8UVJQTARyiUAuEcjltPurvQ8oFgFDAQAA3gpsAhkYCkHwRElBMRHIJQK5RLyzXNtcA++s2CoYCkHwRElBMRHIJQK5RCBXDJ9NgGIRMBQAAKBA8BHkAkMhCJ4oKSgmArlEIJeIN5drg3fgzRWLg6EQBE+UFBQTgVwikEsEcmnSW38Ui4ChAAAAAEEwFILgiZKCYiKQSwRyiUCukIMglJwRxSJgKATBEyUFxUQglwjkEoFcUlAsAoYCAACUjy85I16EJDAUguCJkoJiIpBLBHKJQC4pKBYBQyEInigpKCYCuUQglwjkWmFhFaBYhD+fXYH8hAxD7gMAgHejqjYmdQZDgYZCLoOgqipsCxEoJgK5RCCXCOSSgmIR6HoIwk0jBcVEIJcI5BKBXEo4QhLFImAoAAAAQBAMhSAEwUpBMRHIJQK5RCCXjRHDN0LSbINiQTAUguCJkoJiIpBLBHKJQK5kPuwDFIuAoQAAAGViWn/8BXvAUAiCJ0oKiolALhHIJQK5EnhyIaBYBAyFIHiipKCYCOQSgVwikMsQHPvwbBmgWAQMBQAAAAiCoRAET5QUFBOBXCKQSwRyxVmmUkCxCBgKQfBESUExEcglArlEIJcUFIuAoQAAAOWjXQaRVAoQAkMhCJ4oKSgmArlEIJcI5LJJcRagWAQMhSBxT1Rl8fPPPzs/9Zrl+tAuoZXezUQbGH755ZfELTfjyHI6R90pG8HVKQK5RCCXFBSLMZfFYWdkDvTvf/9bKfXvf//b/tOXL1+cynz79u3bt29m2dnF2dHezHv0ruv0oe3t43z9+vU///lP4sYFUN69DQCbUWo2rwQ1f/RAzLP+l/1Ypb188CgEEX2Sfv/+XS/8/PPP9nrz86effjLb/PTTT9++fTM/bX7//Xez/NNPP9l/mqZpmia9PAyDWdYODGdL++cvv/zyyy+/pJ8LHMP1fR6XArlEIJcXWxVn4AOKRcBQCDIne6K+fPliGvjv379rT4BS6tu3b7/99pt6th5+/vnnL1++fP/+3bYJDN++ffvHP/5hNtMrp2mqqmqaprZtjbmg//v7779///79t99++/r1q72l/q9Sqqqq33777X//9391TeA6pN9goJBLCHJJQbEYp/oz8nPYmSqr6+HLly/fvn3TXQlKKbtHQG9m9zt8+fJFb2kWnDL1vrpAvaau63Ec7W3qup4/ez3s9UopveU4jnVd/+c///n69avZgK4HAHhbPL0PdD2k8eeXWiGnMGcyDKuqSi/q69evuivBuBM0X758+fnnn3/66SdT1O+///73v//973//u1Lq+/fvf/vb37wF6q4Kvdnj8ej7Xq+v69op39mxaRr938fj8T//8z9/+ctfTA0TzwWOQXSDAXKJQK4QVeUfBIFiEeh6CCK6af72t7/pXgCnPf7HP/7x/ft305zrDgVjpnl7H75+/fr161fbAqjruu973emg7YAQdV2bjom6rr9+/fp///d/+k90PVwN3koikEsEckXwRiOgWAQMhWx8+/bt999/dzwE2oAw1sP37991CIJG+xuccnT4gr2Zjk5omqaqKmMoGB+DTd/3esu2bfu+/3//7/8ppf7yl78YvwIAwHuCJbCZ0pwtGd1H8aKO91M57oSId2HV8fAOXN+ReP0aXgrkEoFcIT7cCXOlnuaZng9rO+5Icedz1BUq71YoDC4QACz5TORcVU/JnHO+K8p7+dD1AAAA7wiZExLBUAhC/g14KdxgIpBLBHLFWaqDYhEwFIJcxHc0LVCL3IuR9d7l+FFCu5if6cVChIvcYHcBuUQg1xquPigW44U5Gs7gsDNyDvRHJpYH6rqu6zqdPkEv66PrBVMZnYLJrpXeyyyrz1xModOp69o+0DzPetk5ZV2UWWkng7oU5d3bALAfnXbpc7KHl+RcKu/lU2DCpVxcJCBFD4Ps+75pGntIpPf7XudR0EMepmky2w/D0HWdTsYQOpBdoJ3fqe97ZyhmXddN0+BL2MlFbrC7gFwikCvEPPvzKKBYBLoeglz5prHzM07TpL/ylVJ2o/54POxBkn3fPx6PlMLt0ZV93w/D4GxgDJENNQfDlW+wC4JcIpBLCopFwFC4K8bBMAyDadd15malVN/3tvWgl7V7IFRg9ckwDPZm4zguszLoHFC5zgUAAC7L5boedBPVNE0kZZB2oTefvKgmIk/Un/6UzeRKPKjujNCpmu31Jt+z3e9g/pty3P4T/VMrvLQwuq4jrdMecHWKQC4RyCUFxSJcyKNgJkfWX6uhb1/9yas+P2ojn8g7ucVNswwg0J0Fpt9BdxCYmJSU3odl/ME0TUs7Qx83sTsDltziBrsOyCUCudapniRCsQgXMhTattWxeLrT3fsFrBuneZ7jmx1PxlEP6QfVHQ3OZ73+afod7AgGtdb7YBfrrBzHcbklYQoAcDswCaRcyNlSVZXdHe781DhhdNqpYJ/CWXM9ZDxolnLg+o7E69fwUiCXCOSKY2Z8+NSIuR5iXCVGQbf9jlmwnNwoklAoO4VdaYOTVUmtRYTAiyj1BnsRyCUCuaSgWISrGApe4naA7oy3/eqabR/l+i4xlmDKwv6DnsK7mQWia8oCCyy8w4KTmTH7IQrj0oZCZBplPTbPO3Jvz3Uy+87zhyfKXrO/fDieyBU8d+H6NbzUgv0KZmF1YfX19eYLzpdddsUK40LBjIn0fd+2rc4x/NIv44tc8sPmeggdOlST5QarRwGbi9xgdwG5RCCXFBSLMV8G9TwZgfLNTaBj7+NzFrykcmsHyjjqweGwuR6Wa/TsD+ZY+uhm/TiOzmQQq1fnSC51bwPApVCf0z3MzPWQwIXOx251nJmHdLNkthmfsQvJeIXiRR1mKGiMiWCObowA3Tzrn/YUTfaybuzNLquno42A5bKzpbkc3p/ncv1n9fo1vBTIJQK54qjPqaGMoXBY23FHrhV5UVkdRyb+QEck6J+VL2bQPoXDYkmcA+U6qPcElTU1lP5pDxPVK02PgJn5ya6hXo6Is/xTVVV6HqnIljou0nRAVFWl8zRcIViy1KgiANiPedHO88dAyayFl/byuVaMwjzPxklgz19gfnqNnRMrbKj+9Kcs/1Ty6Inscz04zJ8RZFVVRSIPzBGdzE4AAJflGu3GbbiWoaCuNHgv9HG/vcCspWnPwRSe68HIOAzDMAxVVT0ej8RgQ+Or0KZbfP6nruu0J+MiF+4uZL/Byga5RCCXFBSLcOnhkeci8lXMf/yxus0fCe4t6c3qnetBt+vOXA+i8k0vhgoPUrWP6E0mDXEu4gy7C8glArmkoFiEy3kUIJ28cz1Un2jjY/qcn1MHK8Rr8ng86HcAACiS0mIuMkaRxIs6OJjxLJZZtO/C9eOJrl/DS4FcIpBrFf2uNcGMh7Udd6S48yl01ENG3mSuh/KeVQDIiGMoZC25tJdPcedzkqEAV4MLBAARMBTSIUYhyNV6AaAwuMFEIJcI5JKCYhEY9RDkIibhckCjznFkdxZMn5N0L9ebnynRBuZY9l72cb1F3TeO4VwucoPdBeQSgVxSUCwCHoU87MmOGU8eZUYqtm1rwgvatrUHL5ifdsIDe+Sk2T1yCnq8g86DaRp+c9C+703mJfsoZhQlAACUSa4W7iJkPKN4Uc5f7z7Xg73xbM3IZZ+mPSWVWenMBHEdrn9vX7+GlwK5RCDXKsz1kA4ehSDzhT1RdjZGO1OC7UVwUiz0fa9zLXtxNp59U3jTxZCXK99gFwS5RCCXFBSLUKChUAV46UHzzPRQ/alKTvT8orkedBeD7obQa2wBMRQAoECIZIxSoKEQcp5Iy8lvW2Qt70VzPej5Hew0i7aAiVNFQApEWYtALhHItYrTJqBYhAINhVyIbIs/5j/W//2xvs0sHM7rnethGAbTlWDmetCEeh8cZ8MwDMtt9KgKvbGxGDAdNoOrUwRyiUAuKSgWgeGRN6ZpGt3vsBzEGJ/rYdkBoT0QVVVp/0Ro4gYzq2TbtnrLx+PBAwYAUDClJZBirofDuHhs4/WTo12/hpcCuUQgVwpV9ZmZsVJV1td4YeIXdz6kcF6DuR4AANSzoeDGLOwqtrSXT3Hng6EASikuEACs8cNQUCrjdA/lvXwIZgxyo14AuCPcYCKQSwRySUGxCBgKQS5iEk4L1GKsQWS9dzl+lNAu3pEOjHrYzEVusLuAXCKQK5Gq+hAKxSKU5iE5q+vhdcGMeoTCNE2Px0MPRtA5kbqus3Mi6SGLdq1MogX1OWZyHMdQLIJerwdQmIEMOn2TKVAXrosyK3XepwuGOJTn/QOAvLxopunyXj54FIJcxBOlRzM2TaMtA2MceL/vnQwHZuNhGGzDInKgaZpse8KbzLGu6wtaBrfjIjfYXUAuEcglBcUiYCgEubJJmH2uBxuTB1p9uiKWGyg6HXZz5RvsgiCXCOSSgmIRMBTykGemhz8JjNoXzfWwxNthoWejlhYFAHBV8CgEITNjkBf0M1UZu8F0f0Rkrge730EFsjKnoK2EpYXRdR0dEHsoryPzpSCXCOSCjGAoBJHN9fBHysZ/rBoK0n4y71wP+lvfmeshvXwdD2Gv0WGSy0PbnRQghfe4COQSgVzp5PyAKxS6Hm6Mbqedz/qUuR68pbVta6aTXm4zjuNyF8IUAOD2VNgJK5TmnmKuB9Bc3/V6/RpeCuQSgVyJvGKEZHni0/UQRHSlb9TAv8lcD9ensFfJq0EuEcgFGSnN8Ik02HnPtDybsTC4QACwCh6FFAr0KJQ3VajtAPB++jszPmefANpboK6VWb/0UjgbvKJit+Y6N9gtQC4RyAUZIZgxyHUes7ZtdX9B27YhQ8G006aFzlsBZ01VVXoQpl4wdWjb1qSOdnIt6J/EPxquc4PdAuQSgVyQk7ksDjsj50B/ZGL1WHp5HEd7g67r9Jq6rruuM+vHcXS2ND8jZIPbAQAAC0tJREFUf1o92XEc67o2P+1le0s92sIUq/M9RI6Sl/LubQDIjlKzNqvmOdsbo7yXDx6FIBeMTzSf4+ZL3fgPtFffpGtUn6kbTQoEnfZA/7WqKp2RySRT0uUknrIelrmcdWKJPcHE4/FwckO9ORe8wa4McolALsgIhkKQ+Uq+O53hoG1bnc+g6zrdPJs8Csv0i4/HQ1sDZqYoY1WM46htCJ0uSRsZfd+nn7LeUtcqYiiYjExOOgdQF7vBrg9yiUAuyAiGQh6q6k9Z/oXyjRsXkJkPWudkNK2vNh1MPiVjGXhjGmzvgvoML6iqKjHS0ExdPc/zOI7xSR90xa45FTUAAKxS4KiHXGQPG64qlas8/aX+eDxMDU3CZt3e2/mbTc+CvVL/V3sgtHdBfbocVlt0bVhoO2N1Y5PpGUPBgbh0EcglArkgIxgKQUSP2Tz/sbrNH3+sGwrpPYum98FBf+LP89x1XVVVy7AAp9nWhegtI825qZgOOzC2yOPxWO1TSNnmDeE9LgK5RCAXZKQ0q/MwO/r0FM52a72BLCkNrpwXgS8qAFiFhEspFHc+7zHXQ9/3wzC84toVk+D5+s/q9Wt4KZBLBHKlU1UYCisUdz4neRTganCBACAFDIVVGPUAAAAAQQhmDLJqFZLSBPZQ3mfHS0EuEcgFGcFQCBJ/zHgIYSfcQiKQSwRyQUboegAAAIAgGApB6FmQgmIikEsEcolALsgIhkIQfHdSUEwEcolALhHIBRkpMEYhZErz5AAAAEgp0FA4JuESLEExEcglArlEIBdkhK6HIDxmUlBMBHKJQC4RyAUZwVAAAACAIBgKQQgbloJiIpBLBHKJQC7ICIZCEHx3UlBMBHKJQC4RyCVgxqhaAUMBAAAAgmAoBMF3JwXFRCCXCOQSgVyQEQwFAAAACIKhAAAAAEEwFAAA4H2ZFYGfK2AoAAAAQBAMBQAAAAhy17ke+r5XSjVN0zTNyVVJI2Pq9WsWlZfLnuM1FbvsOSLXWUXl5ZrneFm5yuN+HoVpmqqqmqZpmqa2bbXFAAAAAK/gfhZZVVV1XU/TpJTq+34YBvsULmuuXrNinOOJpV2zqLylFV9U3tKuWVTe0q5ZlFI67cQFK3YJ7nc+VVWN42h6HJY/L3kXXrRinOOJpV2zqLylFV9U3tKuWVTe0q5ZFIZCnJt1PWhHghOXoFcCAABAdu4azGjjGAoZc5fmTYN6zYpxjieWds2i8pZWfFF5S7tmUXlLu2BR+vufvNchSjAUbAdDYQ4fAAA4BlqPEDfregAAAIAjuZmhoJ0HTl/DXVIpAAAA3I6bGQpKqbqu27bVyybt0on1AQAAKJhbjuKwQ07ssZEZuV3mxyNJEafv+2mamk+OqtoVSb+XdBqxN88hliKXFmp1s3dA9DC++a21St/3SORnvifjOI7j+KKSlVJ1Xdd1rZTquu4VR7kpieLoWwsNpfeS3viIml2SRLm6rrM3e9F74PpIH0a98LZyraL1RB8vdzUUXof9stavpFOrcy1SxHHWv7OGonvJvNAPqNg1SZHLeZvr9u+oCl6LDQ/jm99gIcZxxJCKc78YhQMw3ie9QEInm1VxpmkyT516+wiSxHtJ/9XW7T1JubuUdVNN0zTfsPM0F9I3FTdYiKZptFEFXjAUniDzY4REcUz/cWiDNyH9XpqmyZmy5A1Jv7v0VC+6O5m7a7nSRhsQWqi+7x+Px5sb7l509AbRCRFKSLj0at72ZZRCXBw9axemusErV9u22qMODku5Ho+HUqptW/1xrO8uXvEa793Vdd0wDMMwKKXqukYr2AAehXWwwSOExNGzgQ/DMI4j7ybDUq6maeq65h7zEpJlnmftuNKt4LGVui5LubSzSve7j+OIRwG2gaEA+en7vm1bHYbNiynO4/HQr++macwyTqwQJshfw90VRz+GWqWmabStcHal4H5gKDxB5scIieKYj5g3dyQkytV1nX6Vmz+9Z26ARLneUBkvvKngUE4ccXFN7AFX7zy0z0tEnK7rtIfTjG63OaOy55Mil7P9O49eS5FrOTzybRVLkctZ/86jSVNQDI8MwE3jwTakuG8cvOLYr2/sUZtVuWzeudnTpMjlxMaeVdUrkCKXMySSF1oE9AlxyxTOB+AdfQQaxBGBXCIS5UJVDXLBAWAoAAAAQBCCGQEAACAIhgIAAAAEwVAAAACAIBgKAAAx+r6vLOwEIVVVZc+OpacekO5SVZW9rCd3iEcvnpixY5om+9C6zppXJBzTiWKX61elFl3fgmNFMRQAAIKY+Ur0ODGdNNq0Li9Kvy1qKadpejweelSkWW4+iex4oqHQtq3RUDfhdp6Mtm2zH9EMExUlNzN7hUwNh2KzzJ02MBMA4PIopYyVoHl1HjZpOg27PrqhfUm18mFX0lth9cp8BtuylaQIewvxt4FHAQAghvN93/e9me3Tdk2bHgrt0DZZlrUv3bjWzfb2ykQXt+2iNwfV02LpEvS3+LLrwT6WWenMrWwKtz+ydVHmT/b2do+MrrzT2RH6Cu/73sma5Zy79ohEam4qFuoPclQyNdFzbT8eD/3TdD04+htPg17vCFtV1X//+197Y3063rzahXC2pQIAcF1Mk+b4FTTq89tXb2ZnMdefrdqkqOva/pPZV68fx9FeH/rk1dVYbm97FELLTn30udgHWlbYOahzjmbZrozzSR05EdthoA9hJFpurGsbqVhIVeeklrWq61oXbpdsH9Q5X+95KaV+/fVXp8DCwFAAAIhh2sKlxaCszOXOeruJcvIr62V7+1BL5t3AOXSo68GsX84Eocs3B1p2piwtjPj5mmbePlnl60Hw+udtB4NtMTgVs/dNuRBmoplVQyGkoXoOntArf/31V7P8z3/+06ttYfx51eUAAPDOmDh87c8fhmEYhnmR09Z2jDszLHgj5vq+nz5Znf3Z+PadlSnRiNM02fVZBtzFCw8dwull0At1Xevz0qUlBkuaThAtr54dW5djV8xchUjF6roehkFvkx5aqI9r9nIun8Nf//pXpdR///vfv/71r//617+0raBpmkb3BBUGMQoAAEGcXvxpmsz4gp0lV1XVtq1unJw++xT07OQ76xAp3CynGAoGHQSglNJDRVYPpO0ke/d5nnVjr5R6PB52m62Fip+1uUDDMDhhDXG0iaMPumph1HX9r3/9Sy8XaRk4YCgAAATRH5r2mpS2J9FDMM9zSsIDc9DeIrEmejO7Pks/xLbCneg/e94p4x5YrZuJE/SirQSnYqsF6srM89x13eqFMGiVEs/9n//85+PxWFpCZUYyYigAAESo61p/95s1Xr+33kwvb2gtVptAuwFW1mCHFJxo/GXD7LTrKf5z+3yNF8H8aRiGkPfea6M4vRimDdYlm5qnVMzO0CBC75XoCNG9D06/gybebXFXzg2RAAC4OMtXv/mTeo7dM5iIOSd2zwmUM5jGaQ4PFjBjMs0uev1qMOP8HC2ofGF9TuGhgMTQ+S4DMyPB/06ZzqGdfb01j1TM2d4eMWEXaMI5nZBMFYgYnZ/HWXg3XtaqGJhmGgBgHdu1vrpN4pB6p8yU4MSUamzeV1q4d3vdmxBpWUwU57Ko0NGzVGxzafaOZq/lJV498fuCoQAAsBe72dANhp016K2oqqqu67iRVFXV3fWpqurXX3/VfRAabSAWmcUZQwEAYC9OUJ4e3Xdedc7BiLDarOgQzpuG/umwx6UxVFXFtqfFnhgAwMHs6Rcog8TUDndHJ1E4uxbHgaEAAAAAQRgeCQAAAEEwFAAAACAIhgIAAAAEwVAAAACAIBgKAAAAEARDAQAAAIJgKAAAAEAQDAUAAAAIgqEAAAAAQTAUAAAAIAiGAgAAAAT5/28TEYBf7eAnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  plot ROC curve\n",
    "c1 = factory.GetROCCurve(dataloader)\n",
    "c1.Draw()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e9f421",
   "metadata": {},
   "source": [
    "### Close the Output File\n",
    "Close outputfile to save all output information (evaluation result of methods) and it can be used by TMVAGUI to display additional plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02873c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (outputFile):\n",
    "    outputFile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f11903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
