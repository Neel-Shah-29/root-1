{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9e3314",
   "metadata": {},
   "source": [
    "# TMVA Higgs Classification in Python\n",
    "In this example we will still do Higgs classification but we will use together with the native TMVA methods also methods from Keras and scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f6b1b",
   "metadata": {},
   "source": [
    "### Import the necessary modules\n",
    "\n",
    "We start with importing the necessary modules required for the tutorial. Here we imported ROOT and TMVA(Toolkit for Multivariate Data Analysis). If you want to know more about TMVA, you can refer the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d8e0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edbf77",
   "metadata": {},
   "source": [
    "\n",
    "## Classification example of TMVA based on public Higgs UCI dataset\n",
    "The UCI data set is a public HIGGS data set , see http://archive.ics.uci.edu/ml/datasets/HIGGS\n",
    "used in this paper: Baldi, P., P. Sadowski, and D. Whiteson. “Searching for Exotic Particles in High-energy Physics with Deep Learning.” Nature Communications 5 (July 2, 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a6b867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options to control used methods\n",
    "\n",
    "useLikelihood = True       #likelihood based discriminant\n",
    "useLikelihoodKDE = False   #likelihood based discriminant\n",
    "useFischer = True          #Fischer discriminant\n",
    "useMLP = False             #Multi Layer Perceptron (old TMVA NN implementation)\n",
    "useBDT = True              #BOosted Decision Tree\n",
    "useDL = True               #TMVA Deep learning ( CPU or GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f3fdd",
   "metadata": {},
   "source": [
    "### Setting up TMVA\n",
    "\n",
    "TMVA requires initialization the PyMVA to utilize PyTorch. PyMVA is the interface for third-party MVA tools based on Python. It is created to make powerful external libraries easily accessible with a direct integration into the TMVA workflow. All PyMVA methods provide the same plug-and-play mechanisms as the TMVA methods. Because the base method of PyMVA is inherited from the TMVA base method, all options of internal TMVA methods apply for PyMVA methods as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901569c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.TMVA.Tools object at 0x7c18eb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT.TMVA.Tools.Instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f69c8",
   "metadata": {},
   "source": [
    "\n",
    "### Create an Output File and Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods whose performance you'd like to investigate.\n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    "- The first argument is the base of the name of all the output weightfiles in the directory weight/ that will be created with the method parameters\n",
    "\n",
    "- The second argument is the output file for the training results\n",
    "\n",
    "- The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3259f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputFile = ROOT.TFile.Open(\"Higgs_ClassificationOutput.root\", \"RECREATE\")\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_Higgs_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c10f7",
   "metadata": {},
   "source": [
    "### Define the input datafile\n",
    "\n",
    "Take the input of the .root file in a variable if file exists. If the file doesn't exist, then download it through Cern box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d25d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileName = \"Higgs_data.root\"\n",
    "\n",
    "inputFile = ROOT.TFile.Open( inputFileName )\n",
    "inputFileLink = \"http://root.cern.ch/files/\" + inputFileName\n",
    "\n",
    "\n",
    "if (ROOT.gSystem.AccessPathName(inputFileName)!=None):\n",
    "    # file exists\n",
    "    inputFile = ROOT.TFile.Open( inputFileName )\n",
    "if(inputFile == None): \n",
    "    # download file from Cernbox location\n",
    "    ROOT.Info(\"TMVA_Higgs_Classification\",\"Download Higgs_data.root file\")\n",
    "    ROOT.TFile.SetCacheFileDir(\".\")\n",
    "    inputFile = ROOT.TFile.Open(inputFileLink, \"CACHEREAD\")\n",
    "    if (inputFile == NULL):\n",
    "        Error(\"TMVA_Higgs_Classification\",\"Input file cannot be downloaded - exit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fad5ec",
   "metadata": {},
   "source": [
    "### Setting up the Signal and Background Trees\n",
    "\n",
    "Here we are setting up the Training and testing Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776b16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : tree                                                   *\n",
      "*Entries :    10000 : Total =         1177229 bytes  File  Size =     785298 *\n",
      "*        :          : Tree compression factor =   1.48                       *\n",
      "******************************************************************************\n",
      "*Br    0 :Type      : Type/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40556 bytes  File Size  =        307 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression= 130.54     *\n",
      "*............................................................................*\n",
      "*Br    1 :lepton_pT : lepton_pT/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40581 bytes  File Size  =      30464 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.32     *\n",
      "*............................................................................*\n",
      "*Br    2 :lepton_eta : lepton_eta/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40586 bytes  File Size  =      28650 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.40     *\n",
      "*............................................................................*\n",
      "*Br    3 :lepton_phi : lepton_phi/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40586 bytes  File Size  =      30508 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.31     *\n",
      "*............................................................................*\n",
      "*Br    4 :missing_energy_magnitude : missing_energy_magnitude/F              *\n",
      "*Entries :    10000 : Total  Size=      40656 bytes  File Size  =      35749 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.12     *\n",
      "*............................................................................*\n",
      "*Br    5 :missing_energy_phi : missing_energy_phi/F                          *\n",
      "*Entries :    10000 : Total  Size=      40626 bytes  File Size  =      36766 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.09     *\n",
      "*............................................................................*\n",
      "*Br    6 :jet1_pt   : jet1_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40571 bytes  File Size  =      32298 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.24     *\n",
      "*............................................................................*\n",
      "*Br    7 :jet1_eta  : jet1_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      28467 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.41     *\n",
      "*............................................................................*\n",
      "*Br    8 :jet1_phi  : jet1_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      30399 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.32     *\n",
      "*............................................................................*\n",
      "*Br    9 :jet1_b-tag : jet1_b-tag/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40586 bytes  File Size  =       5087 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   7.88     *\n",
      "*............................................................................*\n",
      "*Br   10 :jet2_pt   : jet2_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40571 bytes  File Size  =      31561 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.27     *\n",
      "*............................................................................*\n",
      "*Br   11 :jet2_eta  : jet2_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      28616 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.40     *\n",
      "*............................................................................*\n",
      "*Br   12 :jet2_phi  : jet2_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      30547 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.31     *\n",
      "*............................................................................*\n",
      "*Br   13 :jet2_b-tag : jet2_b-tag/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40586 bytes  File Size  =       5031 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   7.97     *\n",
      "*............................................................................*\n",
      "*Br   14 :jet3_pt   : jet3_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40571 bytes  File Size  =      30642 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.31     *\n",
      "*............................................................................*\n",
      "*Br   15 :jet3_eta  : jet3_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      28955 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.38     *\n",
      "*............................................................................*\n",
      "*Br   16 :jet3_phi  : jet3_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      30433 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.32     *\n",
      "*............................................................................*\n",
      "*Br   17 :jet3_b-tag : jet3_b-tag/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40586 bytes  File Size  =       4879 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   8.22     *\n",
      "*............................................................................*\n",
      "*Br   18 :jet4_pt   : jet4_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40571 bytes  File Size  =      29189 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.37     *\n",
      "*............................................................................*\n",
      "*Br   19 :jet4_eta  : jet4_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      29311 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.37     *\n",
      "*............................................................................*\n",
      "*Br   20 :jet4_phi  : jet4_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40576 bytes  File Size  =      30525 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.31     *\n",
      "*............................................................................*\n",
      "*Br   21 :jet4_b-tag : jet4_b-tag/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40586 bytes  File Size  =       4725 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   8.48     *\n",
      "*............................................................................*\n",
      "*Br   22 :m_jj      : m_jj/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40556 bytes  File Size  =      34991 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.15     *\n",
      "*............................................................................*\n",
      "*Br   23 :m_jjj     : m_jjj/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40561 bytes  File Size  =      34460 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.16     *\n",
      "*............................................................................*\n",
      "*Br   24 :m_lv      : m_lv/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40556 bytes  File Size  =      32232 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.24     *\n",
      "*............................................................................*\n",
      "*Br   25 :m_jlv     : m_jlv/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40561 bytes  File Size  =      34598 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.16     *\n",
      "*............................................................................*\n",
      "*Br   26 :m_bb      : m_bb/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40556 bytes  File Size  =      35012 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.14     *\n",
      "*............................................................................*\n",
      "*Br   27 :m_wbb     : m_wbb/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40561 bytes  File Size  =      34493 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.16     *\n",
      "*............................................................................*\n",
      "*Br   28 :m_wwbb    : m_wwbb/F                                               *\n",
      "*Entries :    10000 : Total  Size=      40566 bytes  File Size  =      34410 *\n",
      "*Baskets :        1 : Basket Size=    1500672 bytes  Compression=   1.16     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "# --- Register the training and test trees\n",
    "\n",
    "signalTree = inputFile.Get(\"sig_tree\")\n",
    "backgroundTree = inputFile.Get(\"bkg_tree\")\n",
    "\n",
    "signalTree.Print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547618f9",
   "metadata": {},
   "source": [
    "### Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables\n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc942fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "loader.AddVariable(\"m_jj\")\n",
    "loader.AddVariable(\"m_jjj\")\n",
    "loader.AddVariable(\"m_lv\")\n",
    "loader.AddVariable(\"m_jlv\")\n",
    "loader.AddVariable(\"m_bb\")\n",
    "loader.AddVariable(\"m_wbb\")\n",
    "loader.AddVariable(\"m_wwbb\")\n",
    "\n",
    "### We set now the input data trees in the TMVA DataLoader class\n",
    "\n",
    "# global event weights per tree (see below for setting event-wise weights)\n",
    "signalWeight = 1.0\n",
    "backgroundWeight = 1.0\n",
    "\n",
    "#  You can add an arbitrary number of signal or background trees\n",
    "loader.AddSignalTree    ( signalTree,     signalWeight     )\n",
    "loader.AddBackgroundTree( backgroundTree, backgroundWeight )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441704b",
   "metadata": {},
   "source": [
    "Set individual event weights (the variables must exist in the original TTree)\n",
    "\n",
    "for signal    : factory.SetSignalWeightExpression    (\"weight1*weight2\")\n",
    "\n",
    "for background: factory.SetBackgroundWeightExpression(\"weight1*weight2\")\n",
    "\n",
    "loader.SetBackgroundWeightExpression( \"weight\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30a7c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\") # for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\"\n",
    "mycutb = ROOT.TCut(\"\") # for example: TCut mycutb = \"abs(var1)<0.5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55304d",
   "metadata": {},
   "source": [
    "### Tell the factory how to use the training and testing events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71f3f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If no numbers of events are given, half of the events in the tree are used\n",
    "# for training, and the other half for testing:\n",
    "#    loader.PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" )\n",
    "# To also specify the number of testing events, use:\n",
    "\n",
    "loader.PrepareTrainingAndTestTree( mycuts, mycutb, \"nTrain_Signal=7000:nTrain_Background=7000:SplitMode=Random:NormMode=NumEvents:!V\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8b9ac",
   "metadata": {},
   "source": [
    "### Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book first a Likelihood based on KDE (Kernel Density Estimation), a Fischer discriminant, a BDT\n",
    "and a shallow neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8269f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLikelihood\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mFisher\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "                         : Rebuilding Dataset dataset\n",
      "                         : Building event vectors for type 2 Signal\n",
      "                         : Dataset[dataset] :  create input formulas for tree sig_tree\n",
      "                         : Building event vectors for type 2 Background\n",
      "                         : Dataset[dataset] :  create input formulas for tree bkg_tree\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 7000\n",
      "                         : Signal     -- testing events             : 3000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 7000\n",
      "                         : Background -- testing events             : 3000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------------------------------\n",
      "                         :             m_jj   m_jjj    m_lv   m_jlv    m_bb   m_wbb  m_wwbb\n",
      "                         :    m_jj:  +1.000  +0.774  -0.004  +0.096  +0.024  +0.512  +0.533\n",
      "                         :   m_jjj:  +0.774  +1.000  -0.010  +0.073  +0.152  +0.674  +0.668\n",
      "                         :    m_lv:  -0.004  -0.010  +1.000  +0.121  -0.027  +0.009  +0.021\n",
      "                         :   m_jlv:  +0.096  +0.073  +0.121  +1.000  +0.313  +0.544  +0.552\n",
      "                         :    m_bb:  +0.024  +0.152  -0.027  +0.313  +1.000  +0.445  +0.333\n",
      "                         :   m_wbb:  +0.512  +0.674  +0.009  +0.544  +0.445  +1.000  +0.915\n",
      "                         :  m_wwbb:  +0.533  +0.668  +0.021  +0.552  +0.333  +0.915  +1.000\n",
      "                         : ----------------------------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------------------------------\n",
      "                         :             m_jj   m_jjj    m_lv   m_jlv    m_bb   m_wbb  m_wwbb\n",
      "                         :    m_jj:  +1.000  +0.808  +0.022  +0.150  +0.028  +0.407  +0.415\n",
      "                         :   m_jjj:  +0.808  +1.000  +0.041  +0.206  +0.177  +0.569  +0.547\n",
      "                         :    m_lv:  +0.022  +0.041  +1.000  +0.139  +0.037  +0.081  +0.085\n",
      "                         :   m_jlv:  +0.150  +0.206  +0.139  +1.000  +0.309  +0.607  +0.557\n",
      "                         :    m_bb:  +0.028  +0.177  +0.037  +0.309  +1.000  +0.625  +0.447\n",
      "                         :   m_wbb:  +0.407  +0.569  +0.081  +0.607  +0.625  +1.000  +0.884\n",
      "                         :  m_wwbb:  +0.415  +0.547  +0.085  +0.557  +0.447  +0.884  +1.000\n",
      "                         : ----------------------------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "# Likelihood (\"naive Bayes estimator\")\n",
    "if (useLikelihood):\n",
    "   factory.BookMethod(loader, ROOT.TMVA.Types.kLikelihood, \"Likelihood\",\n",
    "                           \"H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmoothBkg[1]=10:NSmooth=1:NAvEvtPerBin=50\" )\n",
    "\n",
    "# Use a kernel density estimator to approximate the PDFs\n",
    "if (useLikelihoodKDE):\n",
    "   factory.BookMethod(loader, ROOT.TMVA.Types.kLikelihood, \"LikelihoodKDE\",\n",
    "                      \"!H:!V:!TransformOutput:PDFInterpol=KDE:KDEtype=Gauss:KDEiter=Adaptive:KDEFineFactor=0.3:KDEborder=None:NAvEvtPerBin=50\" )\n",
    "\n",
    "# Fisher discriminant (same as LD)\n",
    "if (useFischer):\n",
    "   factory.BookMethod(loader, ROOT.TMVA.Types.kFisher, \"Fisher\", \"H:!V:Fisher:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10\" )\n",
    "\n",
    "\n",
    "# Boosted Decision Trees\n",
    "if (useBDT):\n",
    "   factory.BookMethod(loader,ROOT.TMVA.Types.kBDT, \"BDT\",\n",
    "                      \"!V:NTrees=200:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" )\n",
    "\n",
    "\n",
    "# Multi-Layer Perceptron (Neural Network)\n",
    "if (useMLP):\n",
    "   factory.BookMethod(loader, ROOT.TMVA.Types.kMLP, \"MLP\",\n",
    "                      \"!H:!V:NeuronType=tanh:VarTransform=N:NCycles=100:HiddenLayers=N+5:TestRate=5:!UseRegulator\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae1286",
   "metadata": {},
   "source": [
    "   ### Booking Deep Neural Network\n",
    "\n",
    "   Here we define the option string for building the Deep Neural network model.\n",
    "\n",
    "   #### 1. Define DNN layout\n",
    "\n",
    "   The DNN configuration is defined using a string. Note that whitespaces between characters are not allowed.\n",
    "\n",
    "   We define first the DNN layout:\n",
    "\n",
    "   - **input layout** :   this defines the input data format for the DNN as  ``input depth | height | width``.\n",
    "      In case of a dense layer as first layer the input layout should be  ``1 | 1 | number of input variables`` (features)\n",
    "   - **batch layout**  : this defines how are the input batch. It is related to input layout but not the same.\n",
    "      If the first layer is dense it should be ``1 | batch size ! number of variables`` (features)\n",
    "\n",
    "      *(note the use of the character `|` as  separator of  input parameters for DNN layout)*\n",
    "\n",
    "   note that in case of only dense layer the input layout could be omitted but it is required when defining more\n",
    "   complex architectures\n",
    "\n",
    "   - **layer layout** string defining the layer architecture. The syntax is\n",
    "      - layer type (e.g. DENSE, CONV, RNN)\n",
    "      - layer parameters (e.g. number of units)\n",
    "      - activation function (e.g  TANH, RELU,...)\n",
    "\n",
    "      *the different layers are separated by the ``\",\"`` *\n",
    "\n",
    "   #### 2. Define Training Strategy\n",
    "\n",
    "   We define here the training strategy parameters for the DNN. The parameters are separated by the ``\",\"`` separator.\n",
    "   One can then concatenate different training strategy with different parameters. The training strategy are separated by\n",
    "   the ``\"|\"`` separator.\n",
    "\n",
    "   - Optimizer\n",
    "   - Learning rate\n",
    "   - Momentum (valid for SGD and RMSPROP)\n",
    "   - Regularization and Weight Decay\n",
    "   - Dropout\n",
    "   - Max number of epochs\n",
    "   - Convergence steps. if the test error will not decrease after that value the training will stop\n",
    "   - Batch size (This value must be the same specified in the input layout)\n",
    "   - Test Repetitions (the interval when the test error will be computed)\n",
    "\n",
    "\n",
    "   #### 3. Define general DNN options\n",
    "\n",
    "   We define the general DNN options concatenating in the final string the previously defined layout and training strategy.\n",
    "   Note we use the ``\":\"`` separator to separate the different higher level options, as in the other TMVA methods.\n",
    "   In addition to input layout, batch layout and training strategy we add now:\n",
    "\n",
    "   - Type of Loss function (e.g. CROSSENTROPY)\n",
    "   - Weight Initizalization (e.g XAVIER, XAVIERUNIFORM, NORMAL )\n",
    "   - Variable Transformation\n",
    "   - Type of Architecture (e.g. CPU, GPU, Standard)\n",
    "\n",
    "   We can then book the DL method using the built option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760b7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we book the new DNN of TMVA if we have support in ROOT. We will use GPU version if ROOT is enabled with GPU\n",
    "\n",
    "# Define DNN layout\n",
    "inputLayoutString = \"InputLayout=1|1|7\"\n",
    "batchLayoutString= \"BatchLayout=1|32|7\"\n",
    "layoutString= \"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\"\n",
    "# Define Training strategies\n",
    "# one can catenate several training strategies\n",
    "training1  = \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,\"\n",
    "training1 += \"DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
    "#      training2 = ROOT.TString(\"LearningRate=1e-3,Momentum=0.9\"\n",
    "#                       \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "#                       \"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"\n",
    "#                       \"Optimizer=SGD,DropConfig=0.0+0.0+0.0+0.\");\n",
    "\n",
    "trainingStrategyString = \"TrainingStrategy=\"\n",
    "trainingStrategyString += training1 # + \"|\" + training2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172a959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  General Options.\n",
    "\n",
    "dnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:\"+\"WeightInitialization=XAVIER\"\n",
    "\n",
    "dnnOptions +=  \":\" + inputLayoutString\n",
    "dnnOptions +=  \":\" + batchLayoutString\n",
    "dnnOptions +=  \":\" + layoutString\n",
    "dnnOptions +=  \":\" + trainingStrategyString\n",
    "\n",
    "dnnMethodName = \"DNN_CPU\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd869bf8",
   "metadata": {},
   "source": [
    "### Booking a Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "323a80cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "none of the 3 overloaded methods succeeded. Full details:\n  TMVA::MethodBase* TMVA::Factory::BookMethod(TMVA::DataLoader* loader, TString theMethodName, TString methodTitle, TString theOption = \"\") =>\n    TypeError: could not convert argument 2\n  TMVA::MethodBase* TMVA::Factory::BookMethod(TMVA::DataLoader* loader, TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = \"\") =>\n    runtime_error: FATAL error\n  TMVA::MethodBase* TMVA::Factory::BookMethod(TMVA::DataLoader*, TMVA::Types::EMVA, TString, TString, TMVA::Types::EMVA, TString) =>\n    TypeError: takes at least 6 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBookMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mROOT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTMVA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkDL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdnnMethodName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdnnOptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: none of the 3 overloaded methods succeeded. Full details:\n  TMVA::MethodBase* TMVA::Factory::BookMethod(TMVA::DataLoader* loader, TString theMethodName, TString methodTitle, TString theOption = \"\") =>\n    TypeError: could not convert argument 2\n  TMVA::MethodBase* TMVA::Factory::BookMethod(TMVA::DataLoader* loader, TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = \"\") =>\n    runtime_error: FATAL error\n  TMVA::MethodBase* TMVA::Factory::BookMethod(TMVA::DataLoader*, TMVA::Types::EMVA, TString, TString, TMVA::Types::EMVA, TString) =>\n    TypeError: takes at least 6 arguments (4 given)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37;41;1m<FATAL>                         : Booking failed since method with title <DNN_CPU> already exists in with DataSet Name <dataset>  \u001b[0m\n",
      "***> abort program execution\n",
      "\u001b[37;41;1m<FATAL>                         : Booking failed since method with title <DNN_CPU> already exists in with DataSet Name <dataset>  Booking failed since method with title <DNN_CPU> already exists in with DataSet Name <dataset>  \u001b[0m\n",
      "***> abort program execution\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(loader, ROOT.TMVA.Types.kDL, dnnMethodName, dnnOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7fdbc8",
   "metadata": {},
   "source": [
    "### Training All Methods\n",
    "\n",
    "Here we train all the previously booked methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f6a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0318    0.65629   [    0.15106     16.132 ]\n",
      "                         :    m_jjj:     1.0217    0.37420   [    0.34247     8.9401 ]\n",
      "                         :     m_lv:     1.0507    0.16678   [    0.26679     3.6823 ]\n",
      "                         :    m_jlv:     1.0161    0.40288   [    0.38441     6.5831 ]\n",
      "                         :     m_bb:    0.97707    0.53961   [   0.080986     8.2551 ]\n",
      "                         :    m_wbb:     1.0358    0.36856   [    0.38503     6.4013 ]\n",
      "                         :   m_wwbb:    0.96265    0.31608   [    0.43228     4.5350 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : -------------------------------\n",
      "                         :    1 : m_bb      : 9.511e-02\n",
      "                         :    2 : m_wbb     : 4.268e-02\n",
      "                         :    3 : m_wwbb    : 4.178e-02\n",
      "                         :    4 : m_jjj     : 2.825e-02\n",
      "                         :    5 : m_jlv     : 1.999e-02\n",
      "                         :    6 : m_jj      : 3.834e-03\n",
      "                         :    7 : m_lv      : 3.699e-03\n",
      "                         : -------------------------------\n",
      "Factory                  : Train method: Likelihood for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Likelihood ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : The maximum-likelihood classifier models the data with probability \n",
      "                         : density functions (PDF) reproducing the signal and background\n",
      "                         : distributions of the input variables. Correlations among the \n",
      "                         : variables are ignored.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Required for good performance are decorrelated input variables\n",
      "                         : (PCA transformation via the option \"VarTransform=Decorrelate\"\n",
      "                         : may be tried). Irreducible non-linear correlations may be reduced\n",
      "                         : by precombining strongly correlated input variables, or by simply\n",
      "                         : removing one of the variables.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : High fidelity PDF estimates are mandatory, i.e., sufficient training \n",
      "                         : statistics is required to populate the tails of the distributions\n",
      "                         : It would be a surprise if the default Spline or KDE kernel parameters\n",
      "                         : provide a satisfying fit to the data. The user is advised to properly\n",
      "                         : tune the events per bin and smooth options in the spline cases\n",
      "                         : individually per variable. If the KDE kernel is used, the adaptive\n",
      "                         : Gaussian kernel may lead to artefacts, so please always also try\n",
      "                         : the non-adaptive one.\n",
      "                         : \n",
      "                         : All tuning parameters must be adjusted individually for each input\n",
      "                         : variable!\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Filling reference histograms\n",
      "                         : Building PDF out of reference histograms\n",
      "                         : Elapsed time for training with 14000 events: 0.13 sec         \n",
      "Likelihood               : [dataset] : Evaluation of Likelihood on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.0189 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Likelihood.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Likelihood.class.C\u001b[0m\n",
      "                         : Higgs_ClassificationOutput.root:/dataset/Method_Likelihood/Likelihood\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: Fisher for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Fisher ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : Fisher discriminants select events by distinguishing the mean \n",
      "                         : values of the signal and background distributions in a trans- \n",
      "                         : formed variable space where linear correlations are removed.\n",
      "                         : \n",
      "                         :    (More precisely: the \"linear discriminator\" determines\n",
      "                         :     an axis in the (correlated) hyperspace of the input \n",
      "                         :     variables such that, when projecting the output classes \n",
      "                         :     (signal and background) upon this axis, they are pushed \n",
      "                         :     as far as possible away from each other, while events\n",
      "                         :     of a same class are confined in a close vicinity. The  \n",
      "                         :     linearity property of this classifier is reflected in the \n",
      "                         :     metric with which \"far apart\" and \"close vicinity\" are \n",
      "                         :     determined: the covariance matrix of the discriminating\n",
      "                         :     variable space.)\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Optimal performance for Fisher discriminants is obtained for \n",
      "                         : linearly correlated Gaussian-distributed variables. Any deviation\n",
      "                         : from this ideal reduces the achievable separation power. In \n",
      "                         : particular, no discrimination at all is achieved for a variable\n",
      "                         : that has the same sample mean for signal and background, even if \n",
      "                         : the shapes of the distributions are very different. Thus, Fisher \n",
      "                         : discriminants often benefit from suitable transformations of the \n",
      "                         : input variables. For example, if a variable x in [-1,1] has a \n",
      "                         : a parabolic signal distributions, and a uniform background\n",
      "                         : distributions, their mean value is zero in both cases, leading \n",
      "                         : to no separation. The simple transformation x -> |x| renders this \n",
      "                         : variable powerful for the use in a Fisher discriminant.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : <None>\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "Fisher                   : Results for Fisher coefficients:\n",
      "                         : -----------------------\n",
      "                         : Variable:  Coefficient:\n",
      "                         : -----------------------\n",
      "                         :     m_jj:       -0.051\n",
      "                         :    m_jjj:       +0.192\n",
      "                         :     m_lv:       +0.045\n",
      "                         :    m_jlv:       +0.059\n",
      "                         :     m_bb:       -0.211\n",
      "                         :    m_wbb:       +0.549\n",
      "                         :   m_wwbb:       -0.778\n",
      "                         : (offset):       +0.136\n",
      "                         : -----------------------\n",
      "                         : Elapsed time for training with 14000 events: 0.0117 sec         \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.00208 sec       \n",
      "                         : <CreateMVAPdfs> Separation from histogram (PDF): 0.090 (0.000)\n",
      "                         : Dataset[dataset] : Evaluation of Fisher on training sample\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Fisher.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Fisher.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 7000 bkg: 7000\n",
      "                         : #events: (unweighted) sig: 7000 bkg: 7000\n",
      "                         : Training 200 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 14000 events: 0.888 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.123 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_BDT.class.C\u001b[0m\n",
      "                         : Higgs_ClassificationOutput.root:/dataset/Method_BDT/BDT\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DNN_CPU for Classification\n",
      "                         : \n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:  0.0043655    0.99836   [    -3.2801     5.7307 ]\n",
      "                         :    m_jjj:  0.0044371    0.99827   [    -3.2805     5.7307 ]\n",
      "                         :     m_lv:  0.0053380     1.0003   [    -3.2810     5.7307 ]\n",
      "                         :    m_jlv:  0.0044637    0.99837   [    -3.2803     5.7307 ]\n",
      "                         :     m_bb:  0.0043676    0.99847   [    -3.2797     5.7307 ]\n",
      "                         :    m_wbb:  0.0042343    0.99744   [    -3.2803     5.7307 ]\n",
      "                         :   m_wwbb:  0.0046014    0.99948   [    -3.2802     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 1\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:  0.0043655    0.99836   [    -3.2801     5.7307 ]\n",
      "                         :    m_jjj:  0.0044371    0.99827   [    -3.2805     5.7307 ]\n",
      "                         :     m_lv:  0.0053380     1.0003   [    -3.2810     5.7307 ]\n",
      "                         :    m_jlv:  0.0044637    0.99837   [    -3.2803     5.7307 ]\n",
      "                         :     m_bb:  0.0043676    0.99847   [    -3.2797     5.7307 ]\n",
      "                         :    m_wbb:  0.0042343    0.99744   [    -3.2803     5.7307 ]\n",
      "                         :   m_wwbb:  0.0046014    0.99948   [    -3.2802     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 7 )  Batch size = 32  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =     7 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,    32 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 11200 events for training and 2800 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.001 regularization 0 minimum error = 0.867651\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.636311     0.59466    0.309578   0.0313318     40252.1           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.590788     0.59122    0.300325   0.0315455     41669.8           0\n",
      "                         :          3 |     0.579105    0.592004    0.335267   0.0295925     36640.3           1\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.574017    0.588647    0.333557   0.0267198     36501.5           0\n",
      "                         :          5 |     0.567451    0.591496    0.313355   0.0282821     39288.2           1\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.565052    0.586042    0.299318   0.0267129     41085.1           0\n",
      "                         :          7 |     0.561269    0.588571    0.333248    0.026305     36488.8           1\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.558239    0.585236    0.293383   0.0286853     42312.4           0\n",
      "                         :          9 |     0.553902    0.593314    0.301313   0.0283012     41023.9           1\n",
      "                         :         10 |     0.555055    0.588438    0.322546   0.0275191     37962.6           2\n",
      "                         :         11 |     0.550357    0.591367    0.291273   0.0267248     42336.3           3\n",
      "                         :         12 |     0.548204    0.586704    0.320335   0.0290197     38446.3           4\n",
      "                         :         13 |     0.545726    0.590871    0.323255   0.0322095       38482           5\n",
      "                         :         14 |     0.541652    0.596525    0.454011   0.0429761     27248.3           6\n",
      "                         :         15 |     0.539892    0.599224     0.36174   0.0267406     33432.9           7\n",
      "                         :         16 |      0.53758    0.594828    0.319713   0.0301005     38672.4           8\n",
      "                         :         17 |     0.536005    0.596272    0.301719   0.0267562     40732.8           9\n",
      "                         :         18 |     0.531919    0.595307    0.292776   0.0267151     42095.6          10\n",
      "                         :         19 |     0.529903    0.591755    0.294699   0.0266639     41785.6          11\n",
      "                         : \n",
      "                         : Elapsed time for training with 14000 events: 6.27 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 32\n",
      "                         : \n",
      "DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.137 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_DNN_CPU.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_DNN_CPU.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "Likelihood               : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Delta Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : m_bb      : 4.061e-02\n",
      "                         :    2 : m_wbb     : 3.765e-02\n",
      "                         :    3 : m_wwbb    : 3.119e-02\n",
      "                         :    4 : m_jj      : -1.589e-03\n",
      "                         :    5 : m_jjj     : -2.901e-03\n",
      "                         :    6 : m_lv      : -7.919e-03\n",
      "                         :    7 : m_jlv     : -8.293e-03\n",
      "                         : -------------------------------------\n",
      "Fisher                   : Ranking result (top variable is best ranked)\n",
      "                         : ---------------------------------\n",
      "                         : Rank : Variable  : Discr. power\n",
      "                         : ---------------------------------\n",
      "                         :    1 : m_bb      : 1.279e-02\n",
      "                         :    2 : m_wwbb    : 9.131e-03\n",
      "                         :    3 : m_wbb     : 2.668e-03\n",
      "                         :    4 : m_jlv     : 9.145e-04\n",
      "                         :    5 : m_jjj     : 1.769e-04\n",
      "                         :    6 : m_lv      : 6.617e-05\n",
      "                         :    7 : m_jj      : 6.707e-06\n",
      "                         : ---------------------------------\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : ----------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ----------------------------------------\n",
      "                         :    1 : m_bb      : 2.089e-01\n",
      "                         :    2 : m_wwbb    : 1.673e-01\n",
      "                         :    3 : m_wbb     : 1.568e-01\n",
      "                         :    4 : m_jlv     : 1.560e-01\n",
      "                         :    5 : m_jjj     : 1.421e-01\n",
      "                         :    6 : m_jj      : 1.052e-01\n",
      "                         :    7 : m_lv      : 6.369e-02\n",
      "                         : ----------------------------------------\n",
      "                         : No variable ranking supplied by classifier: DNN_CPU\n",
      "TH1.Print Name  = TrainingHistory_DNN_CPU_trainingError, Entries= 0, Total sum= 10.6024\n",
      "TH1.Print Name  = TrainingHistory_DNN_CPU_valError, Entries= 0, Total sum= 11.2425\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Likelihood.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Fisher.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_DNN_CPU.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b9e08",
   "metadata": {},
   "source": [
    "### Test all methods\n",
    "\n",
    "Now we test  all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d79a5678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: Likelihood for Classification performance\n",
      "                         : \n",
      "Likelihood               : [dataset] : Evaluation of Likelihood on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.00972 sec       \n",
      "Factory                  : Test method: Fisher for Classification performance\n",
      "                         : \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0012 sec       \n",
      "                         : Dataset[dataset] : Evaluation of Fisher on testing sample\n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0495 sec       \n",
      "Factory                  : Test method: DNN_CPU for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   0.017919     1.0069   [    -3.3498     3.4247 ]\n",
      "                         :    m_jjj:   0.020352     1.0044   [    -3.2831     3.3699 ]\n",
      "                         :     m_lv:   0.016289    0.99263   [    -3.2339     3.3958 ]\n",
      "                         :    m_jlv:  -0.018431    0.98242   [    -3.0632     5.7307 ]\n",
      "                         :     m_bb:  0.0069564    0.98851   [    -2.9734     3.3513 ]\n",
      "                         :    m_wbb:  -0.010633    0.99340   [    -3.2442     3.2244 ]\n",
      "                         :   m_wwbb:  -0.012669    0.99259   [    -3.1871     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0688 sec       \n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f7f69",
   "metadata": {},
   "source": [
    "### Evaluate all methods\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both training and tetsing data sets. Several histograms are produced which can be examined with the TMVAGui or directly using the output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a48d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: Likelihood\n",
      "                         : \n",
      "Likelihood               : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_Likelihood     : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0447    0.66216   [    0.14661     10.222 ]\n",
      "                         :    m_jjj:     1.0275    0.37015   [    0.34201     5.6016 ]\n",
      "                         :     m_lv:     1.0500    0.15582   [    0.29757     2.8989 ]\n",
      "                         :    m_jlv:     1.0053    0.39478   [    0.41660     5.8799 ]\n",
      "                         :     m_bb:    0.97464    0.52138   [    0.10941     5.5163 ]\n",
      "                         :    m_wbb:     1.0296    0.35719   [    0.38878     3.9747 ]\n",
      "                         :   m_wwbb:    0.95617    0.30368   [    0.44118     4.0728 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: Fisher\n",
      "                         : \n",
      "Fisher                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Also filling probability and rarity histograms (on request)...\n",
      "TFHandler_Fisher         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0447    0.66216   [    0.14661     10.222 ]\n",
      "                         :    m_jjj:     1.0275    0.37015   [    0.34201     5.6016 ]\n",
      "                         :     m_lv:     1.0500    0.15582   [    0.29757     2.8989 ]\n",
      "                         :    m_jlv:     1.0053    0.39478   [    0.41660     5.8799 ]\n",
      "                         :     m_bb:    0.97464    0.52138   [    0.10941     5.5163 ]\n",
      "                         :    m_wbb:     1.0296    0.35719   [    0.38878     3.9747 ]\n",
      "                         :   m_wwbb:    0.95617    0.30368   [    0.44118     4.0728 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0447    0.66216   [    0.14661     10.222 ]\n",
      "                         :    m_jjj:     1.0275    0.37015   [    0.34201     5.6016 ]\n",
      "                         :     m_lv:     1.0500    0.15582   [    0.29757     2.8989 ]\n",
      "                         :    m_jlv:     1.0053    0.39478   [    0.41660     5.8799 ]\n",
      "                         :     m_bb:    0.97464    0.52138   [    0.10941     5.5163 ]\n",
      "                         :    m_wbb:     1.0296    0.35719   [    0.38878     3.9747 ]\n",
      "                         :   m_wwbb:    0.95617    0.30368   [    0.44118     4.0728 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: DNN_CPU\n",
      "                         : \n",
      "DNN_CPU                  : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:  0.0043655    0.99836   [    -3.2801     5.7307 ]\n",
      "                         :    m_jjj:  0.0044371    0.99827   [    -3.2805     5.7307 ]\n",
      "                         :     m_lv:  0.0053380     1.0003   [    -3.2810     5.7307 ]\n",
      "                         :    m_jlv:  0.0044637    0.99837   [    -3.2803     5.7307 ]\n",
      "                         :     m_bb:  0.0043676    0.99847   [    -3.2797     5.7307 ]\n",
      "                         :    m_wbb:  0.0042343    0.99744   [    -3.2803     5.7307 ]\n",
      "                         :   m_wwbb:  0.0046014    0.99948   [    -3.2802     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   0.017919     1.0069   [    -3.3498     3.4247 ]\n",
      "                         :    m_jjj:   0.020352     1.0044   [    -3.2831     3.3699 ]\n",
      "                         :     m_lv:   0.016289    0.99263   [    -3.2339     3.3958 ]\n",
      "                         :    m_jlv:  -0.018431    0.98242   [    -3.0632     5.7307 ]\n",
      "                         :     m_bb:  0.0069564    0.98851   [    -2.9734     3.3513 ]\n",
      "                         :    m_wbb:  -0.010633    0.99340   [    -3.2442     3.2244 ]\n",
      "                         :   m_wwbb:  -0.012669    0.99259   [    -3.1871     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       DNN_CPU        : 0.755\n",
      "                         : dataset       BDT            : 0.754\n",
      "                         : dataset       Likelihood     : 0.699\n",
      "                         : dataset       Fisher         : 0.642\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              DNN_CPU        : 0.127 (0.154)       0.402 (0.452)      0.660 (0.705)\n",
      "                         : dataset              BDT            : 0.098 (0.099)       0.393 (0.402)      0.657 (0.681)\n",
      "                         : dataset              Likelihood     : 0.070 (0.075)       0.356 (0.363)      0.581 (0.597)\n",
      "                         : dataset              Fisher         : 0.015 (0.015)       0.121 (0.131)      0.487 (0.506)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 6000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 14000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16610140",
   "metadata": {},
   "source": [
    "### Plot ROC Curve\n",
    "Here we plot the ROC curve and display the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1008073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## after we get the ROC curve and we display\n",
    "\n",
    "c1 = factory.GetROCCurve(loader)\n",
    "c1.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35b6dc",
   "metadata": {},
   "source": [
    "### Close the Output File\n",
    "Close outputfile to save all output information (evaluation result of methods) and it can be used by TMVAGUI to display additional plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3f3ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputFile.Close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
